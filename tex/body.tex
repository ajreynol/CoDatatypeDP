\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{arydshln}
\usepackage[scaled=.82]{beramono}
\usepackage{booktabs}
\usepackage{bussproofs}
\usepackage{calc}
\usepackage{cite}
\usepackage{mathptmx}
%\usepackage{txfonts}
%\usepackage{mathrsfs}
%\usepackage{pifont}
%\usepackage{smallcap}
\usepackage{mathpartir}
\usepackage{stmaryrd}
\usepackage{subfigure}
\usepackage[usenames]{color}
%\usepackage{graphicx}
%\usepackage{newcent}
\usepackage{textcomp}
%\usepackage{tipa}
\usepackage{units}
\usepackage{url}
\usepackage[all]{xy}

\makeatletter
\def\spnXwtheorem#1#2#3#4{\@spynthm{#1}{#2}{#3}{#4}%
                         \@addtoreset{#1}{chapter}}%
\makeatother

%\newcommand\typ[1]{: #1}
\newcommand\typ[1]{^{\vthinspace #1}}

%\newcommand\PART[1]{.#1}
\newcommand\PART[1]{(#1)}

%\newcommand\AST{\ast}
\newcommand\AST{\infty} %%% matter of taste -- revert if you don't like

\newcommand\MU{\vvthinspace\mu\vvthinspace}

%%% not part of shared counter
\spnXwtheorem{examplex}{Example}{\itshape}{\rmfamily}

\newcommand\MIDRULE{
\\[-1pt] %%% TYPESETTING HACK
\midrule
%$\enatT$
\\[-11pt] %%% TYPESETTING HACK
}

\renewcommand\models{\vDash} %%% matter of taste

\def\thewordpaper{paper}
\newcommand\dotReportFootnote[1]{.}

\newcommand\FV{\mathrm{FV}}

\newcommand\afterDot{\;} %%% Too little space by default after "Lemma Foo."

\begin{report}
\def\thewordpaper{report}
\renewcommand\dotReportFootnote[1]{.\footnote{#1}}
\end{report}

\newcommand\afterLdots{\kern.1em} %% TYPESETTING

% for "bussproofs" package
\EnableBpAbbreviations
\def\ScoreOverhang{1.5pt}
\def\proofSkipAmount{\vskip 0pt}
\def\defaultHypSeparation{\hskip0.75em}

\DeclareFontFamily{OT1}{pzc}{}
\DeclareFontShape{OT1}{pzc}{m}{it}{<-> s * [1.10] pzcmi7t}{}
\DeclareMathAlphabet{\mathscr}{OT1}{pzc}{m}{it}

\DeclareMathAlphabet{\mathcal}{OT1}{pzc}{m}{it}

\let\labelitemi=\labelitemii %% CHEAT!

\newcommand\cpp{C\nobreak\raisebox{.05ex}{+}\nobreak\raisebox{.05ex}{+}}

\newcommand\iPrime{i\vthinspace'\negvthinspace}
\newcommand\jPrime{j\vthinspace'\negvthinspace}

\newcommand\Sig{\mathrm{\Sigma}}

\newcommand\keyw[1]{\textbf{#1}}
\newcommand\const[1]{\textsf{#1}}
\newcommand\ty[1]{\textit{#1}}

%%% @ANDY: I don't like using \qed or anything too similar (e.g. \Box) for
%%% anything else than "quid erat demonstrandum". I'm open to other symbols,
%%% e.g. a filled black square. But if the example are short enough, which
%%% they currently are, we could live with nothing.
%%%
\newcommand\xend{{\hfill$\scriptstyle\blacksquare$}}
%\newcommand\xend{{\qed}}
%\newcommand\xend{{}}

%\renewcommand{\vec}[1]{\mathbf{#1}}
\renewcommand{\vec}[1]{\bar #1}
%\newcommand{\Ec}{\mathsf{E}}
\newcommand{\Ec}{E}
%\newcommand{\Ec}{\mathcal{E}}
%\newcommand{\Fc}{\mathsf{F}}
\newcommand{\Fc}{F}
%\newcommand{\Fc}{\mathcal{F}}
%\newcommand{\Gc}{\mathsf{G}}
%\newcommand{\Ac}{\mathsf{A}}
%\newcommand{\Dc}{\mathsf{D}}
%\newcommand{\Rc}{\mathsf{R}}
\newcommand{\vrange}{\mathsf{range}}
\newcommand{\vdom}{\mathsf{dom}}
\newcommand{\tEc}{\mathcal{T}(\Ec)}
\newcommand{\tcEc}{\mathcal{T}^\AST(\Ec)}
\newcommand{\rn}[1]{\textsf{\small #1}}
\newcommand{\cvc}{\textsc{cvc}{\small 4}\xspace}
\newcommand{\teq}{\approx}
\newcommand{\tneq}{\not\teq}
\newcommand{\rem}[1]{\textcolor{red}{[#1]}}
%\newcommand{\is}[1]{is\text{-} #1}
\newcommand{\is}[1]{\const{is#1}}
\newcommand{\ror}{\kern.45em \parallel \kern.45em}
\newcommand{\tpath}[2]{\mathcal{P}_{ #2 \rightarrow \_ }( #1 )}
\newcommand{\ttpath}[3]{\mathcal{P}_{ #2 \rightarrow #3 }( #1 )}
%\newcommand{\interp}[2]{#1\llbracket #2 \rrbracket}
%%% @ANDY: I prefer a notation that puts more emphasis on #2 (which is, in essence,
%%% the object that is returned) and less on #1
%\newcommand{\interp}[2]{\llbracket #2 \rrbracket_{#1}}
%%% And one that doesn't look so semantic
%\newcommand{\interp}[2]{\lceil #2 \rceil_{#1}}
\newcommand{\interp}[2]{\left< \smash{#2} \right>_{#1}}
\newcommand{\dpath}[3]{\delta^{#1}_{#2}( #3 )}
\newcommand{\ec}[1]{[#1]}
\newcommand{\M}{\mathcal{M}}
\newcommand{\Val}{\mathcal{A}}
\newcommand{\ValC}{\mathcal{A}^\star}
\newcommand{\Var}{\mathcal{V}}
%\newcommand{\Varec}[1]{\Var{\ec{#1}}}
\newcommand{\Varec}[1]{\widetilde{#1}}
\newcommand{\VAREC}[1]{\widetilde{\vphantom{\scriptstyle x^i}\smash{#1}}}
%\newcommand{\nf}[1]{{{#1}{\downarrow}}}
\newcommand{\nf}[1]{\lfloor#1\rfloor}
\newcommand{\aequiv}{\mathrel{=_\alpha}}
\newcommand{\vsim}{\aequiv}
\newcommand{\vsimv}[1]{\mathrel{=^{#1}_\alpha}}
\newcommand{\tpos}[2]{#1\!\mid_{#2}}
\newcommand{\muvar}{\mathcal{Var}}

\newcommand\SSS{\mathit{S\vthinspace}}
\newcommand\SSSS[1]{\mathit{S}^{\,#1}}

% change?
\newcommand{\thO}{T_{\mathrm{o}}}
%\newcommand{\thD}{T_{\!\mathrm{cd}}}
%%% @ANDY: the italicized "T" makes it look as though it were a variable;
%%% and the subscript means we have two layers of subscripts in things like
%%% \model_\thD (although we could drop the "T" and keep only the subscript
%%% like you did in the string paper).
%%% How about the following? I'm pretty sure \mathcal has been used for theories
%%% before by other authors.
%\newcommand{\thD}{\mathcal{CoDt}}
%\newcommand{\thD}{\mathcal{TDC}}
\newcommand{\thD}{\mathcal{DC}}

%\newcommand\Types{\mathcal{T}}
\newcommand\Types{\mathcal{Y}}
\newcommand\Funcs{\mathcal{F}}

\newcommand\Data{\Types_{\mathrm{dt}}}
\newcommand\Codata{\Types_{\mathrm{codt}}}
\newcommand\Nondata{\Types_{\mathrm{ord}}}

\newcommand\Ctr{\Funcs_{\mathrm{ctr}}}
\newcommand\Sel{\Funcs_{\mathrm{sel}}}
%\newcommand\Plainfuncs{\Funcs_{\mathrm{other}}}

\newcommand\vvthinspace{\kern+0.041667em}
\newcommand\vthinspace{\kern+0.083333em}
\newcommand\negvthinspace{\kern-0.083333em}

%%% For final version as well?
\usepackage[
   a4paper,
   pdftex,
   pdftitle={A Decision Procedure for (Co)datatypes in SMT Solvers},
   pdfauthor={Andrew Reynolds and Jasmin Christian Blanchette},
   pdfkeywords={},
   pdfborder={0 0 0},
   draft=false,
   bookmarksnumbered,
   bookmarks,
   bookmarksdepth=2,
   bookmarksopenlevel=2,
   bookmarksopen]{hyperref}

\urlstyle{ttstyle}

\global\def\figurename{Figure}
\global\def\figuresname{Figures}

\DeclareSymbolFont{letters}{OML}{txmi}{m}{it}

%%% REMOVE BEFORE SUBMITTING ABSOLUTELY FINAL VERSION
\makeatletter
\ps@myheadings
\makeatother

\include{defs}

\hyphenation{data-type data-types co-data-type co-data-types isa-belle sledge-hammer
non-redun-dant}


\begin{document}

\title{A Decision Procedure for (Co)datatypes in SMT Solvers}

\author {Andrew Reynolds\inst{1} \and Jasmin Christian Blanchette\inst{2,3}}
\authorrunning {A. Reynolds \and J. C. Blanchette}
\institute{
\'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL), Switzerland
\and
Inria Nancy \& LORIA, Villers-l\`es-Nancy, France
\and
Max-Planck-Institut f\"ur Informatik, Saarbr\"ucken, Germany
}

\maketitle

\begin{abstract}
%Codatatypes naturally capture potentially infinite data structures and
%processes.
We present a decision procedure that combines reasoning about
datatypes and codatatypes. The dual of the acyclicity rule for datatypes is a
uniqueness rule that identifies observationally equal values, also in the presence of cyclic
($\omega$-regular) data. The procedure decides ground and universal
problems and is composable via the Nelson--Oppen method. It has been
implemented in the latest version of CVC4, a state-of-the-art SMT solver. An
evaluation based on problems generated from Isabelle theories demonstrates the
potential of the procedure.
\end{abstract}

%% The institutions above shouldn't count as footnotes
\setcounter{footnote}{0}

\section{Introduction}
\label{sec:introduction}

Freely generated inductive datatypes are ubiquitous in functional programs and
logical specifications. They are especially
useful to represent finite data structures in computer science applications but
also arise when formalizing mathematics.
They can be implemented efficiently and enjoy
properties that can be exploited in automated reasoners.
%
%However, because datatype values correspond to finite ground terms, they
%are generally not adequate to represent infinite objects.
%For example, the datatype of natural numbers
%constructed by $\const{Z} : \ty{nat}$ and $\const{S} : \ty{nat} \to \ty{nat}$
%only allow values of the form $\const{S}(\ldots(\const{S}(\const{Z}))\ldots)$.

To represent infinite objects, % such as $\const{S}(\const{S}(\const{S}(\ldots))$,
a natural choice is to turn to coinductive datatypes, or \emph{codatatypes},
the non-well-founded dual of inductive \emph{datatypes}.
%
Despite their reputation for being esoteric, codatatypes have a
role to play in computer science. The verified C compiler CompCert
\cite{leroy-2009}, the verified Java compiler Jinja\-Threads
\cite{lochbihler-2010-jinja}, and the formalized Java memory model
\cite{lochbihler-2014-jmm} all depend on codatatypes to capture infinite
processes.

Codatatypes are freely generated by their constructors, but in contrast with datatypes,
infinit\-e constructor terms are also legitimate values for codatatypes
(Section~\ref{sec:the-theory-of-co-datatypes}). Intuitively, the
values of a codatatype consist of all well-typed finite and infinite ground
constructor
terms, and only those. For example, the coinductive specification
%
\[\keyw{codatatype}~\,\ty{enat} \,=\, \const{Z} \,\mid\, \const{S}(\ty{enat})\]
%
(using an ML-like syntax) introduces a type that
models the natural numbers $\const{Z}$, $\const{S}(\const{Z})$, $\const{S}(\const{S}(\const{Z}))$, $\ldots$\afterLdots{},
using Peano notation but extended with an
infinite value $\infty = \const{S}(\const{S}(\const{S}(\ldots)))$.
The equation $\const{S}(\infty) \teq \infty$ holds as expected,
because both sides expand to the infinite term
$\const{S}(\const{S}(\const{S}(\ldots)))$, which uniquely identifies the
value~$\infty$.
Compared
with the conventional inductive definition
\[\keyw{datatype}~\,\ty{enat} \,=\, \const{Z} \,\mid\, \const{S}(\ty{enat}) \,\mid\, \const{Infty}\]
with a dedicated constructor for representing infinity, the codatatype avoids
one case by unifying the finite and infinite nonzero cases.

\nopagebreak

Datatypes and codatatypes are an integral part of modern proof assistants,
including Agda, Coq, Isabelle, Matita, and PVS. In recent years, datatypes
have made their appearance in a few automatic theorem provers. The SMT-LIB~2
\cite{barrett-et-al-2010} syntax, implemented by most SMT (satisfiability
modulo theories) solvers, includes a theory of datatypes.

\pagebreak

In this \thewordpaper, we introduce a unified decision procedure for ground
problems involving datatypes and codatatypes in combination
(Section~\ref{sec:a-ground-decision-procedure-for-co-datatypes})
and discuss extensions  of the procedure for handling quantifiers
(Section~\ref{sec:extension-to-quantified-formulas}).
The procedure is described abstractly as a calculus and is
designed to be composable via the Nelson--Oppen method \cite{nelson-oppen-1979}.
For the datatype case, it follows the lines of Barrett et al.\ \cite{barrett-et-al-2007}.
To our knowledge, our procedure is the first of its kind for the theory of
codatatypes.

Datatypes and codatatypes share many of the same properties, so it makes sense
to consider them together. There are, however, at least three important
differences.

First, \emph{codatatypes need not be well-founded.}
For example, the type
%
\[\keyw{codatatype}~\;\ty{stream}_{\,\tau} \,=\, \const{SCons}(\tau,\: \ty{stream}_{\,\tau})\]
%
of infinite sequences, or streams, over an element type $\tau$ is allowed; the
corresponding datatype would be rejected as non-well-founded \cite{blanchette-et-al-2015-esop}.

Second, \emph{a uniqueness rule replaces the acyclicity rule of datatypes.}
Cyclic constraints such as
$\const{x} \teq \const{S}(\const{x})$ %, where $\const{C}$ is a constructor,
are unsatisfiable for datatypes but satisfiable for codatatypes.
However, the uniqueness principle states that two bisimilar values---i.e., two values
having the same possibly infinite expansion---must be equal; from $\const{x}
\teq \const{S}(\const{y})$ and
$\const{y} \teq \const{S}(\const{x})$, it deduces $\const{x} \teq \const{y}$.
The acyclicity and uniqueness rules are needed to ensure completeness on
ground problems. %and the absence of spurious models.
They cannot be replaced by
finite axiomatizations, so they naturally belong in a decision procedure.
%    * in particular, acyclicity and uniqueness are necessary for some proofs
%%      (and cannot be axiomatized finitely)
%    * and for model finding, without them we quickly get spurious models
%    * explain how finite model finding works
%(For the other (co)datatype properties---the injectivity, distinctness, and
%exhaustiveness of constructors and the selector laws---it is
%widely recognized that decision procedures can be more efficient than
%axiomatizations.)
%axiom.

Third, \emph{it must be possible to express cyclic }(\emph{$\omega$-regular}) \emph{values as closed terms and
to enumerate them.} This is necessary both for finite model finding (modulo theories)
and for theory combinations. The $\mu$-binder notation associates a name with
a (sub)term; it is used to represent cyclic values in the generated models and
in the metatheory. For example,
the $\mu$-term $\const{SCons}(1,\: \MU s.\; \const{SCons}(0,\: \const{SCons}(9,\: s)))$
stands for the lasso-shaped sequence $1, 0, 9, 0, 9, 0, 9, \ldots$\afterLdots.

%%% 1090909 is a prime number


\begin{paper}
Proofs of soundness and completeness are included in the technical report
associated with this paper \cite{our-report}.
\end{paper}%
The procedure is implemented in the SMT solver CVC4 as a combination
of rewriting and a theory solver
(Section~\ref{sec:the-theory-solver}).
%\textbf{TODO: CHECK WITH IMPLEMENTATION, but round to nearest 50 or 1000.}
It consists of about 2000 lines of \cpp{} code, among which 1600 are
shared between datatypes and codatatypes. The code is integrated in the
development version of the solver and is expected to be part of the CVC4~1.5 release.
%
An evaluation on %hand-crafted examples and on
problems generated from Isabelle theories using the Sledgehammer tool
demonstrates the usefulness of the approach (Section~\ref{sec:experimental-results}).

%  * useful both for proving and for model finding

%\ref{sec:examples}

%  * benchmarking is often an issue -- esp. codatatypes
%
%Polymorphic types, nested (co)recursion, and datatype--codatatype mixtures fall

%  * setting: FOL
%    * core procedure is restricted to ground
%      * but theory solver cooperates

%  * codatatypes were added later, motivated by the use of SMT solvers as
%    backends to proof assistants (more specifically, CVC4 to Isabelle/HOL)

%  * setting :
%    * universal formulas
%    * many-sorted logic
%   * mutually (co)recursive types with constructors, selectors, and
%      discriminators

%  * codatatypes: from a theoretical and implementational point of view, like
%      datatypes but:
%    * infinite values (infinitely many nested constructors)
%    * codatatypes are never empty (e.g. finite streams are rejected)

%\[
%      \keyw{codatatype}\; \,\ty{llist} \,=\, \const{LNil} \,\mid\, \const{LCons}(\ty{int},\: \ty{llist})
%\]

%  * consider a natural fragment---datatypes as supported in modern SMT solvers
%    and the SMT-LIB 2 standard, and codatatypes as their duals
%    * mutual recursion, but no polymorphism, nested recursion
%  * integrated with Nelson--Oppen

% * SMT-Lib

%  * one implication is that if $m$ equals $ES(n)$ and $n$ equals $ES(m)$, necessarily
%    $m$ and $n$ must be equal.

%  * perhaps the most commonly used codatatype is that of lazy lists or sequences.
%    using a syntax similar to Standard ML, Haskell, or SMT-LIB

%  * less briefly: codatatypes and why they are useful
%    * in Agda, Coq, Matita -- recently also in Isabelle/HOL \cite{nipkow-et-al-2002}
%    * but not in SMT-LIB 2 \cite{barrett-et-al-2010}

\paragraph{Related Work.}
Although it was written several years ago, the account of related work in
Barrett et al.\ \cite{barrett-et-al-2007} is still a good starting point.
Since then, datatypes have been added to the SMT solver
Z3 in unpublished work by Leonardo de Moura and to a SPASS-like prototype
superposition prover called Pirate by Daniel Wand.
Closely related is the automatic structural
induction in CVC4 by Reynolds and Kuncak \cite{reynolds-kuncak-2015} and in
Pirate by Wand and Weidenbach \cite{wand-weidenbach-201x};
both methods naturally depend on a notion of datatype.

%     * point to Barrett et al. for SMT datatypes
%       * about their own work, they say: "our focus is on generality and
%         efficiency rather than immediacy of implementation"
%       * (deal more directly with finite sorts than Barrett et al., Section 6.1)
%     * SPASS-Pirate
%     * additional ones since then (e.g. strings?)
%     * anything about codatatypes?
%       * proof assistants like Agda, Coq, etc. have them
%       * Dafny, CoALP
%       * also a lot of theoretical research, some of which is loosely connected,
%         e.g. decision procedure for corecursive functions (Henning in Nijmegen)
%
%     * ODDITY: Oppen 1980: single-constructor, recursive -- infinite values?

\paragraph{Conventions.}
The setting is a monomorphic (or many-sorted) first-order logic.
A signature $\Sig = (\Types, \Funcs)$ consists of a set of types $\Types$ and a
set of function symbols $\Funcs$. Types are simply atomic sorts, with no
structure, and interpreted by nonempty domains. The set~$\Types$ must contain a
distinguished type \ty{bool}\begin{report} interpreted as the set of truth
values $\{\bot, \top\}$\end{report}. %, and may contain other interpreted types (e.g., \ty{int}, \ty{real}).
The only predicate is equality ($\teq$)\begin{report} and belongs to the logical symbols\end{report}.
Other predicates can be represented as functions to $\ty{bool}$,
with $\const{p}(\ldots)$ abbreviating $\const{p}(\ldots) \teq \const{true}$.
\begin{report}
The metavariables $\delta,\:\varepsilon$ range over (co)datatypes,
whereas $\tau,\:\upsilon$ range over arbitrary types.
When applied to terms, the symbol $=$ denotes syntactic equality.\end{report}

\begin{report}
Function symbols are written in a sans-serif font (e.g., $\const{f}$, $\const{g}$) to
distinguish them from variables (e.g., $x$, $y$).
\end{report}
Symbols starting with an uppercase letter (e.g.,
$\const{C}, \const{S}$, $\const{SCons}$) are reserved for constructors. With each function symbol \const{f}
is associated a list of argument types $\tau_1,\ldots,\tau_n$ (with $n \ge 0$)
and a return type $\tau$. This connection can be expressed %compactly
as $\const{f} : \tau_1 \times \cdots \times \tau_n \to \tau$\begin{report},
which collapses to $\const{f} : \tau$ if $n = 0$\end{report}.
For a term $t$, the notation $t\typ{\tau}$ indicates that it has type $\tau$.
Functions are invoked in the standard way, with $\const{f}(t_1,\ldots,t_n)$
applying the $n$-ary function symbol
\const{f} to $n$ well-typed arguments $t_1 :\nobreak \tau_1$, \ldots, $t_n :
\tau_n$. Nullary function symbols are called constants and can appear without
parentheses in terms.
\begin{report}%
The operator $\bigwedge_{\,i}\, \varphi_i$ abbeviates a conjunction
$\varphi_1 \mathrel\land \cdots \mathrel\land \varphi_n$. \end{report}%
Finally, $[n]$ denotes the set $\{1,\ldots, n\}$, and
$\bar x$ abbreviates a list or tuple $x_1,\ldots,x_n$.


%* although nothing prevents composing the decision procedure with theories
%  providing polymorphic types (parametric sorts), such as for arrays (e.g., $\ty{array}(\alpha,\beta)$)

\section{%The Theory of
(Co)datatypes}
\label{sec:the-theory-of-co-datatypes}

%    (terminology: freely-generated, inductive, algebraic, ..., sometimes
%    with different meanings; we'll clarify below what we use)

We fix a signature $\Sig = (\Types, \Funcs)$. The types are partioned into
$\Types = \Data \mathrel{\uplus} \Codata \mathrel{\uplus} \Nondata$, where $\Data$ are the
\emph{datatypes}, $\Codata$ are the \emph{codatatypes}, and $\Nondata$ are the %remaining
\emph{ordinary types}. The function symbols are partitioned into $\Funcs = \Ctr
\mathrel{\uplus} \Sel$, where $\Ctr$ are the \emph{constructors} and $\Sel$ are the
\emph{selectors}. There is no need to consider further function symbols
because they can be abstracted away as variables when combining theories.
Exceptionally, it is convenient to use natural number
constants ($0$, $1$, \ldots)\ in examples.

%\paragraph{Specifications.}
In an SMT problem, the signature is normally given by specifying the
uninterpreted types in any order, the (co)datatypes with their constructors
and selectors in groups of mutually (co)recursive groups of (co)datatypes, and
finally any other function symbols.
%
A (co)datatype specification consists of $l$~mutually recursive types which are
either all datatypes or all codatatypes. Polymorphic types, nested
(co)recursion, and datatype--codatatype mixtures fall outside this fragment%
\dotReportFootnote{%
In principle, rank-1 (top-level) polymorphism \cite{blanchette-paskevich-2013}
should not raise any special difficulties. Nesting datatypes inside datatypes,
and likewise for codatatypes, can be reduced to the mutual case
\cite{gunter-1993-not}. So the only genuinely interesting cases missing are
mixed nested (co)recursion as well as
(co)recursion through a non-(co)datatype (both of which make sense
\cite{blanchette-et-al-2014-codata}).}
In the presentation, we allow ourselves some metalevel parameterization
% at the metalevel
through subscripts---for example, $\ty{stream}_{\,\tau}$ denotes a
family of ground types including
$\ty{stream}_{\,\ty{int}}$, $\ty{stream}_{\,\ty{bool}}$,
and \smash{$\ty{stream}_{\,\ty{stream}_{\,\ty{real}}}$}.

\newcommand\elll{\kern.18ex l\kern.11ex}
\newcommand\elllx{\kern.11ex l\kern.18ex}

Each datatype $\delta$ is equipped with
$m \ge 1$ constructors, and each constructor for $\delta$ takes zero or more
arguments and returns a $\delta$ value. The argument types must be either
ordinary, among the already known (co)datatypes, or among the (co)datatypes
being introduced.
%
To every argument corresponds a selector. The names for the (co)data\-types, the
constructors, and the selectors must be distinct and different from
existing names%
\dotReportFootnote{It can be convenient to specify the same selector
for several constructors associated with the same (co)data\-type,
as long as the argument types coincide. % \cite[Section~3]{blanchette-et-al-2014-codata}.
However, this is disallowed by SMT-LIB 2, so we do not consider it here.}
Schematically:
%
\[
\begin{aligned}[t]
\!(\keyw{co})\keyw{datatype}\;\,
  \delta_1 & {}= \smash{\const{C}_{11\!}(\bigl[\const{s}_{11\!}^1{:}\bigr]\vthinspace \tau_{11\!}^1, \ldots, \bigl[\const{s}_{11\!}^{n_{11\!}}{:}\bigr]\vthinspace \tau_{11\!}^{n_{11\!}})} \mid \cdots \mid \smash{\const{C}_{1m_1\!}(\ldots)} \\
   \smash{\vdots\,\,\,} \\[-1\jot]
  \keyw{and}\; \,\delta_{\elllx} & =\, \smash{\const{C}_{\elll 1\!}(\bigl[\const{s}_{\elll 1\!}^1{:}\bigr]\vthinspace \tau_{\elll 1\!}^1, \ldots, \bigl[\const{s}_{\elll 1\!}^{n_{\elll 1\!}}{:}\bigr]\vthinspace \tau_{\elll 1\!}^{n_{\elll 1\!}})} \mid \cdots \mid \smash{\const{C}_{\elll m_{\elllx}\!}(\ldots)}
\end{aligned}
\]
%
with
$\const{C}_{i\negvthinspace j} : \tau_{i\negvthinspace j}^1\times\cdots\times\tau_{i\negvthinspace j}^{\,k_{\smash{i\negvthinspace j}}} \to \delta_i$
and $\const{s}_{i\negvthinspace j}^{\,k} : \delta_i \to \tau_{i\negvthinspace j}^{\,k}$. Defaults are assumed for
the selector names if they are omitted. Given a type $\delta$, its
constructors and selectors are denoted by $\Ctr^\delta$ and $\Sel^\delta$,
respectively.

For types with several constructors, it is customary to provide discriminators
$\const{d}_{i\negvthinspace j} : \delta_i \to \ty{bool}$. However,
it is not necessary to extend the signature:
The discriminator term $\const{d}_{i\negvthinspace j}(x)$ can be seen as an abbreviation for
$x = \const{C}_{i\negvthinspace j}\bigl(\const{s}_{i\negvthinspace j}^1(x), \ldots, \const{s}_{i\negvthinspace j}^{\,n_{\smash{{i\negvthinspace j}}}}(x)\bigr)$.
%This will simplify the presentation. % of the decision procedure.

Here are a few examples of legal specifications of (co)datatype families:
\[\begin{aligned}[t]
      \keyw{codatatype}\; \,\ty{llist}_{\,\tau} & \,=\, \const{LNil} \,\mid\, \const{LCons}(%\const{lhead}{:}\;
      \tau,\: %\const{ltail}{:}\;
      \ty{llist}_{\,\tau}) \\%[-.5\jot]
      \keyw{datatype}\;\, \ty{tree}_{\,\tau} & \,=\, \const{Node}(\tau,\:\, \ty{forest}_{\,\tau}) \\[-\jot]
      \keyw{and}\;\,\, \ty{forest}_{\,\tau} & \,=\, \const{FNil} \,\mid\, \const{FCons}(\ty{tree}_{\,\tau},\:\, \ty{forest}_{\,\tau})
\end{aligned}
\]

\begin{report}%
Because all types must be inhabited (nonempty), a datatype specification is
admissible only if a ground constructor term can be exhibited.
This rules out non-well-founded specifications such as
\[\keyw{datatype}\;\, \ty{fstream}_{\,\tau} \,=\, \const{FSCons}(\tau,\:\, \ty{fstream}_{\,\tau})\]
For codatatypes, no admissibility check is necessary because there is always a term,
finite or infinite, that witnesses nonemptiness \cite{blanchette-et-al-2015-esop}.
\end{report}

A type $\delta$ depends on another type $\varepsilon$ if $\varepsilon$ is the
type of an argument to one of $\delta$'s constructors. Semantically, a set of
types is mutually (co)recursive if and only if the associated dependency graph
is strongly connected. Types can be declared together as mutually
(co)recursive even if they are not actually (co)recursive, but the
semantic notion is more precise and is the one that interests us.
%
In addition, nothing forbids non(co)recursive specifications
such~as
\begin{paper}%
\vthinspace$\keyw{datatype}~\vthinspace\ty{option}_{\,\tau} = \const{None} \mid \const{Some}(\tau)$.%
\end{paper}%
\begin{report}%
\[\begin{aligned}[t]
      \keyw{datatype}\;\, \ty{option}_{\,\tau} & \,=\, \const{None} \mid \const{Some}(\tau) \\[-.5\jot]
      \keyw{codatatype}\; \,\ty{complex} & \,=\, \const{Complex}(\const{re}{:}\; \ty{real},\; \const{im}{:}\;\ty{real})
\end{aligned}
\]
At the semantic level, it makes no difference whether such types are
introduced as datatypes or as codatatypes.
\end{report}%
%Without loss of generality, we consider that these types are datatypes
%instead of codatatypes.

%Given the specification
%
%\[\keyw{codatatype}\;\, \ty{stream} \,=\, \const{SCons}(\ty{int},\:\ty{stream})\]
%
%the infinite value $\const{SCons}(0, \const{SCons}(0, \ldots))$ witnesses
%nonemptiness.

%\paragraph{Characterization.}
One way to define datatypes semantically is as the initial model of the
selector--constructor equations \cite{barrett-et-al-2010}.
\begin{report}
A drawback of this approach is that it does
not naturally account for selectors applied to wrong constructors. Barrett et
al.\ address this by parameterizing the construction by default values, but
this gives rise to spurious equalities between unrelated terms---e.g.,
$\const{s}_{11}(\const{C}_2) \teq \const{s}_{11}(\const{C}_3)$. This flaw
could be corrected, but the added complexity seems to suggest that selectors
are better characterized axiomatically.

\end{report}
A related semantic view of datatypes is as initial algebras. Codatatypes are
then defined dually as final coalgebras \cite{rutten-2000}. The datatypes are
generated by their constructors, whereas the codatatypes are viewed through
their selectors.
%By uniformly focusing on the constructors, the
%axiomatic approach emphasizes the commonality between datatypes and
%codatatypes, while sacrificing a theoretically fruitful notion of duality.

Datatypes and codatatypes share many basic properties pertaining to
constructors and selectors. All properties below are implicitly universally
quantified and range over all $i$, $j$, $\jPrime$, and $k$ within bounds:
% and to all possible splits of the
%$n$-ary constructor $\const{C}_{i\negvthinspace j}$'s argument list into $\bar x,
%y, \bar z$:
%
\[
\begin{aligned}[t]
\text{Distinctness:}\quad
  & %\forall \bar x, \bar y.\;\,
    \smash{\const{C}_{i\negvthinspace j}(\bar x) \tneq \const{C}_{i\negvthinspace \jPrime}(\bar y) \quad\text{if $j \not= \jPrime$}}
  \\[-.5\jot]
\text{Injectivity:}\quad
  & %\forall x_1,\ldots,x_{n_{i\negvthinspace j}} y.\;\,
    \smash{\const{C}_{i\negvthinspace j}(x_1,\ldots,x_{n_{i\negvthinspace j}}) \teq \const{C}_{i\negvthinspace j}(x_1,\ldots,x_{k-1},y,x_{k+1},\ldots,x_{n_{i\negvthinspace j}}) \longrightarrow x_k \teq y}
  \\[-.5\jot]
\text{Exhaustiveness:}\quad
  & \smash{\is{C}_{i1}(x) \mathrel\lor \cdots \mathrel\lor \is{C}_{im_i}(x)}
  \\[-.5\jot]
\text{Selection:}\quad
  & \smash{\const{s}_{i\negvthinspace j}^{\,k}(\const{C}_{i\negvthinspace j}(x_1,\ldots,x_{n_{i\negvthinspace j}})) = x_k}
\end{aligned}
\]
%
\begin{report}%
Expressed in the algebraic jargon, exhaustiveness helps ensure that ``no
junk'' exists, whereas distinctness and injectivity guarantee that ``no
confusion'' can arise.
The result of selectors applied to the wrong
constructor is left completely unspecified.
\end{report}

%  * how to deal with "wrong" selectors, e.g.
%        hd(nil1) = hd(nil2)?
%      * leave them unspecified; hence hd(nil1) = hd(nil2) in some models,
%        and not in other models

Datatypes are additionally characterized by an induction axiom schema\begin{report}:
%
\[
\begin{aligned}[t]
\text{Induction:}\quad
\AXC{\strut$\bigwedge_{\,i,j}\, \forall x_1 \ldots \vthinspace x_{n_{i\negvthinspace j}}.\; \bigl(\bigwedge_{\,k}\, \mathit{IH}_{i\negvthinspace j}^k[x_k]\bigr) \longrightarrow P_i[\const C_{i\negvthinspace j}(x_1,\ldots,x_{n_{ij}})]$}
\UIC{\strut$\bigwedge_{\,i}\, P_i[v_i]$}
\DP
\end{aligned}
\]
where the induction hypothesis $\mathit{IH}_{i\negvthinspace j}^k(x)$
denotes either $P_{\iPrime}(x)$ if there exists some $\iPrime$ such that
the formula is type-correct or else $\top$\end{report}.
%
The axiom schema ensures that the interpretation of datatypes
is a standard model. For example,
for a datatype of natural numbers constructed from $\const{Z}$ and $\const{S}$,
induction prohibits nonstandard models, which could contain cyclic values---e.g.,
an $n$ such that $n \teq \const{S}(n)$---or even infinite acyclic values
$\const{S}(\const{S}(\ldots))$.
%
\begin{report}\par\end{report}
%
For codatatypes, the dual notion is called coinduction. \begin{report}It depends on
witnesses $R_i$ that are required to be bisimulations:
%
\[
\begin{aligned}[t]
\text{Coinduction:}\kern.8em %%% TYPESETTING: should be \quad
\AXC{\strut$\begin{gathered}\textstyle \bigwedge_{\,i}\, R_i[v_i, w_i] \\[-\jot]\textstyle
\bigwedge_{\,i}\, \forall v\; w.\;\, R_i[v, w] \longrightarrow
  \bigwedge_{\,j}\, \const{d}_{\negvthinspace j}(v) \teq \const{d}_{\negvthinspace j}(w)
  \mathrel\land
  \const{d}_{\negvthinspace j}(v) \longrightarrow \bigwedge_{\,k}\, \const{s}_{i\negvthinspace j}^{\,k}(v) \sim \const{s}_{i\negvthinspace j}^{\,k}(w)
\end{gathered}$}
\UIC{\strut$\bigwedge_{\,i}\, v_i \teq w_i$}
\DP
\end{aligned}
\]
where $x \sim y$ denotes either $R_{\iPrime}[x, y]$ if there exists some
$\iPrime$ such that the formula is type-correct or $x \teq y$ otherwise.
\end{report}%
This axiom schema guarantees that two values that yield the same
observations must be equal, where the observations are made by using the
selectors and discriminators.
%
\begin{report}\par\end{report}
  %
In addition, codatatypes are guaranteed to contain all values corresponding to
infinite ground constructor terms.
\begin{report}
In general, this cannot be captured by a
first-order axiomatization, since there may be uncountably many of them.
For example, $\ty{stream}_{\,\ty{int}}$ is isomorphic to the uncountable
function space $\ty{nat} \to \ty{int}$.
\end{report}

%TODO: Andy, introduce theory here. There were some ideas below in the comments
%you might want to mention either here or in Section 3. I'm not sure what's the
%best way to justify it though, but for the conference at least we can just claim it. (we
%won't have the place for a proof anyway).

Given a signature $\Sig$, we write $\thD$ to refer to the \emph{theory} of (co)datatypes,
which in addition to $\Sig$ defines a class of $\Sig$-interpretations $\mathbf{I}$,
namely the ones that satisfy the %axioms --- existence of all infinite codatatype values cannot be axiomatized
properties mentioned in this section.
In particular, this means that each interpretation in~$\mathbf{I}$ has a fixed interpretation
for constructor terms and correctly applied selector terms, but may differ on its interpretation for
wrongly applied selector terms and variables.
A formula $\varphi$ is $\thD$-satisfiable if there exists an interpretation in $\mathbf{I}$ that satisfies $\varphi$;
otherwise, it is $\thD$-unsatisfiable.
\rem{more?}

When looking at the ground theory, induction can be replaced by the acyclicity
axiom schema, which states that any ground constructor term cannot be equal to
a variable it contains \cite{barrett-et-al-2007}. Dually, coinduction can be
replaced by the uniqueness axiom schema, which asserts that (co)recursive
definitions giving rise to the same infinite expansion---e.g., $x \teq
\const{C}(x)$ and $y \teq \const{C}(\const{C}(y))$---must be equal.

\begin{report}
TODO: State more precisely and proof?
\end{report}

%    * :
%        enough to consider acyclicity -- no way to specify infinite objects
%        otherwise

%    * codatatypes:
%      * when looking at the ground theory, enough to
%        consider uniqueness -- no way to express that certain infinite
%        acyclic objects do not exist

%\paragraph{Special Cases.}
Some codatatypes are so degenerate as to have infinite values
even though they are finite. The simplest example is
\vthinspace$\keyw{codatatype}~\ty{a} = \const{A}(\ty{a})$, whose
only value is $\MU a.\; A(a)$. Other specimens are
\begin{paper}%
\vthinspace$\keyw{codatatype}~\ty{b} = \const{B}(\ty{b},\: \ty{c},\: \ty{b},\: \ty{unit})
~\keyw{and}~ \ty{c} = \const{C}(\ty{a},\: \ty{unit},\: \ty{b},\: \ty{c})$,
\end{paper}%
\begin{report}%
\[\begin{aligned}[t]
      \keyw{codatatype}\;\, \ty{b} & \,=\, \const{B}(\ty{b},\: \ty{c},\: \ty{b},\: \ty{unit}) \\[-1\jot]
      \keyw{and}\;\, \ty{c} & \,=\, \const{C}(\ty{a},\: \ty{unit},\: \ty{b},\: \ty{c})
\end{aligned}
\]
\end{report}%
where \ty{unit} is a datatype with the single constructor $\const{Unity} :
\ty{unit}$, as well as $\ty{stream}_{\,\ty{unit}\,}$. We call such types
\emph{corecursive singletons}. For the decision procedure, it will be
important to detect these types. %, even if they rarely arise in practice.
A type may also be a corecursive singleton only in some models. If the example
above is altered to leave \ty{unit} uninterpreted, \ty{b} and \ty{c} will be
singletons precisely when \ty{unit} is interpreted as a singleton.
Fortunately, given cardinalities for the ordinary types, it is easy to
characterize this degenerate case:

% In other words, all finite corecursive codatatypes are corecursive singletons.

\begin{lemma}%[Corecursive Singletons]%
\label{lem:corecursive-singletons}%
\afterDot
Let $\delta$ be a corecursive codatatype. The domain interpreting $\delta$ is
either infinite or a singleton. In the latter case, $\delta$ necessarily has a
single constructor, whose arguments have types that are interpreted as
singletons.
\end{lemma}

\begin{report}
\begin{proof}
By definition, the type is equipped with at least one (directly or indirectly)
corecursive constructor $\const{C}$. If it additional has second
corecursive constructor $\const{D}$, it is possible to encode infinitely many
alternation patterns---e.g.,
$\const{C}(\const{D}(\const{C}(\const{C}(\ldots))))$---all of which correspond
to distinct values (by distinctness and injectivity). If the type has a
noncorecursive constructor $\const{E}$, it is possible to create terms of
arbitrary depths---e.g., $\const{C}(\ldots(\const{C}(\const{E}))\ldots)$. In
both cases, there can be no finite models.

Therefore, $\const{C}$ must be the only constructor.
If any of its noncorecursive arguments has a cardinality greater than 1,
it is possible to encode alternation patterns using it---e.g.,
$\const{C}(0,\: \const{C}(1,\: \const{C}(0,\: \const{C}(0,\: \ldots))))$---which
again excludes finite models. Otherwise, the coinduction principle ensures
that the type has at most one value.
\qed
\end{proof}
\end{report}

%  * assume for simplicity no indirect recursion, but this does not radically
%    change the argument
%  * assume there are at least two values built with C.
%    they must be different at some point, e.g.
%    C(0, C(1, C(0, ...))) and C(0, C(1, C(1, ...)))
%    can use that to create infinitely alternation patterns
%  * leaves us with the case of a single constructor
% * since we are looking at a specific model, we can assume all ordinary
%   types are finite datatypes with nullary constructors corresponding to their
%   elements
% * if two
% * either there is only one ``path'' from ctr to itself
%   or at least two;

\section{The Ground Decision Procedure} % for (Co)datatypes}
\label{sec:a-ground-decision-procedure-for-co-datatypes}

The decision procedure for the ground theory of (co)datatypes $\thD$ determines the
$\thD$-satisfiability of sets of ground constraints over a fixed
signature~$\Sig$. It is formulated as a calculus, whose rules are applied
until saturation or contradiction.
%
The rules operate on a finite set $\Ec$ of equalities and disequalities
between $\Sig$-terms, where $\Ec$ is interpreted as a conjunction.
We write $\tEc$ to denote the set of $\Sig$-terms occurring in $\Ec$.
%We will commonly denote tuples of terms $( t_1, \ldots, t_n )$ in bold font, as $\vec t$.
%We assume that all $\Sig$-terms in $\Ec$ are \emph{normalized}, meaning that all subterms of the form $\const{s}^{\,k}_{\negvthinspace j}( \const{C}_{\negvthinspace j}(t_1,\ldots,t_n) )$
%are simplified to $t_k$. All constraints added to $\Ec$ are also implicitly
%normalized in this manner.

To simplify the presentation, we make the following assumptions about $\Sig$.
First, all codatatypes in $\Codata$ are corecursive. This is not restrictive
because noncorecursive codatatypes can be considered as nonrecursive
datatypes.
Second, all types $\tau \in \Nondata$ have infinite cardinality.
This is not overly restrictive, because each interpreted type $\tau \in \Nondata$
having finite cardinality~$n$
can be replaced by an enumeration datatype with $n$~nullary constructors.
Moreover, since the constraints are ground, they cannot entail an upper bound
on the cardinality of any uninterpreted type $\tau \in \Nondata$; thus,
we may without loss of generality or completeness treat all types in $\Nondata$ as infinite.

The calculus consists of three sets of rules, given in \figuresname~\ref{fig:cc-rules} to
\ref{fig:split-rule}, corresponding to three phases. The first
phase computes the bidirectional closure of $\Ec$. The second phase makes
inferences based on acyclicity (for datatypes) and uniqueness (for
codatatypes). The third phase performs case splitting on constructors for
various terms in $\tEc$.
%Following the conventions from~\cite{},
%The derivation rules are given in \relax{guarded assignment form},
%where
A rule can be applied to $\Ec$ if all the specified preconditions are met.
The conclusion of a rule either describes equalities to be added to $\Ec$
or is $\bot$.
% (in which case we call an application of it \emph{nonterminal})
% (in which case we call an application of it \emph{terminal}).
A rule may have multiple conclusions separated by $\parallel$,
denoting nondeterministic branching. The rules associated with a phase have
priority over those of the subsequent phases. The rules are applied
until a contradiction ($\bot$) is derived or until no rule can be applied to
extend~$\Ec$ further.

%We assume that all $\Sig$-terms in $\Ec$ are \emph{normalized}, meaning that all subterms of the form $\const{s}^{\,k}_{\negvthinspace j}( \const{C}_{\negvthinspace j}(t_1,\ldots,t_n) )$
%are simplified to $t_i$, and moreover assume that all %additional
%constraints added to $\Ec$ are normalized in this manner.
%We present the calculus in three steps.
%In the first step, we compute the bidirectional closure of $\Ec$;
%in the second step, we make inferences based on cyclicity and uniqueness;
%and in the third step, %(when necessary),
%we branch on constructor types for various terms in $\tEc$.
%Following the conventions from~\cite{},
%the derivation rules of our calculus are given in \emph{guarded assignment form},
%where a rule can be applied to $\Ec$ if it meets all of the specified preconditions for $\Ec$.
%The conclusion of a rule either describes equalities to be added to $\Ec$ (in which case we call an application of it \emph{nonterminal}),
%or is $\bot$ (in which case we call an application of it \emph{terminal}).
%A rule may have multiple conclusions separated by $\parallel$, which denotes nondeterministic branching.

\begin{figure}[bth]
\normalsize
\centering
\begin{tabular}{c}
\(
\inferrule{
  t \in \tEc
}{
  \Ec := \Ec,\: t \teq t
}
\)
\rn{Refl}
\qquad
\(
\inferrule{
 t \teq u \in \Ec
}{
 \Ec := \Ec,\: u \teq t
}
\)
\rn{Sym}
\qquad
\(
\inferrule{
  s \teq t,\; t \teq u \in \Ec
}{
  \Ec := \Ec,\: s \teq u
}
\)
\rn{Trans}
\\[5\jot]
\(
\inferrule{
  \vec t \teq \vec u \in \Ec \quad \const f( \vec t \,),\, \const f( \vec u ) \in \tEc
}{
  \Ec := \Ec,\: \const f( \vec t \,) \teq \const f( \vec u )
}
\)
\rn{Cong}
\qquad
\(
\inferrule{
  t \teq u,\; t \tneq u \in \Ec
}{
  \bot
}
\)
\rn{Conflict}
\\[5\jot]
\(
\inferrule{
  \const{C}( \vec t \,) \teq \const{C}( \vec u ) \in \Ec
}{
  \Ec := \Ec,\: \vec t \teq \vec u
}
\)
\rn{Inject}
\qquad
\(
\inferrule{
  \const{C}( \vec t \,) \teq \const{D}( \vec u ) \in \Ec
  \quad
  \const{C} \not= \const{D}
}{
  \bot
}
\)
\rn{Clash}
\end{tabular}
\caption{\,Derivation rules for bidirectional closure%.
}
\label{fig:cc-rules}
\end{figure}

\paragraph{Phase 1: Computing the Bidirectional Closure.}
In conjunction with \rn{Refl}, \rn{Sym}, and \rn{Trans}, the \rn{Cong} rule computes the (upward) congruence closure,
whereas the \rn{Inject} and \rn{Clash} rules together compute (downward) unification.
For unification, additional equalities are inferred based on the injectivity of constructors by \rn{Inject},
and failures to unify equated terms are recognized by \rn{Clash}.
The \rn{Conflict} rule recognizes when an equality and its negation both occur in $\Ec$, in which case $\Ec$ has no model.

At the end of this phase, $\Ec$ induces an equivalence
relation over $\tEc$ such that two terms $t$ and $u$ are equivalent if and
only if $t \teq u \in \Ec$.
Thus, we can regard $\Ec$ as a set of
equivalence classes of terms. For a term $t \in \tEc$, we write $\ec{t}$ to
denote the equivalence class in $\Ec$ that contains $t$.

\begin{figure}[b!]
\normalsize
\centering
\begin{tabular}{c}
\(
\inferrule{
  t\typ{\delta}
  \quad
  \delta \in \Data
  \quad
  %\ttpath{\Ec}{\ec{t}}{\ec{t}} \neq \emptyset
  \Val \ec{t} = \MU x.\; u
  \quad
  x \in \FV( u )
}{
  \bot
}
\)
\rn{Acyclic}
\\[4\jot]
\(
\inferrule{
 t, u\typ{\delta}
 \quad
 \delta \in \Codata
 \quad
 %\tpath{\Ec}{\ec{t}} = \tpath{\Ec}{\ec{u}}\sigma \neq \emptyset
 \Val \ec{t} \aequiv \Val \ec{u}
}{
 \Ec := \Ec,\: t \teq u
}
\)
\rn{Unique}
\end{tabular}
\caption{\,Derivation rules for acyclicity and uniqueness%.
}
\label{fig:ab-rules}
\end{figure}

\paragraph{Phase 2: Applying Acyclicity and Uniqueness.}
%For presentation of the rules in this phase, we rely on a representation of terms in the $\mu$-notation.
The premises of the rules that make up the second phase refer to a mapping $\Val$
that associates a $\mu$-term as representative with each equivalence class.
%Recall that $\mu$-bindings can be used for representing possibly cyclic terms and values.
%(Section~\ref{sec:introduction}).
% for example, $\MU x.\; \const{C}( \const{0}, x )$ represents the cyclic value $\const{C}( \const{0}, \const{C}( \const{0}, \ldots ))$.
A $\mu$-term $t$ of type $\tau$ describes a class of values of
$\tau$ that terms in that equivalence class can take in the models of $\Ec$.
%either in the case when $\tau$ is a codatatype or datatype type,
When $\tau$ is a datatype, % \in \Data$,
a cyclic $t$ describes an infeasible class of values.
%$\tau \not\in \Codata$.

Formally, $\mu$-\emph{terms} are defined recursively as being either a variable $x$
or a node of the form
$\MU x.\: \const{C}( \vec t\, )$ for some constructor $\const{C} \in \Ctr$ and
$\mu$-terms $\vec t$ with the expected types.
The variable $x$ need not occur freely under the binder's body, in which case the
binder will sometimes be omitted in examples.
In the \rn{Acyclic} rule,
$\FV( u )$ denotes the variables occurring freely in $u$.

%%% But there are no constants of type $\tau \in \Nondata$ -- at most variables!
%
%For uniformity, we also consider $%\MU x.\;
%\const{c}$ to be a $\mu$-term if $\const{c}$ is a constant of type $\tau \in \Nondata$.

%%% I think this should be clear enough from the "Conventions" paragraph at the
%%% end of the introduction.
%%
% which we define recursively:
%if $\const{C} : \vec \tau \rightarrow \upsilon$
%and $\vec v$ are well-typed $\mu$-terms of type $\vec \tau$ under the assumption that $x$ has type $\upsilon$,
%then $\MU x.\; \const{C}( \vec v )$ is a well-typed term of type $\upsilon$.

A $\mu$-term is \emph{closed} if %and only if --- by convention, "and only if" is not necessary for *definitions* (but add it back if you disagree)
it contains no free variables. It is \emph{cyclic} if %and only if --- ditto
it contains an occurrence of a bound variable.
The notation $t \aequiv u$, expressing $\alpha$-\emph{equivalence},
indicates that the $\mu$-terms $t$ and $u$
are syntactically equivalent for some capture-avoiding renaming of $\mu$-bound variables---e.g.,
%$\MU x.\; \const{C}( x ) \aequiv \MU y.\; \const{C}( y )$ and
$\MU x.\; \const{D}( y, x ) \aequiv \MU z.\; \const{D}( y, z )$\begin{report},
but
$\MU x.\; \const{C}( x ) \not\aequiv \MU x.\; \const{D}( y, x ) \not\aequiv \MU x.\; \const{D}( z, x )
\not\aequiv \MU y.\; \const{D}( y, x )$\end{report}.
Two $\mu$-terms can represent the same value while not being $\alpha$-equivalent---e.g.,
$\MU x.\; \const{C}( x ) \not\aequiv \MU x.\; \const{C}( \const{C}( x ) )$.
%, or informally are \emph{observationally equivalent}.
%For convienience, we use $\mu$-terms to refer to (classes of) values for both codatatype and datatype terms,
%where in the latter case, a $\mu$-term with a bound variable denotes an infeasible term.
%where the latter case adds the restriction on $\mu$-terms $t$ that no subterms of $t$ contain are bound variables.

The mapping $\Val$ is computed as follows.
%
For each equivalence class $\ec{x}$, we associate a fresh variable ${\Varec{x}}$ of the same type as $x$
%not occurring in $\tEc$,
and set $\Val\ec{x} = {\Varec{x}}$.
Thus, there are initially no constraints on the values for any equivalence class $\ec{x}$.
The mapping $\Val$ is refined by applying the following unfolding rule exhaustively:\strut
\[
\hbox{\(
\inferrule{
  {\Varec{x}} \in \FV( \Val )
  \quad
  \const{C}( t_1, \ldots, t_n ) \in \ec{x}
  \quad
  \const{C} \in \Ctr
}{
  \Val := \Val \{ {\Varec{x}} \mapsto \MU {\Varec{x}}.\; \const{C}( {\Varec{t_1}}, \ldots, {\Varec{t_n}} ) \}
}
\)
%\rn{Unfold}
}
\]
$\FV( \Val )$ denotes the union of the free variables occurring in $\Val$'s range,
and $\Val\{{\Varec{x}} \mapsto \ldots\}$ denotes the corresponding substitution.
It is easy to see that the height of terms produced as a result of the unfolding
is bounded by the number of equivalence classes of $\Ec$,
and thus the construction of $\Val$ will terminate.

\begin{examplex}
Suppose that $\Ec$ contains four distinct equivalence classes $\ec{w}$, $\ec{x}$, $\ec{y}$, and~$\ec{z}$
such that $\const{C}(w,y) \in \ec{x}$ and $\const{C}(z,x) \in \ec{y}$ for some $\const{C} \in \Ctr$.
A possible sequence of unfoldings is given below, omitting
trivial entries such as $\ec{w} \mapsto {\Varec{w}}$.
%
\begin{enumerate}
\item \noindent\rlap{Initially:}\phantom{Unfold $\Varec{x}$:\enskip}$\{  \}$
\item \noindent\rlap{Unfold $\Varec{x}$:}\phantom{Unfold $\Varec{x}$:\enskip}$\{\vthinspace  \ec{x} \mapsto \MU {\Varec{x}}.\; \const{C}( {\Varec{w}},\, {\Varec{y}} ) \vthinspace\}$
\item \noindent\rlap{Unfold $\Varec{y}$:}\phantom{Unfold $\Varec{x}$:\enskip}$\{\vthinspace  \ec{x} \mapsto \MU {\Varec{x}}.\; \const{C}( {\Varec{w}},\; \MU {\Varec{y}}.\; \const{C}( {\Varec{z}},\, {\Varec{x}} ) ),\;
  \ec{y} \mapsto \MU {\Varec{y}}.\; \const{C}( {\Varec{z}},\, {\Varec{x}} ) \vthinspace\}$
\item \noindent\rlap{Unfold $\Varec{x}$:}\phantom{Unfold $\Varec{x}$:\enskip}$\{\vthinspace  \ec{x} \mapsto \MU {\Varec{x}}.\; \const{C}( {\Varec{w}},\; \MU {\Varec{y}}.\; \const{C}( {\Varec{z}},\, {\Varec{x}} ) ),\;
  \ec{y} \mapsto \MU {\Varec{y}}.\; \const{C}( {\Varec{z}},\; \MU {\Varec{x}}.\; \const{C}( {\Varec{w}},\, {\Varec{y}} ) ) \vthinspace\}$
\end{enumerate}
%
The result indicates that the values for $x$ and $y$ in models of $\Ec$
are of the forms $\const{C}( {\Varec{w}},\allowbreak \const{C}( {\Varec{z}},\allowbreak \const{C}( {\Varec{w}},\allowbreak \const{C}( {\Varec{z}},\ldots ))))$
and $\const{C}( {\Varec{z}}, \const{C}( {\Varec{w}}, \const{C}( {\Varec{z}}, \const{C}( {\Varec{w}}, \ldots ))))$,
respectively. %, for some values of ${\Varec{w}}$ and ${\Varec{z}}$.
\xend
\end{examplex}

Given the mapping $\Val$, the \rn{Acyclic} and \rn{Unique} rules can be stated as follows.
For acyclicity, if $\ec{t\typ{\delta}}$ is an equivalence class such that $\delta$ is a datatype and
whose %class of  -- "whose" already refers to "equivalence class"
values $\Val \ec{t} = \MU x.\; u$ are cyclic,
as indicated by the assumption $x \in \FV( u )$,
then $\Ec$ is unsatisfiable.
For uniqueness, if $\ec{t\typ{\delta}}$ and $\ec{u\typ{\delta}}$ are two equivalence classes such
that $\delta$ is a codatatype and
whose %classes of  -- "whose" already refers to "equivalence classes"
values $\Val \ec{t}$ and $\Val \ec{u}$ are $\alpha$-equivalent,
%for a capture-avoiding renaming of $\mu$-bound variables,
then $t \teq u$. This rule may seem too restrictive, since
$\MU x.\; \const{S}(x)$ and $\MU y.\; \const{S}(\const{S}(y))$ denote the same
value despite being $\alpha$-disequivalent, but the construction also works in
such cases, as illustrated by the following example.

%% @ANDY: Minor terminology point:
%% A function symbol can have a "type signature" (but we're trying to avoid that terminology);
%% unless it's a constant, it doesn't have a (first-order) type. So I'm rephrasing.

\begin{examplex}
Let $\const{C} : $ $\tau \times \delta \rightarrow \delta$ be a constructor,
and let $\Ec = \{ x \teq \const{C}(y,\const{C}(y,x)) \}$.
After phase~1, the equivalence classes %of $\Ec$
are
$\{ y \}$, $\{ \const{C}(y,x) \}$, and $\{ x,\, \const{C}(y,\const{C}(y,x)) \}$.
Constructing $\Val$ yields
\[\begin{array}{rcrlrl}
\Val \ec{x} & \,=\, &
\MU {\Varec{x}}. & \const{C}( {\Varec{y}},\, & \smash{\MU {\VAREC{\const{C}(y, x)}}}. & \const{C}( {\Varec{y}},\, {\Varec{x}} ) ) \\
\Val \ec{\const{C}(y,x)} & = &
\MU {\VAREC{\const{C}(y,x)}}. & \const{C}( {\Varec{y}},\, & \MU {\Varec{x}}. & \const{C}( {\Varec{y}},\, {\VAREC{\const{C}(y,x)}} ) )
\end{array}\]
Since $\Val \ec{x} \aequiv \Val \ec{\const{C}(y,x)}$,
%for the renaming
%$\{ {\Varec{x}} \mapsto {\VAREC{\const{C}(y,x)}}, {\VAREC{\const{C}(y,x)}} \mapsto {\Varec{x}} \}$,
the \rn{Unique} rule applies to derive $x \teq \const{C}(y,x)$.
%Intuitively, this equality holds, since the values of $x$ and $\const{C}( y, x )$
%are equivalent for any value of ${\Varec{y}}$.
\xend
\end{examplex}

%%% @ANDY: I explicitly write "|\delta| is finite" instead of "\delta is finite"
%%% to emphasize the dependency on the model. In principle, some types are
%%% interpreted finitely in some models and infinitely in others. In Isabelle,
%%% those wouldn't be considered "finite" types, but they wouldn't be "infinite"
%%% either. (We have Haskell-style type classes for both of these concepts.)
%%% Naturally, thanks to our assumptions at the beginning of Sect. 3, our types
%%% are either finite or infinite.

\begin{figure}[tbh]
\normalsize
\centering
\begin{tabular}{c}
\(
\inferrule{
  t\typ{\delta} \in \tEc
  \quad
  \Ctr^\delta = \{ \const{C}_1, \ldots, \const{C}_m \}
\\
  \bigl( \const s( t ) \in \tEc \text{ and } \const s \in \Sel^\delta \bigr)
  \text{ or }
  \bigl( \delta \in \Data \text{ and } \left|\delta\right| \text{ is finite} \bigr)
}{
  \Ec := \Ec,\: t \teq \const{C}_1\bigl(\const s^1_1( t ), \ldots,\const s^{n_1}_1( t ) \bigr) \ror \cdots \ror \Ec := \Ec,\: t \teq \const{C}_m\bigl(\const s^1_m( t ), \ldots,\const s^{n_m}_m( t ) \bigr)
}
\)
\rn{Split}
\\[5\jot]
\(
\inferrule{
  t, u\typ{\delta} \in \tEc
  \quad
  \delta \in \Codata
  \quad
  \left|\delta\right| = 1
}{
  \Ec := \Ec,\: t \teq u
}
\)
\rn{Single}
\end{tabular}
\caption{\,Derivation rules for branching%.
%All pairs of terms whose type has cardinality 1 are entailed to be equal (the degenerate case).
%Constructors must be assigned for all terms $t$ if has a selector is applied to it, or if $t$ has finite datatype type.
}
\label{fig:split-rule}
\end{figure}

\paragraph{Phase 3: Branching.}
If a selector is applied to a term $t$, or if $t$'s type is a finite datatype,
the equivalence class of $t$ must contain an application of one of
$\delta$'s constructors.
This is enforced in the third phase by the \rn{Split} rule.
A companion rule, \rn{Single}, focuses on the degenerate case where two
terms from $\tEc$ have a corecursive singleton type
(Section~\ref{sec:the-theory-of-co-datatypes}), in which case they must be
equivalent. Both the finiteness assumption on the datatype in \rn{Split} and
the singleton constraint on the codatatype in \rn{Single} can be 
computed statically
based on a recursive computation of the cardinalities of the
constructors' argument types.

\paragraph{Correctness.}
An application of a rule is \emph{redundant} if
at least one branch in the conclusion is an assignment to $\Ec$ that leaves it
unchanged.
A \emph{derivation tree} is a tree whose nodes are finite sets of equalities and
where each non-root node is obtained by
a nonredundant application of a derivation rule to its parent node.
A derivation tree is \emph{closed} if all of its leaf nodes are $\bot$.
A node is \emph{saturated} if no nonredundant instance of a rule can be applied to it.

Correctness means that if there exists a closed derivation tree with root node
$\Ec$, we can conclude that $\Ec$ is $\thD$-unsatisfiable; and if there exists
a derivation tree with root node $\Ec$ that contains a saturated node, we can
conclude that $\Ec$ is $\thD$-satisfiable.

\begin{theorem}[Termination]%
\label{thm:t}%
\afterDot
All derivation trees are finite.
\end{theorem}
\begin{proof}
Consider a derivation tree with root node $\Ec$.
Let $\SSS \subseteq \tEc$ be the set of terms occurring as arguments of selectors.
Let $T \subseteq \tEc$ be the set of terms whose types are finite datatypes.
For each term $t \in T$\negvthinspace,
let
\begin{align*}
\smash{\SSSS 0_t} & = \{ t \}
& \smash{\SSSS {i+1}_t} & = \smash{\SSSS i_t \mathrel\cup \{ \const s( u ) \mid u\typ{\delta} \in \SSSS i{,}~ \delta \in \Data{,}~ \left|\delta\right| \text{ is finite}{,}~ \const{s} \in \Sel^{\delta}}  \}
\end{align*}
%for $i \geq 0$, let ;
and let $\SSSS \AST_t$ be the limit of this sequence.
This is a finite set for each $t$ because the values of the type of $t$ are of finite size.
Let $\SSSS \AST$ be the union of all sets $\SSSS \AST_t$ where $t \in T$,
and let $\tcEc$ be the set of subterms of $\Ec \mathrel\cup \{ \const C_{\negvthinspace j}\bigl( \const s^1_{\negvthinspace j}( t ), \ldots, \const s^{\smash{\,n_{\negvthinspace j}}}_{\negvthinspace j}( t ) \bigr) \mid t\typ{\delta} \in \SSS \mathrel\cup \SSSS \AST{,}~ \const C_{\negvthinspace j} \in \Ctr^\delta \}$.
In a derivation tree with root node~$\Ec$,
it can be shown by case analysis on the rules of the calculus that each non-root node $\Fc$ is such that
$\mathcal{T}(\Fc) \subseteq \tcEc$, and hence contains an equality between two terms from $\tcEc$ not occurring in its parent node.
Thus, the depth of a branch in a derivation tree with root node $\Ec$ is at most $\left| \smash{\tcEc}\vphantom{X} \right|{\!}^2$,
which is finite since $\tcEc$ is finite.
\qed
\end{proof}

\begin{theorem}[Refutation Soundness]%
\label{thm:rs}%
\afterDot
If there exists a closed derivation tree with root node\/ $\Ec$, then\/ $\Ec$ is $\thD$-unsatisfiable.
\end{theorem}
\begin{proof}
The proof is by structural induction on the derivation tree with root node $\Ec$.
If the tree is an application of \rn{Conflict}, \rn{Clash}, or \rn{Acyclic},
then $\Ec$ is $\thD$-unsatisfiable.
For \rn{Conflict}, this is a consequence of equality reasoning.
For \rn{Clash}, this is a consequence of distinctness.
For \rn{Acyclic}, the construction of $\Val$ indicates that the class of values that term~$t$ can take in models of $\Ec$ is infeasible,
and thus $\Ec$ is unsatisfiable.
If the child nodes of $\Ec$ are closed derivation trees
whose root nodes are the result of applying the rule \rn{Split} on $t\typ{\delta}$,
by the induction hypothesis $\Ec \mathrel\cup t \teq \smash{\const C_{\negvthinspace j}\bigl( \const s^1_{\negvthinspace j}( t ), \ldots, \const s^{\,\smash{n_{\negvthinspace j}}}_{\negvthinspace j}( t ) \bigr)}$ is unsatisfiable
for each $\const C_{\negvthinspace j} \in \smash{\Ctr^\delta}$.
Since by exhaustiveness, all models of $\thD$ entail (exactly) one equality $t \teq \const C_{\negvthinspace j}\bigl( \const s^1_{\negvthinspace j}( t ), \ldots, \const s^{\,\smash{n_{\negvthinspace j}}}_{\negvthinspace j}( t ) \bigr)$,
this means $\Ec$ is $\thD$-unsatisfiable.
Otherwise, the child node of $\Ec$ is a closed derivation tree
whose root node is $\Ec \mathrel\cup t \teq u$ obtained by applying one of the rules \rn{Refl}, \rn{Sym}, \rn{Trans}, \rn{Cong}, \rn{Inject}, \rn{Unique}, or \rn{Single}.
In all cases, we have that $\Ec \models_{\thD} t \teq u$.
For \rn{Refl}, \rn{Sym}, \rn{Trans}, \rn{Cong}, this is a consequence of equality reasoning.
For \rn{Inject}, this is a consequence of injectivity.
For \rn{Unique}, our construction of $\Val$ indicates that the value of $t$ and $u$ are equivalent in all models of $\Ec$.
For \rn{Single}, $t$~and~$u$ must have the same value since the cardinality of their type is $1$.
By the induction hypothesis, $\Ec \mathrel\cup t \teq u$ is $\thD$-unsatisfiable
and thus $\Ec$ is $\thD$-unsatisfiable.
\qed
\end{proof}

It remains to show the converse of the previous theorem: When a derivation tree
with root node $\Ec$ contains a saturated node, then $\Ec$ is
$\thD$-satisfiable.
To do so, we exhibit a specific model $\M$ of $\thD$ that satisfies $\Ec$.

First, we define the set of interpretations of the theory $\thD$,
which requires additional terminology concerning $\mu$-terms.
For a $\mu$-term $t$ with subterm $u$,
%%% @ANDY: I'm taking the liberty of renaming "interpretation" to "expansion". Interpretation
%%% sounds semantic to me (although it is sometimes used for syntactic transformations).
the \emph{expansion of $u$ with respect to $t$} is the $\mu$-term $\interp{t}{u}^\emptyset$,
abbreviated to
$\interp{t}{u}$, as returned by the following recursive function:
%where $x \leadsto \MU x.\; \const{C}( \vec u ) \in t$ indicates that $\MU x.\;
%\const{C}( \vec u )$ is the subterm of $t$ that binds this occurrence of
%variable $x$:
\[\begin{array}{r@{}c@{}l}
\interp{t}{x}^B & {} \,=\, {} &
\textstyle\smash{\begin{cases}
    \MU x.\; \const{C}( \interp{t}{ \vec u}^{\smash{B \mathrel\cup \{ x \}}}) & \text{if this $x \notin B$ is
    bound by $\MU x.\; \const{C}( \vec u )$ in $t$}  \\[-\jot]
    x & \text{otherwise}
\end{cases}} ~ \\[1.5ex] %% TYPESETTING: trick with \smash
\interp{t}{\MU x.\; \const{C}( \vec u )}^B & = &
\textstyle\begin{cases}
    \MU x.\; \const{C}( \interp{t}{ \vec u }^{\smash{B \mathrel\cup \{ x \}}} ) & \text{if }x \not\in B \\[-\jot]
    x & \text{otherwise}
\end{cases}
\end{array}\]

The $\mu$-term $u$
is a \emph{self-similar subterm} of~$t$ if
$u$ is a strict subterm of $t$,
$t$ is of the form $\MU x.\; \const{C}( t_1, \ldots, t_n )$,
$u$ it is of the form $\MU y.\; \const{C}( u_1, \ldots, u_n )$,
and $\interp{t}{ t_k } \aequiv \interp{t}{ u_k }$ for all $k \in [n]$.
The term $t$ is \emph{normal} if it does not contain a self-similar subterm
and all of its strict subterms are also normal.
For example, $t = \MU x.\; \const{C}( \MU y.\; \const{C}( y ) )$ is abnormal
because $\MU y.\; \const{C}( y )$ is a self-similar subterm of $t$.
In particular, note that their arguments have the same expansion with respect to $t$,
that is,
$\interp{t}{\MU y.\; \const{C}( y )} =$
$\MU y.\; \const{C}( \interp{t}{y}^{\smash{\{y\}}} ) =$
$\MU y.\; \const{C}( y )$
is $\alpha$-equivalent to
$\interp{t}{y} =$
$\MU y.\; \const{C}( \interp{t}{y}^{\smash{\{y\}}} ) =$
$\MU y.\; \const{C}( y )$.
The term $t = \MU x.\; \const{C}( \MU y.\; \const{C}( x ) )$ is also abnormal,
since $\MU y.\; \const{C}( x )$ is a self-similar subterm of $t$,
noting that
%
\begin{align*}
\interp{t}{\MU y.\; \const{C}( x )}
& = \MU y.\; \const{C}( \interp{t}{x}^{\smash{\{y\}}} ) \\
& = \MU y.\; \const{C}( \interp{t}{\MU x.\; \const{C}( \MU y.\; \const{C}( x ) ) }^{\smash{\{y\}}} ) \\
& = \MU y.\; \const{C}( \MU x.\; \const{C}( \interp{t}{\MU y.\; \const{C}( x )}^{\smash{\{x,y\}}} ) ) \\
& = \MU y.\allowbreak\; \const{C}( \MU x.\allowbreak\; \const{C}( y ) )
\end{align*}
is $\alpha$-equivalent to $\interp{t}{x} = t$.
% for the renaming $\{ x \mapsto y, y \mapsto x \}$.

For any $\mu$-term $t$ of the form $\MU x.\; \const C( \vec u )$, we can
recursively construct its \emph{normal form} $\nf{t}$
by replacing all of the self-similar subterms of $t$ with $x$
%and by replacing all of the abnormal subterms of $t$ with their corresponding normal forms.
and by normalizing the subterms.
For example, $\nf{\MU x.\; \const{C}( \MU y.\; \const{C}( x ) )} = \MU x.\; \const{C}( x )$.

\begin{report}
\begin{lemma}
\label{lem:mu-norm-arg}
If the $\mu$-terms $\vec u$ are in normal form and $t = \nf{\MU x.\; \const{C}( \vec u )} = \MU x.\; \const{C}( \vec w )$,
then $\vec u \vsim \interp{t}{\vec w}$\vthinspace.
\end{lemma}
\begin{proof}
\rem{TODO}
\end{proof}

\begin{lemma}
\label{lem:mu-norm-interp}
If the $\mu$-term $t$ is normal and $u$ is a subterm of $t$, then $\interp{t}{u}$ is normal.
\end{lemma}
\begin{proof}
\rem{TODO}
\end{proof}

%\begin{lemma}
%\label{lem:mu-cong}
%If $t_u = \MU x.\; \const{C}( \vec u )$ and $t_w = \MU y.\; \const{C}( \vec w )$ are in normal form,
%then $\interp{t_u}{ \vec u } \vsim \interp{t_w}{ \vec w }$ if and only if $t_u \vsim t_w$.
%\end{lemma}
%\begin{proof}
%\rem{TODO}
%\end{proof}
\end{report}

We now define the class of interpretations for $\thD$.
$\M( \tau )$ denotes the interpretation type $\tau$ in $\M$,
that is, a set of domain elements for that type.
For a term $t\typ{\tau}$, $\M( t ) \in \M( \tau )$ denotes the interpretation of $t$ in $\M$.
To simplify the presentation, all types are interpreted as sets of $\mu$-terms; but
only values of types in $\Codata$ may contain cycles.
%Since all values of types in $\Data$ and $\Nondata$ are acyclic,
%a typical representation for these values can be obtained by
%dropping each of its $\mu$-bindings. 
%For example, the $\mu$-term $\MU x.\; \const{Z}$ representing the integer constant zero
%is simply $\const{Z}$ after dropping the $\mu$-binding of $x$.

\begin{definition}[Normal Model]
\afterDot%
\label{def:norm-model}%
\rm
A model $\M$ is \emph{normal} if these conditions are met:
\begin{enumerate}
\item
%%% TODO: What does maximal set mean? Does it make sense for \Nondata?
For each type $\tau$,
$\M( \tau )$ is a maximal set of closed normal $\mu$-terms of that type that are
unique up to $\alpha$-equivalence and acyclic when $\tau \not\in \Codata$.
\item
For each constructor term $\const{C}( \vec t \,)$ of type $\tau$,
$\M( \const{C}( \vec t \,) )$ is the value
in $\M( \tau )$ that is $\alpha$-equivalent to
$\nf{\MU x.\; \const{C}( \M( \vec t \,) )}$, where $x$ is fresh.
%%% TODO: I'm a bit worried to see a semantic value \M under a syntactic
%%% constructor. I know our models consist of \mu-terms, but is this intended?
\item
For all selector terms $\const s^k_{\negvthinspace j}( t )$ of type $\tau$, % for some $\vec u$,
$\M\bigl( \const s^k_{\negvthinspace j}( t ) \bigr)$ is the value
in $\M( \tau )$ that is $\alpha$-equivalent to
$\interp{\M( t )}{u_k}$,
assuming $\M( t )$ is of the form $\MU x.\; \const{C}_{\negvthinspace j}( \vec u )$.
\end{enumerate}
\end{definition}

In the following, we consider only normal models.
When constructing a model $\M$ for $\Ec$,
it remains only to define how $\M$ interprets wrongly applied selector terms and variables.
For the latter, this will be based on the mapping $\Val$ constructed in phase~2 of the calculus.
We compute the \emph{completion} $\ValC$ of $\Val$ for normal model $\M$
by assigning values from $\M$ to unassigned variables in the domain of $\Val$.

%First, we need the following definition.
We write $t \vsimv{x} u$ if $\mu$-terms $t$ and $u$ are syntactically equivalent
for some renaming that avoids capturing any variable other than $x$.
For example,
$\MU x.\; \const{D}( x ) \vsimv{y} \MU x.\; \const{D}( y )$,
$\MU x.\; \const{C}( x, x ) \vsimv{x} \MU y.\; \const{C}( x, y )$ and
$\MU x.\; \const{C}( z, x ) \vsimv{z} \MU y.\; \const{C}( z, y )$,
but
$\MU x.\; \const{D}( x ) \not\vsimv{x} \MU x.\; \const{D}( y )$ and
$\MU x.\; \const{C}( x, x ) \not\vsimv{y} \MU y.\; \const{C}( x, y )$.
For a variable $x\typ{\tau}$ and a fixed normal model $\M$,
we write $\mathcal{T}^\M_x( \Val )$ to denote the set consisting of all values $v$ from $\M( \tau )$
such that $v \vsimv{x} \interp{t}{u}$ for some term $t$ with subterm $u$ occurring in the range of $\Val$.

We construct $\ValC$ by exhaustively applying the following rule to $\nf{\Val}$:
\[
\hbox{\(
\inferrule{
  {\Varec{x}}\typ{\tau} \in \FV( \Val )
  \quad
  \MU {\Varec{x}}.\; t \aequiv v
  \quad
  v \in \M( \tau )
  \quad
  v \not\in \mathcal{T}^\M_{\Varec{x}}(\Val)
}{
  \Val := \nf{\Val \{ {\Varec{x}} \mapsto \MU {\Varec{x}}.\; t \}}
}
\)
%\rn{Assign}
}
\]
%
The rule chooses an unassigned variable in $\Val$
and assigns it a value that is not $\alpha$-equivalent to one occurring in $\mathcal{T}^\M_x(\Val)$.
Since this update removes one variable from the set $\FV( \Val )$ and does not add any variables to $\FV( \Val )$,
it can only be applied a finite number of times.
After assigning this value, we normalize all terms in the range of $\Val$.

\begin{examplex}
Let $\delta$ be a codatatype with the constructors $\const{C}, \const{D}, \const{E} :\delta \rightarrow \delta$.
Let $\Ec$ be the set
$\{
w_1 \teq \const{C}( x ),\;
w_2 \teq \const{E}( w_3 ),\;
x \not\teq y_2,\;
y_1 \teq \const{C}( y_2 ),\;
y_2 \teq \const{D}( x ),\;
z_1 \teq \const{E}( z_2 ),\;
z_2 \teq \const{C}( z_1 )
\}$.
After running the calculus to saturation on $\Ec$, the mapping $\Val$ contains
\[\begin{array}{r@{}c@{}l@{\;}l@{\qquad}r@{}c@{}r@{\;}l@{}l@{\;}l}
\Val \ec{w_1} & {}\,=\,{} & \MU {\Varec{w_1}}. & \const{C}( {\Varec{x}} ) &
\Val \ec{y_1} & {}\,=\,{} & \MU {\Varec{y_1}}. & \const{C}( & \MU {\Varec{y_2}}. & \const{D}( {\Varec{x}} ) ) \\
\Val \ec{w_2} & = & \MU {\Varec{w_2}}. & \const{E}( {\Varec{w_3}} ) &
\Val \ec{y_2} & = & \MU {\Varec{y_2}}. & \multicolumn{2}{@{}l@{}}{\const{D}( {\Varec{x}} )} \\
\Val \ec{w_3} & = & {\Varec{w_3}} &&
\Val \ec{z_1} & = & \MU {\Varec{z_1}}. & \const{E}( & \MU {\Varec{z_2}}. & \const{C}( {\Varec{z_1}} ) ) \\
\Val \ec{x} & = & {\Varec{x}} &&
\Val \ec{z_2} & = & \MU {\Varec{z_2}}. & \const{C}( & \MU {\Varec{z_1}}. & \const{E}( {\Varec{z_2}} ) )
\end{array}\]
%
To construct a completion of $\Val$, we must choose values for the free variables of $\Val$,
namely ${\Varec{w_3}}$ and ${\Varec{x}}$.
The content of the set \smash{$\mathcal{T}^\M_{{\Varec{x}}}( \Val )$} is $\alpha$-equivalent to
\[%\begin{array}{c}
\{
\MU x.\; \const{C}( x ),\;
\MU x.\; \const{C}( \const{D}( x )),\;
\const{C}( \MU x.\; \const{D}( x )),\;
\MU x.\; \const{C}( \const{E}( x )),\;
\MU x.\; \const{D}( x ),\;
\MU x.\; \const{E}( \const{C}( x ))
\}
%\end{array}
\]
Consider a model $\M$ that interprets variables in $\Ec$ based on the mapping $\Val$:
$x$ is interpreted as $\Val \ec{x}$, $y_1$ as $\Val \ec{y_1}$, and so on.
Assigning a value for ${\Varec{x}}$ that is $\alpha$-equivalent to a value in $\mathcal{T}^\M_{{\Varec{x}}}( \Val )$
may cause values in the range of $\Val$ to become $\alpha$-equivalent,
which in turn may cause $\M$ to be inconsistent.
For example, assign $\MU {\Varec{x}}.\; \const{D}( {\Varec{x}} )$ for ${\Varec{x}}$.
After this substitution, $\Val \ec{y_2}$ is $\MU {\Varec{y_2}}.\; \const{D}( \MU {\Varec{x}}.\; \const{D}( {\Varec{x}} ) )$,
which has normal form $\MU {\Varec{y_2}}.\; \const{D}( {\Varec{y_2}} )$,
which is $\alpha$-equivalent to $\MU {\Varec{x}}.\; \const{D}( {\Varec{x}} )$.
However, this contradicts the disequality $x \not\teq y_2$ in~$\Ec$.
On the other hand, if the value assigned to ${\Varec{x}}$ is not $\alpha$-equivalent to any term in $\mathcal{T}^\M_{{\Varec{x}}}( \Val )$,
the values in the range of $\Val$ remain $\alpha$-disequivalent.
For example, we may assign values such as 
$\MU {\Varec{x}}.\; \const{E}( {\Varec{x}} )$,
$\MU {\Varec{x}}.\; \const{E}( \MU x_1.\; \const{C}( x_1) )$, or
$\MU {\Varec{x}}.\; \const{D}( \const{C}( {\Varec{x}} ) )$
to ${\Varec{x}}$.
Legal substitutions for ${\Varec{x}}$ may cause the range of $\Val$ to contain abnormal terms.
After applying the substitution for the third term mentioned above,
$\Val \ec{w_1}$ is $\MU {\Varec{w_1}}.\; \const{C}( \MU {\Varec{x}}.\; \const{D}( \const{C}( {\Varec{x}} ) ) )$,
which has normal form
$\MU {\Varec{w_1}}.\; \const{C}( \MU {\Varec{x}}.\; \const{D}( {\Varec{w_1}} ) )$.
\xend
\end{examplex}

%%% TYPESETTING: Evil hack!!
%We first state the following properties of $\ValC$,
In the following lemma about $\ValC$,
$\vphantom{\Bigl(_j}\muvar( t ) = \smash{\begin{cases}
  x & \text{if $t$ is of the form $\MU {x}.\; u$} \\[-\jot]
  t & \text{otherwise.}
\end{cases}}$

%%% @ANDY: I think it's enough to point this out clearly in the introduction.
%%% At least, that always worked fine for my other papers. :)
%
%\begin{paper} 
%The proof of this lemma can be found in the extended version of this paper.
%\end{paper}

\begin{lemma}
\label{lem:model-completion}
If $\Val$ is constructed for a saturated set $\Ec$
and $\ValC$ is a completion of $\Val$ for a normal model $\M$, the following properties hold:
\begin{enumerate}
\item[\rm (1)] $\ValC \ec{x}$ is $\alpha$-equivalent to a value in $\M( \tau )$, where $\ec{x}$ has type $\tau$.
\item[\rm (2)]
$\ValC \ec{x} = \interp{\ValC \ec{y}}{ t }$ for
all subterms $t$ of $\ValC \ec{y}$ with $\muvar(t) = {\Varec{x}}$. 
\item[\rm (3)]
$\ValC \ec{x} \vsim \ValC \ec{y}$ if and only if $\ec{x} = \ec{y}$.
\end{enumerate}
\end{lemma}
\begin{report}
\begin{proof}
To show 1, we first show that $\ValC$ contains no free variables.
Assume by contradiction that $\ValC$ contained a free variable ${\Varec{y}}$ for some $\ec{y}$ of type $\tau$.
Then it must be the case that $\ec{y}$ does not contain a constructor term,
or else ${\Varec{y}}$ would not occur as a free variable in $\Val$.
Consider the case when $\tau$ is finite.
By assumption, $\tau \not\in \Nondata$.
Since \rn{Split} does not apply to $\Ec$, we have $\tau \not\in \Data$.
If $\tau \in \Codata$, then $\tau$ is corecursive by assumption, and by Lemma~\ref{lem:corecursive-singletons},
the cardinality of $\tau$ must be $1$.
Since \rn{Single} does not apply to $\Ec$,
there is only one equivalence class of type $\tau$ in $\Ec$,
and thus there are no terms in $\mathcal{T}^\M_{\Varec{y}}(\ValC)$ of type $\tau$.
This is a contradiction, since our model completion may assign the value in the domain of $\tau$ to ${\Varec{y}}$.
Now, consider the case when $\tau$ is infinite.
This is also a contradiction,
since there are only a finite number of closed terms in $\mathcal{T}^\M_{\Varec{y}}(\ValC)$,
and thus our model completion can assign a value not occurring in $\mathcal{T}^\M_{\Varec{y}}(\ValC)$ to ${\Varec{y}}$.
By construction, $\ValC \ec{x}$ is normal.
Since \rn{Acyclic} does not apply, $\Val \ec{x}$ is acyclic when $\tau \in \Data$.
Moreover, our construction of $\ValC$ applies substitutions of the form
$\{ {\Varec{y}} \mapsto t \}$, where $t$ is acyclic when the type of ${\Varec{y}}$ is not a codatatype.
Thus, $\ValC \ec{x}$ is acyclic when $\tau \not\in \Codata$.
Therefore, by definition, $\ValC \ec{x}$ is $\alpha$-equivalent to a value in $\M( \tau )$.

We first show that 2 and 3 hold initially for $\Val$.
For all equivalence classes $\ec{z}$,
each pair of constructor terms $\const{C}_{\negvthinspace j}( \vec t )$ and $\const{C}_{\negvthinspace\jPrime}( \vec u )$ in $\ec{z}$
are such that $j = \jPrime$ since \rn{Clash} does not apply to $\Ec$,
and are such that $\ec{ \vec t } = \ec{ \vec u }$ since \rn{Inject} does not apply to $\Ec$.
Thus, 
$\Val$ was constructed by applying a sequence of substitutions
where all substitutions for variables ${\Varec{z}}$ 
were uniquely of the form $\{ {\Varec{z}} \mapsto \const{C}_{\negvthinspace j}( {\Varec{t_1}}, \ldots, {\Varec{t_n}} ) \}$
when $\ec{z}$ contains a constructor $\const{C}_{\negvthinspace j}( t_1, \ldots, t_n )$.
Say $\Val \ec{y}$ has a subterm $t$ where $\muvar(t) = {\Varec{x}}$.
Both $\Val \ec{x}$ and the subterm $t$ of $\Val \ec{y}$ were
constructed by applying a sequence of substitutions of the form mentioned above to ${\Varec{x}}$.
Moreover, free variables ${\Varec{z}}$ in $t$ that are bound in $\Val \ec{y}$ are interpreted in 
the expansion of $\interp{\Val \ec{y}}{ t }$ as a term
constructed by a sequence of substitutions of the form mentioned above to ${\Varec{z}}$. \rem{more detail}
Thus, we have
$\interp{\Val \ec{y}}{ t } = \interp{\Val \ec{x}}{ \Val \ec{x} } = \Val \ec{x}$, and thus 2 holds for $\Val$.
Statement 3 holds for $\Val$ since \rn{Unique} does not apply.

We now show that $\Val = \nf{\Val}$.
Assume by contradition $\Val \ec{x} \neq \nf{\Val \ec{x}}$ for some $\Val \ec{x}$ of minimal size.
We have that $\Val \ec{x}$ is of the form $\MU {\Varec{x}}.\; \const{C}( t_1, \ldots, t_n )$.
Due to our construction of $\Val$, 
we know $\ec{x}$ contains a constructor $\const{C}( z_1, \ldots, z_n )$ and $\muvar( t_i ) = z_i$ for $i \in [n]$.
Since $\Val \ec{x}$ is a minimal, it
contains a subterm of the form $\MU {\Varec{y}}.\; \const{C}( u_1, \ldots, u_n )$
where $\interp{\Val \ec{x}}{ t_i } \aequiv \interp{\Val \ec{x} }{ u_i }$ for $i \in [n]$.
Due to our construction of $\Val$, $\ec{y}$ contains a constructor $\const{C}( w_1, \ldots, w_n )$ and $\muvar( u_i ) = w_i$ for $i \in [n]$.
Since \rn{Cong} does not apply to $\Ec$
we have $\ec{w_{\negvthinspace j}}$ and $\ec{z_{\negvthinspace j}}$ are distinct for some $j$.
By (2), $\interp{\Val \ec{x}}{ t_{\negvthinspace j} } = \Val \ec{z_{\negvthinspace j}}$
and $\interp{\Val \ec{x}}{ u_{\negvthinspace j} } = \Val \ec{w_{\negvthinspace j}}$,
which are not $\alpha$-equivalent by (3), contradicting the fact that $\MU {\Varec{y}}.\; \const{C}( u_1, \ldots, u_n )$ is a self-similar subterm of $\Val \ec{x}$.
Thus, $\Val = \nf{\Val}$, and (2) and (3) hold for $\nf{\Val}$.

We now show that if (2) and (3) hold for some $\Val_1$,
they also hold for $\nf{\Val_1 \sigma}$,
where $\sigma$ is a substitution of the form $\{ {\Varec{x}} \mapsto \MU{\Varec{x}}.\; t \}$,
${\Varec{x}} \in FV( \Val_1 )$,
and $\MU {\Varec{x}}.\; t$ is not $\alpha$-equivalent to a term in $\mathcal{T}^\M_{\Varec{x}}(\Val_1)$.
To show 2,
by assumption of 2 on $\Val_1$, we have $\interp{\Val_1 \ec{y}}{ u } = \Val_1 \ec{x}$ for
all subterms $u$ of $\Val_1 \ec{y}$ where $\muvar(t) = {\Varec{x}}$.
Thus, $\interp{\Val_1 \sigma \ec{y}}{ u } = \Val_1 \sigma \ec{x}$ and
$\interp{\nf{\Val_1 \sigma} \ec{y}}{ u } = \nf{\Val_1 \sigma} \ec{x}$.
To show 3, 
consider two distinct equivalence classes $\ec{y}$ and $\ec{z}$,
and assume by contradiction that $\nf{\Val_1 \sigma} \ec{y} \aequiv \nf{\Val_1 \sigma} \ec{z}$.
Due to (3) for $\Val_1$,
$\ec{y}$ and $\ec{z}$ must have (minimal) subterms 
where $t_1$ occurs in $\Val_1 \ec{y}$ the same position (call it $p$) as $t_2$ occurs in $\Val_1 \ec{z}$,
and $t_1 \not\aequiv t_2$.
%We first show that $\nf{\Val_1 \sigma} \ec{y}$ (and for the same reasons, $\nf{\Val_1 \sigma} \ec{z}$)
%also contains position $p$.
%If this were not the case,
%then without loss of generality we may assume
%$\Val_1 \sigma \ec{y}$ contains a self-similar subterm 
%$\MU {\Varec{w}}.\; u$ that strictly contains $t_1 \sigma$.
If $t_1$ (resp. $t_2$) is a free variable that is not ${\Varec{x}}$,
then $\nf{\Val_1 \sigma} \ec{y}$ (resp. $\nf{\Val_1 \sigma} \ec{z}$)
contains $t_1$ (resp. $t_2$) at position $p$,
and $\nf{\Val_1 \sigma} \ec{z}$ (resp. $\nf{\Val_1 \sigma} \ec{y}$) does not.
If $t_1$ is of the form $\MU w_1.\; \const{C}( \vec t )$ 
and $t_2$ is of the form $\MU w_2.\; \const{D}( \vec u )$,
then the expansion \rem{define} of $\nf{\Val_1 \sigma} \ec{y}$ and $\nf{\Val_1 \sigma} \ec{z}$
are $\alpha$-disequivalent at position $p$.
Since $t_1$ and $t_2$ are minimal,
say $t_1$ is of the form $\MU w.\; \const{C}( \vec t )$,
and $t_2$ is ${\Varec{x}}$.
Since $\sigma$ maps ${\Varec{x}}$ to a closed $\mu$-term $\MU {\Varec{x}}.\; t$,
we have that $FV( t_1 ) \subseteq \{ {\Varec{x}} \}$,
or else the expansion of $\nf{\Val_1 \sigma} \ec{y}$ and $\nf{\Val_1 \sigma} \ec{z}$
are $\alpha$-disequivalent at position $p$ since they do not contain the same free variables.
Since $\interp{\Val_1 \ec{y}}{t_1}$ is normal,
there is a closed $\mu$-term $v \in \mathcal{T}^\M_{\Varec{x}}( \Val_1 )$
such that $v \vsimv{\Varec{x}} \interp{\Val_1 \ec{y}}{t_1}$.
Thus, by assumption on our selection of $\MU {\Varec{x}}.\; t$,
we have $\MU {\Varec{x}}.\; t \not\vsimv{\Varec{x}} \interp{\Val_1 \ec{y}}{t_1}$,
which implies that the expansion of $\nf{\Val_1 \sigma} \ec{y}$ and $\nf{\Val_1 \sigma} \ec{z}$
are $\alpha$-disequivalent at position $p$. \rem{more detail}

Thus, by induction on the number of applications of the above rule used to obtain $\ValC$,
we have that $\ValC$ satisfies (2) and (3).
\qed
\end{proof}
\end{report}

\begin{theorem}[Solution Soundness]%
\label{thm:ss}%
\afterDot
If there exists a derivation tree with root node $\Ec$ containing a saturated node, then $\Ec$ is $\thD$-satisfiable.
\end{theorem}
\begin{proof}
Let $\Fc$ be a saturated node in a derivation tree with root node $\Ec$.
%We will construct a model $\M$ for a set of equalities $\Fc$ that is equivalent to $\Fc_0$, and where
%all equivalence classes of $\Fc$ contain at least one variable, and all selectors in $\Fc$ are applied to variables only.
%The former comes with no loss of generality since new equalities of the form $y \teq t$ for fresh variable $y$ can be added to $\Fc$ without affecting its satisfiability,
%The latter also comes with no loss of generality since nested applications of selectors in $\Fc_0$ can be replaced by fresh variables while adding equalities to $\Fc$.
We consider a normal model $\M$
that interprets wrongly applied selectors based on equality information in $\Fc$,
and interprets the variables of $\Fc$ based on the completion $\ValC$ of the mapping $\Val$ from phase~2.
For the latter, let $\M( x )$ be the value in $\M$ that is $\alpha$-equivalent with $\ValC \ec{x}$ for each variable $x \in \mathcal{T}(\Fc)$.

We first show $\M$ satisfies all equalities in $t_1 \teq t_2 \in \Fc$, where $t_1$ and $t_2$ have type $\tau$.
We show,
by structural induction on $t$,
that $\M( t ) \aequiv \ValC \ec{t}$ for all terms $t \in \mathcal{T}( \Fc )$,
which since $\M$ is normal, implies $\M \models t_1 \teq t_2$.

If $t$ is a variable, then $\M( t ) \vsim \ValC \ec{ t }$ by construction.

If $t$ is a constructor term of the form $\const{C}( u_1, \ldots, u_n )$,
then $\M( t )$ is $\alpha$-equivalent with $\nf{\MU x.\; \const{C}( \M( u_1 ), \ldots, \M( u_n ) ) }$ for some fresh $x$,
which by the induction hypothesis is $\alpha$-equivalent with $\nf{\MU x.\; \const{C}( \ValC \ec{ u_1 }, \ldots, \ValC \ec{ u_n } )}$, call this term $t_u$.
%By Lemma~\ref{lem:model-completion}\PART{2} and due to our construction of $\ValC$, we have $\ValC \ec{t}$ is a term
%of the form $\MU {\Varec{t}}.\; \const{C}( w_1, \ldots, w_n )$
%where $\interp{\ValC \ec{t}}{w_i} = \ValC \ec{u_i}$ for $i \in [n]$.
Since \rn{Inject} and \rn{Clash} do not apply to $\Fc$, 
by our construction of $\ValC$ we have $\ValC \ec{t}$ is a term
of the form $\MU {\Varec{t}}.\; \const{C}( w_1, \ldots, w_n )$ 
where for each $i \in [n]$, 
$\muvar(w_i) = {\Varec{u_i}}$ and thus by Lemma~\ref{lem:model-completion}\PART{2}, 
$\interp{\ValC \ec{t}}{w_i} = \ValC \ec{u_i}$.
For each $i \in [n]$, let $u_\iPrime$ be the $i$\vvthinspace th argument of $t_u$.
By Lemma~\ref{lem:mu-norm-arg}, $\interp{t_u}{u_\iPrime} \vsim \ValC \ec{u_i}$.
Thus $\interp{t_u}{u_\iPrime} \vsim \interp{\ValC \ec{t}}{ w_i }$. % for each $i \in [n]$.
%By Lemma~\ref{lem:mu-cong}, we have $t_u \vsim t_w$.
Thus, $\M( t ) \vsim t_u \vsim \ValC \ec{t}$, and
we have $\M( t ) \vsim \ValC \ec{t}$.

If $t$ is a selector term of the form $\const s^k_{\negvthinspace j}( u )$,
since \rn{Split} does not apply to $\Fc$,
$\ec{u}$ must contain a term of the form $\const C_{\negvthinspace\jPrime}\bigl( \const s^1_{\negvthinspace\jPrime}( u ), \ldots, \const s^{n}_{\negvthinspace\jPrime}( u ) \bigr)$ for some $\jPrime$.
%By Lemma~\ref{lem:model-completion}\PART{2} and due to our construction of $\ValC$, we have $\ValC \ec{u}$ is of the form
%$\MU {\Varec{u}}.\; \const C_{\negvthinspace\jPrime}( w_1, \ldots, w_n )$,
%where $\interp{\ValC \ec{u} }{ w_i } = \ValC \ec{ \const s^i_{\negvthinspace\jPrime}( u )}$ for $i \in [n]$. 
Since \rn{Inject} and \rn{Clash} do not apply to $\Fc$, 
by construction $\ValC$ must be of the form
$\MU {\Varec{u}}.\; \const C_{\negvthinspace\jPrime}( w_1, \ldots, w_n )$,
where for each $i \in [n]$,
$\muvar(w_i) = \smash{\Varec{\vphantom{I}\smash{\const s^i_{\negvthinspace\jPrime}( u )}}}$ and thus by Lemma~\ref{lem:model-completion}\PART{2}, 
$\interp{\ValC \ec{u}}{ w_i } = \ValC \ec{ \smash{\const s^i_{\negvthinspace\jPrime}( u )}}$. 
If $j = \jPrime$, then $\M( t )$ is $\alpha$-equivalent with $\interp{\ValC \ec{u}}{w_k}$, which is equal to $\ValC \ec{ \smash{ \const s^k_{\negvthinspace j}( u )}}$,
which is $\ValC \ec{t}$.
If $j \neq \jPrime$, we are free to interpret $\smash{\const s^k_{\negvthinspace j}( \M( u ) )}$ as the value in $\M( \tau )$ that is $\alpha$-equivalent with $\ValC \ec{ t }$.
Since \rn{Cong} does not apply and due to Lemma~\ref{lem:model-completion}\PART{3},
pairs of wrongly applied selectors are assigned the same value if and only if they reside in the same equivalence class,
and thus this definition is well-defined.

We now show that all disequalities in $\Fc$ are satisfied by $\M$.
Say $t_1 \tneq t_2 \in \Fc$.
Since \rn{Conflict} does not apply, $t_1 \teq t_2 \not\in \Fc$ and thus $\ec{t_1}$ and $\ec{t_2}$ are distinct.
Since $\M( t_1 ) \vsim \ValC \ec{t_1}$ and $\M( t_2 ) \vsim \ValC \ec{t_2}$,
by Lemma~\ref{lem:model-completion}\PART{3}, $\M( t_1 ) \neq \M( t_2 )$, and thus $\M \models t_1 \tneq t_2$.

Since by assumption $\Fc$ contains only equalities and disequalities, we have $\M \models \Fc$,
and since $\Fc$ is a superset of $\Ec$, we have that $\Ec$ is satisfied by $\M$.
\qed
\end{proof}

By Theorems~\ref{thm:t},~\ref{thm:rs}, and~\ref{thm:ss}, the calculus is sound and complete for $\thD$.

\section{Extension to Quantified Formulas}
\label{sec:extension-to-quantified-formulas}

  * universal conjecture is no problem:
    * falls into the ground fragment via negation
      and skolemization
  * nor is existential axiom a problem
  * what's interesting: universal axioms and existential conjectures

Blah.

\section{Implementation as a Theory Solver in CVC4}
\label{sec:the-theory-solver}

This section describes how the calculus in Section~\ref{sec:a-ground-decision-procedure-for-co-datatypes} is implemented within the SMT solver CVC4.

\paragraph{Optimizations.}
We first discuss several optimizations that are not reflected in the presentation of the calculus, which closely follow the approach outlined by Barrett et al.\ \cite{barrett-et-al-2007}.
We only briefly mention these optimizations, since each applies to datatypes as well as codatatypes, and most have been presented thoroughly in Barrett et al.

Discriminators are treated as predicate symbols, so a discriminator $\const{d}_{\negvthinspace j}( t )$ is such that $\const{d}_{\negvthinspace j}$
is a predicate symbol, instead of reducing this constraint to $t \teq \const{C}_{\negvthinspace j}\bigl( \const s^1_{\negvthinspace j}( t ), \ldots, \const s^n_{\negvthinspace j}( t ) \bigr)$.
We have found that this leads to better performance since this reduction introduces terms more eagerly to $\tEc$.
Handling discriminators requires extending the decision procedure with several
additional rules (see~Barrett et al.\ \cite{barrett-et-al-2007} for more
details), which apply uniformly to both datatypes and codatatypes.
Also, selectors are collapsed eagerly:
if $\const s^k_{\negvthinspace j}( t )$ is a term in $\tEc$ and $t$ contains the constructor
$\const{C}_{\negvthinspace j}( \vec u )$, we immediately infer $\const s^k_{\negvthinspace j}( t ) \teq u_k$, whereas the calculus we presented would apply \rn{Split} and \rn{Inject} before inferring this equality.
For the sake of reducing the number of unique constraints considered by the calculus, we compute a normal form for constraints as a preprocessing step.
In particular, we
replace $t \teq s$ by $s \teq t$ if $s$ is less than $t$ based on a term ordering,
replace $\const{C}_{\negvthinspace j}( \vec t ) \teq \const{C}_{\negvthinspace\jPrime}( \vec u )$ with $\bot$ when $j \neq \jPrime$,
replace all selector terms of the form $\const{s}^{\,k}_{\negvthinspace j}( \const{C}_{\negvthinspace j}(t_1,\ldots,t_n) )$ by $t_k$,
and replace all occurrences of discriminators $\const{d}_{\negvthinspace j}( \const{C}_{\negvthinspace\jPrime}( \vec t ) )$ by $\top$ if $j = \jPrime$ and $\bot$ otherwise.

\paragraph{Integration into DPLL(T).}
The calculus is implemented as \emph{theory solver} of CVC4,
that is, a specialized solver for determining the satisfiability of conjunctions of constraints for its theory.
Given a theory $T = T_1 \mathrel\cup \ldots T_n$ and a input set of clauses $F$ in CNF,
the DPLL($T$) \rem{CDCL($T$)?} procedure
(incrementally) builds partial assignments from the atomic formulas of $F$ to truth values such that no clause in $F$ is falsified.
We may interpret this partial assignment as a set of literals where $a \in M$ for all atoms $a$ that it assigned the value $\top$, and $\neg a \in M$ for all atoms that it assigns the value $\bot$.
Then, at a high level, by the Nelson--Oppen combination framework,
each $T_i$-solver for $i = 1, \ldots, l$ takes as input a combination of (1) the purified form of $T_i$-constraints occurring in $M$ where terms containing symbols not belonging to $T_i$ are replaced by fresh variables of the same type,
(2) additional equalities and disequalities between variables of types not belonging to $T_i$.
Let us call this set $M_i$.
Each $T_i$ solver either
reports that a subset $C$ of $M_i$ is $T_i$-unsatisfiable, in which case $\neg C$ is added to $F$,
adds a clause $C$ to $F$,
or does nothing.
When $M$ is a complete assignment for $F$, a theory solver can only choose to do nothing when $M_i$ is indeed $T_i$-satisfiable.

Assume $\Ec$ is initially the set $M_i$ described above.
For each equality added to $\Ec$, we associate a set of equalities from $M_i$ that together entail $t \teq s$,
which we call its \emph{explanation}.
Similarly, each $\Val \ec{x}$ is also associated an explanation, that is,
a set of equalities from $M_i$ that entail that the values of $\ec{x}$ in models of $\Ec$ are of the form $\Val \ec{x}$.
For example, if $x \teq \const{C}( x ) \in M_i$, then $x \teq \const{C}( x )$ is a (possible) explanation for $\Val \ec{x} = \MU {\Varec{x}}.\; \const{C}( {\Varec{x}} )$.
Thus, the rules of the calculus are implemented as follows.
For all rules with conclusion $\bot$,
we report the union of the explanations for all premises is $\thD$-unsatisfiable.
For the \rn{Split} rule, we add a clause of the form
$\const{C}_1\bigl( \const s^1_1( t ), \ldots, \const s^{n_1}_1( t ) \bigr) \mathrel\lor \cdots \mathrel\lor t \teq \const{C}_m\bigl( \const s^1_m( t ), \ldots, \const s^{n_m}_m( t ) \bigr)$
to $F$.
Decisions on which branch to take are thus performed externally by the SAT solver, and not by the theory solver.
All other rules add equalities to the internal state of the theory solver.
The rules in phase~1 (along with the optimization for collapsing selectors) and the \rn{Single} rule are performed eagerly,
that is for partial satisfying assignments $M$, while the rules in phase~2 and the \rn{Split} rule are performed only for complete satisfying assignments $M$,
and in that order.

    * sharing is caring (let's cite it for a change)
    * theory combination more complicated (and Theorem Completeness too weak)


%\section{Examples}
%\label{sec:examples}

\section{Evaluation on Isabelle Problems}
\label{sec:experimental-results}

\newcommand\gandl{G\&L}
\newcommand\HD[1]{\hbox to2.5em{\hfill#1\hfill}}

\begin{table*}[tbh!]
\normalsize
\begin{center}\begin{tabular}{l@{\kern1.5em}c@{\kern.5em}c@{\kern.5em}c@{\kern1.5em}c}
  & \HD{Distro} & \HD{AFP} & \HD{\gandl} & All
\MIDRULE
No (co)datatypes
  & 221 & 760 & \phantom{0}55 & 1036 \\[\jot]
%Datatype simplication only
%  &  \\
Datatypes without acyclicity
  & 227 & 765 & \phantom{0}55 & 1047 \\
Datatypes with acyclicity
  & 227 & 771 & \phantom{0}55 & 1053 \\[\jot]
%Codatatype simplication only
%  &  \\
Codatatypes without uniqueness
  & 222 & 789 & \phantom{0}56 & 1067 \\
Codatatypes with uniqueness
  & 223 & 789 & \bfseries \phantom{0}59 & 1071 \\[\jot]
Full (co)datatypes
  & \bfseries 229 & \bfseries 800 & \bfseries \phantom{0}59 & \bfseries 1088 \\[\jot]
Total number of goals
  & 879 & 2974\phantom{0} & 317 & 4170
\end{tabular}\end{center}
\caption{\,Number of solved goals for the three benchmark suites}
\label{tab:bench}
\end{table*}

To evaluate the decision procedure, we generated problems from existing
Isabelle formalizations using Sledgehammer \cite{paulson-blanchette-2010}.
Codatatypes being a recent addition to Isabelle
\cite{blanchette-et-al-2014-impl}, benchmarks are somewhat hard to come by. We
included the theory files from the Isabelle distribution (Distro) and the \emph{Archive
of Formal Proofs} (AFP) \cite{klein-et-al-afp} that define codatatypes falling
within the supported fragment. We also included two unpublished theories by
Peter Gammie and Andreas Lochbihler (\gandl), about Bird and Stern--Brocot trees.
To also exercise the the support
for datatypes, the benchmarks are complemented by theories about various list
and tree data structures. The theory files were selected before running the
experiments. The experimental data is publicly available \cite{our-eval-data}.

For each goal in each theory file, Sledgehammer was invoked to select
256~lemmas as axioms, which were then monomorphized and translated to SMT-LIB
along with the goal \cite{boehme-2012-phd}. The resulting problem was given to
CVC4, running for up to \textbf{TODO: XXX} seconds on the StarExec cluster
\cite{stump-et-al-2014-starexec}. Problems involving no (co)datatypes were
filtered out. Due to the lack of machinery for reconstructing inferences about
(co)datatypes in Isabelle, CVC4 is trusted as an oracle in these experiments.

CVC4 was run on each problem several times, with the support for datatypes and
codatatypes either enabled or disabled. The contributions of the acyclicity and
uniqueness rules were also measured, so find out whether these somewhat
expensive rules are useful in practice. Even when the decision procedure is
disabled, some of the generated axioms typically include basic properties of
constructors and selectors, which the decision procedure would recognize as
tautologies.
%This allows us to answer the question, \relax{What are the
%benefits of activating the decision procedure as opposed to letting
%Sledgehammer do what it would normally do?}

\newcommand\BAD[1]{\textcolor{red}{\textbf{#1}}}

%  * experience with such features is not extremely high -- e.g. arithmetic,
%    a most useful theory on lots of benchmarks, increases Sledgehammer's
%    success rate by 2 percentage points, or 4\%, with Z3 in earlier work \cite{xxx}

%  * so when analyzing statistics of this kind, with highly varied problems,
%    we must not overestimate the importance of a single trick
%  * on the other hand: every percentage point counts! cite Tom Hales

The results are summarized in Table~\ref{tab:bench}. The decision procedure
makes a difference across all theories, and an overall difference of
\BAD{4.7\%}. Moreover, every aspect of the procedure, including the more
expensive rules, make a contribution. \textbf{NOT TRUE}: What is not visible in the table, but
readily available when looking at the raw data \cite{our-eval-data}, is that
the stronger decision procedures subsume the weaker ones. In the context of
Sledgehammer, the power of interpreted (co)datatypes is roughly
comparable to that of arithmetic \cite{blanchette-et-al-2013-smt}.

%* and finally, we look in more detail at one or two such proofs, by presenting
%  it and explaining it (and, before that, understanding it)

Among the four uniqueness proofs, three corresponded to one-line
proofs in Isabelle, of the form \keyw{by}~\textit{coinduction}~\textit{auto}
\cite{blanchette-et-al-2014-impl}. The fourth proof was somewhat more elaborate:
%
\begin{quote}
\keyw{lemma} \,\textit{X0\_unique}: \,$x = \const{Node}\;0\;\const{num}\; x \Longrightarrow x = \const{X0}$ \\
\keyw{proof} \,(\textit{coinduction arbitrary}: $x$ \textit{rule}: \textit{tree.coinduct\_strong}) \\
\noindent\hbox{}\quad  \keyw{case} (\textit{Eq\_tree} $x$) \keyw{show} \textit{?case} \\
\noindent\hbox{}\qquad  \keyw{by} (\textit{subst} (1 2 3 4) \textit{Eq\_tree}) (\textit{simp add}: \textit{eqTrueI}[OF \textit{Eq\_tree}]) \\
\keyw{qed}
\end{quote}
%
\noindent
where \const{X0} is defined as $\const{X0} =
\const{Node}\;0\;\const{num}\;\const{X0}$.

\section{Conclusion}
\label{sec:conclusion}

We introduced a decision procedure for the ground theory of datatypes and
codatatypes and implemented it in the SMT solver CVC4. Our main
contribution has been the support for codatatypes. Both the metatheory and
the implementation rely heavily on $\mu$-terms to represent cyclic values,
a complication specific to codatatypes.
% are not very
% difficult per se, but there are tricky corner cases to take care of if we care
% about completeness (which we do).
%% alliteration
On the practical side, we obtained respectable results on Isabelle benchmarks.

This work is part of a larger program that aims at enriching automatic provers
with high-level features and at reducing the gap between automatic and
interactive theorem proving. As future work, we want to implement proof
reconstruction for CVC4's (co)datatype inferences in Isabelle. We also want to
try out CVC4 for higher-order model finding in Isabelle, as an alternative to
the counterexample generator Nitpick \cite{blanchette-nipkow-2010}. We
see some opportunities to enrich SMT solvers with recursive and corecursive
functions. Finally, it might be possible to go further in terms of supporting
nested and mixed (co)recursion and quantified formulas over (co)datatypes in
solvers.

\def\ackname{Acknowledgment}
\paragraph{\ackname.}
We owe a great debt to Clark Barrett and Cesare Tinelli for datatype case blah
blah blah. \textbf{TODO FIXME}
Morgan Deters?
%
Our present and former bosses, Viktor Kuncak, Stephan Merz, Tobias Nipkow,
Cesare Tinelli, and Christoph Weidenbach, have either encouraged the research on
codatatype or at least endured
%tolerated?
it, both of which we are thankful for.
%
Peter Gammie and Andreas Lochbihler shared their private
theories with us so we could include them in the benchmarks.
Andrei Popescu helped clarify our thoughts regarding the axiomatization of
codatatypes. Dmitriy Traytel took part in discussions about degenerate
codatatypes.
%
Blanchette's research was partially supported by the Deutsche
Forschungs\-gemein\-schaft (DFG) project
\relax{Hardening the Hammer} (grant Ni\,491\slash 14-1).

\bibliographystyle{splncs03}
\bibliography{bib}{}

\end{document}
