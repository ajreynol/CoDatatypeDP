\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{arydshln}
\usepackage[scaled=.82]{beramono}
\usepackage{booktabs}
\usepackage{bussproofs}
\usepackage{calc}
\usepackage{cite}
\usepackage{mathptmx}
%\usepackage{txfonts}
%\usepackage{mathrsfs}
%\usepackage{pifont}
%\usepackage{smallcap}
\usepackage{mathpartir}
\usepackage{stmaryrd}
\usepackage{subfigure}
\usepackage[usenames]{color}
%\usepackage{graphicx}
%\usepackage{newcent}
\usepackage{textcomp}
%\usepackage{tipa}
\usepackage{units}
\usepackage{url}
\usepackage[all]{xy}

\makeatletter
\def\spnXwtheorem#1#2#3#4{\@spynthm{#1}{#2}{#3}{#4}%
                         \@addtoreset{#1}{chapter}}%
\makeatother

\newcommand\MU{\vvthinspace\mu\vvthinspace}

%%% not part of shared counter
\spnXwtheorem{examplex}{Example}{\itshape}{\rmfamily}

\newcommand\MIDRULE{
\\[-1pt] %%% TYPESETTING HACK
\midrule
%$\enatT$
\\[-11pt] %%% TYPESETTING HACK
}

\def\thewordpaper{paper}
\newcommand\dotReportFootnote[1]{.}

\newcommand\FV{\mathrm{FV}}

\newcommand\afterDot{\;} %%% Too little space by default after "Lemma Foo."

\begin{report}
\def\thewordpaper{report}
\renewcommand\dotReportFootnote[1]{.\footnote{#1}}
\end{report}

\newcommand\afterLdots{\kern.1em} %% TYPESETTING

% for "bussproofs" package
\EnableBpAbbreviations
\def\ScoreOverhang{1.5pt}
\def\proofSkipAmount{\vskip 0pt}
\def\defaultHypSeparation{\hskip0.75em}

\DeclareFontFamily{OT1}{pzc}{}
\DeclareFontShape{OT1}{pzc}{m}{it}{<-> s * [1.10] pzcmi7t}{}
\DeclareMathAlphabet{\mathscr}{OT1}{pzc}{m}{it}

\DeclareMathAlphabet{\mathcal}{OT1}{pzc}{m}{it}

\let\labelitemi=\labelitemii %% CHEAT!

\newcommand\cpp{C\nobreak\raisebox{.05ex}{+}\nobreak\raisebox{.05ex}{+}}

\newcommand\iPrime{i\vthinspace'\negvthinspace}
\newcommand\jPrime{j\vthinspace'\negvthinspace}

\newcommand\Sig{\mathrm{\Sigma}}

\newcommand\keyw[1]{\textbf{#1}}
\newcommand\const[1]{\textsf{#1}}
\newcommand\ty[1]{\textit{#1}}

%%% @ANDY: I don't like using \qed or anything too similar (e.g. \Box) for
%%% anything else than "quid erat demonstrandum". I'm open to other symbols,
%%% e.g. a filled black square. But if the example are short enough, which
%%% they currently are, we could live with nothing.
%%%
\newcommand\xend{{\hfill$\scriptstyle\blacksquare$}}
%\newcommand\xend{{\qed}}
%\newcommand\xend{{}}

%\renewcommand{\vec}[1]{\mathbf{#1}}
\renewcommand{\vec}[1]{\bar #1}
%\newcommand{\Ec}{\mathsf{E}}
\newcommand{\Ec}{E}
%\newcommand{\Ec}{\mathcal{E}}
%\newcommand{\Fc}{\mathsf{F}}
\newcommand{\Fc}{F}
%\newcommand{\Fc}{\mathcal{F}}
%\newcommand{\Gc}{\mathsf{G}}
%\newcommand{\Ac}{\mathsf{A}}
%\newcommand{\Dc}{\mathsf{D}}
%\newcommand{\Rc}{\mathsf{R}}
\newcommand{\vrange}{\mathsf{range}}
\newcommand{\vdom}{\mathsf{dom}}
\newcommand{\tEc}{\mathcal{T}(\Ec)}
\newcommand{\tcEc}{\mathcal{T}^\ast(\Ec)}
\newcommand{\rn}[1]{\textsf{\small #1}}
\newcommand{\cvc}{\textsc{cvc}{\small 4}\xspace}
\newcommand{\teq}{\approx}
\newcommand{\tneq}{\not\teq}
\newcommand{\rem}[1]{\textcolor{red}{[#1]}}
%\newcommand{\is}[1]{is\text{-} #1}
\newcommand{\is}[1]{\const{is#1}}
\newcommand{\ror}{\kern.45em \parallel \kern.45em}
\newcommand{\tpath}[2]{\mathcal{P}_{ #2 \rightarrow \_ }( #1 )}
\newcommand{\ttpath}[3]{\mathcal{P}_{ #2 \rightarrow #3 }( #1 )}
\newcommand{\interp}[1]{\llbracket #1 \rrbracket}
\newcommand{\dpath}[3]{\delta^{#1}_{#2}( #3 )}
\newcommand{\ec}[1]{[#1]}
\newcommand{\M}{\mathcal{M}}
\newcommand{\Val}{\mathcal{A}}
\newcommand{\Var}{\mathcal{V}}
%\newcommand{\Varec}[1]{\Var{\ec{#1}}}
\newcommand{\Varec}[1]{\widetilde{#1}}
\newcommand{\VAREC}[1]{\widetilde{\vphantom{\scriptstyle x^i}\smash{#1}}}
%\newcommand{\nf}[1]{{{#1}{\downarrow}}}
\newcommand{\nf}[1]{\lfloor#1\rfloor}
\newcommand{\aequiv}{\mathrel{=_\alpha}}
\newcommand{\vsim}{\aequiv}
\newcommand{\vsimv}[1]{\mathrel{=^{#1}_\alpha}}
\newcommand{\tpos}[2]{#1\!\mid_{#2}}
\newcommand{\muvar}{\mathcal{Var}}

\newcommand\SSS{\mathit{S\vthinspace}}
\newcommand\SSSS[1]{\mathit{S}^{\,#1}}

% change?
\newcommand{\thO}{T_{\mathrm{o}}}
\newcommand{\thD}{T_{\!\mathrm{cd}}}

%\newcommand\Types{\mathcal{T}}
\newcommand\Types{\mathcal{Y}}
\newcommand\Funcs{\mathcal{F}}

\newcommand\Data{\Types_{\mathrm{dt}}}
\newcommand\Codata{\Types_{\mathrm{codt}}}
\newcommand\Nondata{\Types_{\mathrm{ord}}}

\newcommand\Ctr{\Funcs_{\mathrm{ctr}}}
\newcommand\Sel{\Funcs_{\mathrm{sel}}}
%\newcommand\Plainfuncs{\Funcs_{\mathrm{other}}}

\newcommand\vvthinspace{\kern+0.041667em}
\newcommand\vthinspace{\kern+0.083333em}
\newcommand\negvthinspace{\kern-0.083333em}

%%% For final version as well?
\usepackage[
   a4paper,
   pdftex,
   pdftitle={A Decision Procedure for (Co)datatypes in SMT Solvers},
   pdfauthor={Andrew Reynolds and Jasmin Christian Blanchette},
   pdfkeywords={},
   pdfborder={0 0 0},
   draft=false,
   bookmarksnumbered,
   bookmarks,
   bookmarksdepth=2,
   bookmarksopenlevel=2,
   bookmarksopen]{hyperref}

\urlstyle{ttstyle}

\global\def\figurename{Figure}
\global\def\figuresname{Figures}

\DeclareSymbolFont{letters}{OML}{txmi}{m}{it}

%%% REMOVE BEFORE SUBMITTING ABSOLUTELY FINAL VERSION
\makeatletter
\ps@myheadings
\makeatother

\include{defs}

\hyphenation{data-type data-types co-data-type co-data-types isa-belle sledge-hammer}


\begin{document}

\title{A Decision Procedure for (Co)datatypes in SMT Solvers}

\author {Andrew Reynolds\inst{1} \and Jasmin Christian Blanchette\inst{2,3}}
\authorrunning {A. Reynolds \and J. C. Blanchette}
\institute{
\'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL), Switzerland
\and
Inria Nancy \& LORIA, Villers-l\`es-Nancy, France
\and
Max-Planck-Institut f\"ur Informatik, Saarbr\"ucken, Germany
}

\maketitle

\begin{abstract}
Codatatypes naturally capture potentially infinite data structures and
processes. We present a decision procedure that combines reasoning about
datatypes and codatatypes. The dual of the acyclicity rule for datatypes is a
uniqueness rule that identifies observationally equal values, also in the presence of cyclic
($\omega$-regular) data. The procedure decides ground and universal
problems and is composable via the Nelson--Oppen method. It has been
implemented in the latest version of CVC4, a state-of-the-art SMT solver. An
evaluation based on problems generated from Isabelle theories demonstrates the
potential of the procedure.
\end{abstract}

%% The institutions above shouldn't count as footnotes
\setcounter{footnote}{0}

\section{Introduction}
\label{sec:introduction}

Freely generated inductive datatypes are ubiquitous in functional programs and
logical specifications. They are especially
useful to represent finite data structures in computer science applications but
also arise when formalizing mathematics.
They can be implemented efficiently and enjoy
properties that can be exploited in automated reasoners.
%
%However, because datatype values correspond to finite ground terms, they
%are generally not adequate to represent infinite objects.
%For example, the datatype of natural numbers
%constructed by $\const{Z} : \ty{nat}$ and $\const{S} : \ty{nat} \to \ty{nat}$
%only allow values of the form $\const{S}(\ldots(\const{S}(\const{Z}))\ldots)$.

To represent infinite objects, % such as $\const{S}(\const{S}(\const{S}(\ldots))$,
a natural choice is to turn to coinductive datatypes, or \emph{codatatypes},
the non-well-founded dual of inductive \emph{datatypes}.
%
Despite their reputation for being esoteric, codatatypes have a
role to play in computer science. The verified C compiler CompCert
\cite{leroy-2009}, the verified Java compiler Jinja\-Threads
\cite{lochbihler-2010-jinja}, and the formalized Java memory model
\cite{lochbihler-2014-jmm} all depend on codatatypes to capture infinite
processes.

Codatatypes are freely generated by their constructors, but in contrast with datatypes,
infinit\-e constructor terms are also legitimate values for codatatypes
(Section~\ref{sec:the-theory-of-co-datatypes}). Intuitively, the
values of a codatatype consist of all well-typed finite and infinite ground
constructor
terms, and only those. For example, the coinductive specification
%
\[\keyw{codatatype}~\,\ty{enat} \,=\, \const{Z} \,\mid\, \const{S}(\ty{enat})\]
%
(using an ML-like syntax) introduces a type that
models the natural numbers $\const{Z}$, $\const{S}(\const{Z})$, $\const{S}(\const{S}(\const{Z}))$, $\ldots$\afterLdots{},
using Peano notation but extended with an
infinity value $\infty = \const{S}(\const{S}(\const{S}(\ldots)))$. Compared
with the more conventional, inductive definition with a dedicated constructor
for representing infinity,
%\[\keyw{datatype}~\,\ty{enat} \,=\, \const{Z} \,\mid\, \const{S}(\ty{enat}) \,\mid\, \const{Infty}\]
%
the codatatype avoids one case by unifying the finite and infinite nonzero cases.
Moreover, equations such as $\const{S}(\infty) \teq \infty$ hold by default,
because both sides expand to the infinite term
$\const{S}(\const{S}(\const{S}(\ldots)))$, which uniquely identifies the
value~$\infty$.

\nopagebreak

Datatypes and codatatypes are an integral part of modern proof assistants,
including Agda, Coq, Isabelle, Matita, and PVS. In recent years, datatypes
have made their appearance in a few automatic theorem provers. The SMT-LIB~2
\cite{barrett-et-al-2010} syntax, implemented by most SMT (satisfiability
modulo theories) solvers, includes a theory of datatypes.

\pagebreak

In this \thewordpaper, we introduce a unified decision procedure for ground
problems involving datatypes and codatatypes in combination
(Section~\ref{sec:a-ground-decision-procedure-for-co-datatypes})
and discuss extensions  of the procedure for handling quantifiers
(Section~\ref{sec:extension-to-quantified-formulas}).
The procedure is described abstractly as a calculus and is
designed to be composable via the Nelson--Oppen method \cite{nelson-oppen-1979}.
For the datatype case, it follows the lines of Barrett et al.\ \cite{barrett-et-al-2007}.
To our knowledge, our procedure is the first of its kind for the theory of
codatatypes.

Datatypes and codatatypes share many of the same properties, so it makes sense
to consider them together. There are, however, at least three important
differences.

First, \emph{codatatypes need not be well-founded.}
For example, the type
%
\[\keyw{codatatype}~\;\ty{stream}_{\,\tau} \,=\, \const{SCons}(\tau,\: \ty{stream}_{\,\tau})\]
%
of infinite sequences, or streams, over an element type $\tau$ is allowed; the
corresponding datatype would be rejected as non-well-founded \cite{blanchette-et-al-2015-esop}.

Second, \emph{a uniqueness rule replaces the acyclicity rule of datatypes.}
Cyclic constraints such as
$\const{x} \teq \const{S}(\const{x})$ %, where $\const{C}$ is a constructor,
are unsatisfiable for datatypes but satisfiable for codatatypes.
However, the uniqueness principle states that two bisimilar values---i.e., two values
having the same possibly infinite expansion---must be equal; from $\const{x}
\teq \const{S}(\const{y})$ and
$\const{y} \teq \const{S}(\const{x})$, it deduces $\const{x} \teq \const{y}$.
The acyclicity and uniqueness rules are needed to ensure completeness on
ground problems and the absence of spurious models. They cannot be replaced by
finite axiomatizations, so they naturally belong in a decision procedure.
%    * in particular, acyclicity and uniqueness are necessary for some proofs
%%      (and cannot be axiomatized finitely)
%    * and for model finding, without them we quickly get spurious models
%    * explain how finite model finding works
%(For the other (co)datatype properties---the injectivity, distinctness, and
%exhaustiveness of constructors and the selector laws---it is
%widely recognized that decision procedures can be more efficient than
%axiomatizations.)
%axiom.

Third, \emph{it must be possible to express cyclic }(\emph{$\omega$-regular}) \emph{values as closed terms and
to enumerate them.} This is necessary both for finite model finding (modulo theories)
and for theory combinations. The $\mu$-binder notation associates a name with
a (sub)term; it is used to represent cyclic values in the generated models and
in the metatheory. For example,
the $\mu$-term $\const{SCons}(1,\: \MU s.\; \const{SCons}(0,\: \const{SCons}(9,\: s)))$
stands for the lasso-shaped sequence $1, 0, 9, 0, 9, 0, 9, \ldots$\afterLdots.

%%% 1090909 is a prime number


\begin{paper}
Proofs of soundness and completeness are included in the technical report
associated with this paper \cite{our-report}.
\end{paper}%
The procedure is implemented in the SMT solver CVC4 as a combination
of rewriting and a theory solver
(Section~\ref{sec:the-theory-solver}).
%\textbf{TODO: CHECK WITH IMPLEMENTATION, but round to nearest 50 or 1000.}
It consists of about 2000 lines of \cpp{} code, among which 1600 are
shared between datatypes and codatatypes. The code is integrated in the
development version of the solver and is expected to be part of the CVC4~1.5 release.
%
An evaluation on %hand-crafted examples and on
problems generated from Isabelle theories using the Sledgehammer tool
demonstrates the usefulness of the approach (Section~\ref{sec:experimental-results}).

%  * useful both for proving and for model finding

%\ref{sec:examples}

%  * benchmarking is often an issue -- esp. codatatypes
%
%Polymorphic types, nested (co)recursion, and datatype--codatatype mixtures fall

%  * setting: FOL
%    * core procedure is restricted to ground
%      * but theory solver cooperates

%  * codatatypes were added later, motivated by the use of SMT solvers as
%    backends to proof assistants (more specifically, CVC4 to Isabelle/HOL)

%  * setting :
%    * universal formulas
%    * many-sorted logic
%   * mutually (co)recursive types with constructors, selectors, and
%      discriminators

%  * codatatypes: from a theoretical and implementational point of view, like
%      datatypes but:
%    * infinite values (infinitely many nested constructors)
%    * codatatypes are never empty (e.g. finite streams are rejected)

%\[
%      \keyw{codatatype}\; \,\ty{llist} \,=\, \const{LNil} \,\mid\, \const{LCons}(\ty{int},\: \ty{llist})
%\]

%  * consider a natural fragment---datatypes as supported in modern SMT solvers
%    and the SMT-LIB 2 standard, and codatatypes as their duals
%    * mutual recursion, but no polymorphism, nested recursion
%  * integrated with Nelson--Oppen

% * SMT-Lib

%  * one implication is that if $m$ equals $ES(n)$ and $n$ equals $ES(m)$, necessarily
%    $m$ and $n$ must be equal.

%  * perhaps the most commonly used codatatype is that of lazy lists or sequences.
%    using a syntax similar to Standard ML, Haskell, or SMT-LIB

%  * less briefly: codatatypes and why they are useful
%    * in Agda, Coq, Matita -- recently also in Isabelle/HOL \cite{nipkow-et-al-2002}
%    * but not in SMT-LIB 2 \cite{barrett-et-al-2010}

\paragraph{Related Work.}
Although it was written several years ago, the account of related work in
Barrett et al.\ \cite{barrett-et-al-2007} is still a good starting point.
Since then, datatypes have been added to the SMT solver
Z3 in unpublished work by Leonardo de Moura and to a SPASS-like prototype
superposition prover called Pirate by Daniel Wand.
Closely related is the automatic structural
induction in CVC4 by Reynolds and Kuncak \cite{reynolds-kuncak-2015} and in
Pirate by Wand and Weidenbach \cite{wand-weidenbach-201x};
both methods naturally depend on a notion of datatype.

%     * point to Barrett et al. for SMT datatypes
%       * about their own work, they say: "our focus is on generality and
%         efficiency rather than immediacy of implementation"
%       * (deal more directly with finite sorts than Barrett et al., Section 6.1)
%     * SPASS-Pirate
%     * additional ones since then (e.g. strings?)
%     * anything about codatatypes?
%       * proof assistants like Agda, Coq, etc. have them
%       * Dafny, CoALP
%       * also a lot of theoretical research, some of which is loosely connected,
%         e.g. decision procedure for corecursive functions (Henning in Nijmegen)
%
%     * ODDITY: Oppen 1980: single-constructor, recursive -- infinite values?

\paragraph{Conventions.}
The setting is a monomorphic (or many-sorted) first-order logic.
A signature $\Sig = (\Types, \Funcs)$ consists of a set of types $\Types$ and a
set of function symbols $\Funcs$. Types are simply atomic sorts, with no
structure, and interpreted by nonempty domains. The set~$\Types$ must contain a
distinguished type \ty{bool}\begin{report} interpreted as the set of truth
values $\{\bot, \top\}$\end{report}. %, and may contain other interpreted types (e.g., \ty{int}, \ty{real}).
The only predicate is equality ($\teq$)\begin{report} and belongs to the logical symbols\end{report}.
Other predicates can be represented as functions to $\ty{bool}$,
with $\const{p}(\ldots)$ abbreviating $\const{p}(\ldots) \teq \const{true}$.
\begin{report}
The metavariables $\delta,\:\varepsilon$ range over (co)datatypes,
whereas $\tau,\:\upsilon$ range over arbitrary types.
When applied to terms, the symbol $=$ denotes syntactic equality.\end{report}

\begin{report}
Function symbols are written in a sans-serif font (e.g., $\const{f}$, $\const{g}$) to
distinguish them from variables (e.g., $x$, $y$).
\end{report}
Symbols starting with an uppercase letter (e.g.,
$\const{S}$, $\const{SCons}$) are reserved for constructors. With each function symbol \const{f}
is associated a list of argument types $\tau_1,\ldots,\tau_n$ (with $n \ge 0$)
and a return type $\tau$. This connection can be expressed %compactly
as $\const{f} : \tau_1 \times \cdots \times \tau_n \to \tau$\begin{report},
which collapses to $\const{f} : \tau$ if $n = 0$\end{report}.
For a term $t$, the notation $t : \tau$ indicates that it has type $\tau$.
Functions are invoked in the standard way, with $\const{f}(t_1,\ldots,t_n)$
applying the $n$-ary function symbol
\const{f} to $n$ well-typed arguments $t_1 :\nobreak \tau_1$, \ldots, $t_n :
\tau_n$. Nullary function symbols are called constants and can appear without
parentheses in terms.
%
Finally, $\bar x$ abbreviates a list or tuple $x_1,\ldots,x_n$\begin{report}
and $\bigwedge_{\,i}\, \varphi_i$ abbeviates a conjunction
$\varphi_1 \mathrel\land \cdots \mathrel\land \varphi_n$\end{report}.

%* although nothing prevents composing the decision procedure with theories
%  providing polymorphic types (parametric sorts), such as for arrays (e.g., $\ty{array}(\alpha,\beta)$)

\section{%The Theory of
(Co)datatypes}
\label{sec:the-theory-of-co-datatypes}

%    (terminology: freely-generated, inductive, algebraic, ..., sometimes
%    with different meanings; we'll clarify below what we use)

We fix a signature $\Sig = (\Types, \Funcs)$. The types are partioned into
$\Types = \Data \mathrel{\uplus} \Codata \mathrel{\uplus} \Nondata$, where $\Data$ are the
\emph{datatypes}, $\Codata$ are the \emph{codatatypes}, and $\Nondata$ are the %remaining
\emph{ordinary types}. The function symbols are partitioned into $\Funcs = \Ctr
\mathrel{\uplus} \Sel$, where $\Ctr$ are the \emph{constructors} and $\Sel$ are the
\emph{selectors}. There is no need to consider further function symbols
because they can be abstracted away as variables when combining theories.
Exceptionally, it is convenient to use natural number
constants ($0$, $1$, \ldots)\ in examples.

%\paragraph{Specifications.}
In an SMT problem, the signature is normally given by specifying the
uninterpreted types in any order, the (co)datatypes with their constructors
and selectors in groups of mutually (co)recursive groups of (co)datatypes, and
finally any other function symbols.
%
A (co)datatype specification consists of $l$~mutually recursive types which are
either all datatypes or all codatatypes. Polymorphic types, nested
(co)recursion, and datatype--codatatype mixtures fall outside this fragment%
\dotReportFootnote{%
In principle, rank-1 (top-level) polymorphism \cite{blanchette-paskevich-2013}
should not raise any special difficulties. Nesting datatypes inside datatypes,
and likewise for codatatypes, can be reduced to the mutual case
\cite{gunter-1993-not}. So the only genuinely interesting cases missing are
mixed nested (co)recursion as well as
(co)recursion through a non-(co)datatype (both of which make sense
\cite{blanchette-et-al-2014-codata}).}
In the presentation, we allow ourselves some metalevel parameterization
% at the metalevel
through subscripts---for example, $\ty{stream}_{\,\tau}$ denotes a
family of ground types including
$\ty{stream}_{\,\ty{int}}$, $\ty{stream}_{\,\ty{bool}}$,
and \smash{$\ty{stream}_{\,\ty{stream}_{\,\ty{real}}}$}.

\newcommand\elll{\kern.18ex l\kern.11ex}
\newcommand\elllx{\kern.11ex l\kern.18ex}

Each datatype $\delta$ is equipped with
$m \ge 1$ constructors, and each constructor for $\delta$ takes zero or more
arguments and returns a $\delta$ value. The argument types must be either
ordinary, among the already known (co)datatypes, or among the (co)datatypes
being introduced.
%
To every argument corresponds a selector. The names for the (co)data\-types, the
constructors, and the selectors must be distinct and different from
existing names%
\dotReportFootnote{It can be convenient to specify the same selector
for several constructors associated with the same (co)data\-type,
as long as the argument types coincide. % \cite[Section~3]{blanchette-et-al-2014-codata}.
However, this is disallowed by SMT-LIB 2, so we do not consider it here.}
Schematically:
%
\[
\begin{aligned}[t]
\!(\keyw{co})\keyw{datatype}\;\,
  \delta_1 & {}= \smash{\const{C}_{11\!}(\bigl[\const{s}_{11\!}^1{:}\bigr]\vthinspace \tau_{11\!}^1, \ldots, \bigl[\const{s}_{11\!}^{n_{11\!}}{:}\bigr]\vthinspace \tau_{11\!}^{n_{11\!}})} \mid \cdots \mid \smash{\const{C}_{1m_1\!}(\ldots)} \\
   \smash{\vdots\,\,\,} \\[-1\jot]
  \keyw{and}\; \,\delta_{\elllx} & =\, \smash{\const{C}_{\elll 1\!}(\bigl[\const{s}_{\elll 1\!}^1{:}\bigr]\vthinspace \tau_{\elll 1\!}^1, \ldots, \bigl[\const{s}_{\elll 1\!}^{n_{\elll 1\!}}{:}\bigr]\vthinspace \tau_{\elll 1\!}^{n_{\elll 1\!}})} \mid \cdots \mid \smash{\const{C}_{\elll m_{\elllx}\!}(\ldots)}
\end{aligned}
\]
%
with
$\const{C}_{i\negvthinspace j} : \tau_{i\negvthinspace j}^1\times\cdots\times\tau_{i\negvthinspace j}^{\,k_{\smash{i\negvthinspace j}}} \to \delta_i$
and $\const{s}_{i\negvthinspace j}^{\,k} : \delta_i \to \tau_{i\negvthinspace j}^{\,k}$. Defaults are assumed for
the selector names if they are omitted.

For types with several constructors, it is customary to provide discriminators
$\const{d}_{i\negvthinspace j} : \delta_i \to \ty{bool}$. However,
it is not necessary to extend the signature:
The discriminator term $\const{d}_{i\negvthinspace j}(x)$ can be seen as an abbreviation for
$x = \const{C}_{i\negvthinspace j}\bigl(\const{s}_{i\negvthinspace j}^1(x), \ldots, \const{s}_{i\negvthinspace j}^{\,n_{\smash{{i\negvthinspace j}}}}(x)\bigr)$.
%This will simplify the presentation. % of the decision procedure.

Here are a few examples of legal specifications of (co)datatype families:
\[\begin{aligned}[t]
      \keyw{codatatype}\; \,\ty{llist}_{\,\tau} & \,=\, \const{LNil} \,\mid\, \const{LCons}(%\const{lhead}{:}\;
      \tau,\: %\const{ltail}{:}\;
      \ty{llist}_{\,\tau}) \\%[-.5\jot]
      \keyw{datatype}\;\, \ty{tree}_{\,\tau} & \,=\, \const{Node}(\tau,\:\, \ty{forest}_{\,\tau}) \\[-\jot]
      \keyw{and}\;\,\, \ty{forest}_{\,\tau} & \,=\, \const{FNil} \,\mid\, \const{FCons}(\ty{tree}_{\,\tau},\:\, \ty{forest}_{\,\tau})
\end{aligned}
\]

\begin{report}%
Because all types must be inhabited (nonempty), a datatype specification is
admissible only if a ground constructor term can be exhibited.
This rules out non-well-founded specifications such as
\[\keyw{datatype}\;\, \ty{fstream}_{\,\tau} \,=\, \const{FSCons}(\tau,\:\, \ty{fstream}_{\,\tau})\]
For codatatypes, no admissibility check is necessary because there is always a term,
finite or infinite, that witnesses nonemptiness \cite{blanchette-et-al-2015-esop}.
\end{report}

A type $\delta$ depends on another type $\varepsilon$ if $\varepsilon$ is the
type of an argument to one of $\delta$'s constructors. Semantically, a set of
types is mutually (co)recursive if and only if the associated dependency graph
is strongly connected. Types can be declared together as mutually
(co)recursive even if they are not actually (co)recursive, but the
semantic notion is more precise and is the one that interests us.
%
In addition, nothing forbids non(co)recursive specifications
such~as
\begin{paper}%
\vthinspace$\keyw{datatype}~\vthinspace\ty{option}_{\,\tau} = \const{None} \mid \const{Some}(\tau)$.%
\end{paper}%
\begin{report}%
\[\begin{aligned}[t]
      \keyw{datatype}\;\, \ty{option}_{\,\tau} & \,=\, \const{None} \mid \const{Some}(\tau) \\[-.5\jot]
      \keyw{codatatype}\; \,\ty{complex} & \,=\, \const{Complex}(\const{re}{:}\; \ty{real},\; \const{im}{:}\;\ty{real})
\end{aligned}
\]
At the semantic level, it makes no difference whether such types are
introduced as datatypes or as codatatypes.
\end{report}%
%Without loss of generality, we consider that these types are datatypes
%instead of codatatypes.

%Given the specification
%
%\[\keyw{codatatype}\;\, \ty{stream} \,=\, \const{SCons}(\ty{int},\:\ty{stream})\]
%
%the infinite value $\const{SCons}(0, \const{SCons}(0, \ldots))$ witnesses
%nonemptiness.

%\paragraph{Characterization.}
One way to define datatypes semantically is as the initial model of the
selector--constructor equations \cite{barrett-et-al-2010}.
\begin{report}
A drawback of this approach is that it does
not naturally account for selectors applied to wrong constructors. Barrett et
al.\ address this by parameterizing the construction by default values, but
this gives rise to spurious equalities between unrelated terms---e.g.,
$\const{s}_{11}(\const{C}_2) \teq \const{s}_{11}(\const{C}_3)$. This flaw
could be corrected, but the added complexity seems to suggest that selectors
are better characterized axiomatically.

\end{report}
A related semantic view of datatypes is as initial algebras \cite{xxx}.
Codatatypes are then defined dually as final coalgebras \cite{xxx}. The
datatypes are generated by their constructors, whereas the codatatypes are
viewed through their selectors.
%By uniformly focusing on the constructors, the
%axiomatic approach emphasizes the commonality between datatypes and
%codatatypes, while sacrificing a theoretically fruitful notion of duality.

Datatypes and codatatypes share many basic properties pertaining to
constructors and selectors. All properties below are implicitly universally
quantified and range over all $i$, $j$, $\jPrime$, and $k$ within bounds:
% and to all possible splits of the
%$n$-ary constructor $\const{C}_{i\negvthinspace j}$'s argument list into $\bar x,
%y, \bar z$:
%
\[
\begin{aligned}[t]
\text{Distinctness:}\quad
  & %\forall \bar x, \bar y.\;\,
    \smash{\const{C}_{i\negvthinspace j}(\bar x) \tneq \const{C}_{i\negvthinspace \jPrime}(\bar y) \quad\text{if $j \not= \jPrime$}}
  \\[-.5\jot]
\text{Injectivity:}\quad
  & %\forall x_1,\ldots,x_{n_{i\negvthinspace j}} y.\;\,
    \smash{\const{C}_{i\negvthinspace j}(x_1,\ldots,x_{n_{i\negvthinspace j}}) \teq \const{C}_{i\negvthinspace j}(x_1,\ldots,x_{k-1},y,x_{k+1},\ldots,x_{n_{i\negvthinspace j}}) \longrightarrow x_k \teq y}
  \\[-.5\jot]
\text{Exhaustiveness:}\quad
  & \smash{\is{C}_{i1}(x) \mathrel\lor \cdots \mathrel\lor \is{C}_{im_i}(x)}
  \\[-.5\jot]
\text{Selection:}\quad
  & \smash{\const{s}_{i\negvthinspace j}^{\,k}(\const{C}_{i\negvthinspace j}(x_1,\ldots,x_{n_{i\negvthinspace j}})) = x_k}
\end{aligned}
\]
%
\begin{report}
Expressed in the algebraic jargon, exhaustiveness helps ensure that ``no
junk'' exists, whereas distinctness and injectivity guarantee that ``no
confusion'' can arise.
The result of selectors applied to the wrong
constructor is left completely unspecified.
\end{report}

%  * how to deal with "wrong" selectors, e.g.
%        hd(nil1) = hd(nil2)?
%      * leave them unspecified; hence hd(nil1) = hd(nil2) in some models,
%        and not in other models

Datatypes are additionally characterized by an induction axiom schema\begin{report}:
%
\[
\begin{aligned}[t]
\text{Induction:}\quad
\AXC{\strut$\bigwedge_{\,i,j}\, \forall x_1 \ldots \vthinspace x_{n_{i\negvthinspace j}}.\; \bigl(\bigwedge_{\,k}\, \mathit{IH}_{i\negvthinspace j}^k[x_k]\bigr) \longrightarrow P_i[\const C_{i\negvthinspace j}(x_1,\ldots,x_{n_{ij}})]$}
\UIC{\strut$\bigwedge_{\,i}\, P_i[v_i]$}
\DP
\end{aligned}
\]
where the induction hypothesis $\mathit{IH}_{i\negvthinspace j}^k(x)$
denotes either $P_{\iPrime}(x)$ if there exists some $\iPrime$ such that
the formula is type-correct or else $\top$\end{report}.
%
The axiom schema ensures that the interpretation of datatypes
is a standard model. For example,
for a datatype of natural numbers constructed from $\const{Z}$ and $\const{S}$,
induction prohibits nonstandard models, which could contain cyclic values---e.g.,
an $n$ such that $n \teq \const{S}(n)$---or even infinite acyclic values
$\const{S}(\const{S}(\ldots))$.
%
\begin{report}\par\end{report}
%
For codatatypes, the dual notion is called coinduction. \begin{report}It depends on
witnesses $R_i$ that are required to be bisimulations:
%
\[
\begin{aligned}[t]
\text{Coinduction:}\kern.8em %%% TYPESETTING: should be \quad
\AXC{\strut$\begin{gathered}\textstyle \bigwedge_{\,i}\, R_i[v_i, w_i] \\[-\jot]\textstyle
\bigwedge_{\,i}\, \forall v\; w.\;\, R_i[v, w] \longrightarrow
  \bigwedge_{\,j}\, \const{d}_j(v) \teq \const{d}_j(w)
  \mathrel\land
  \const{d}_j(v) \longrightarrow \bigwedge_{\,k}\, \const{s}_{i\negvthinspace j}^{\,k}(v) \sim \const{s}_{i\negvthinspace j}^{\,k}(w)
\end{gathered}$}
\UIC{\strut$\bigwedge_{\,i}\, v_i \teq w_i$}
\DP
\end{aligned}
\]
where $x \sim y$ denotes either $R_{\iPrime}[x, y]$ if there exists some
$\iPrime$ such that the formula is type-correct or $x \teq y$ otherwise.
\end{report}%
This axiom schema guarantees that two values that yield the same
observations must be equal, where the observations are made by using the
selectors and discriminators.
%
\begin{report}\par\end{report}
  %
In addition, codatatypes are guaranteed to contain all values corresponding to
infinite ground constructor terms.
\begin{report}
In general, this cannot be captured by a
first-order axiomatization, since there may be uncountably many of them.
For example, $\ty{stream}_{\,\ty{int}}$ is isomorphic to the uncountable
function space $\ty{nat} \to \ty{int}$.
\end{report}

%TODO: Andy, introduce theory here. There were some ideas below in the comments
%you might want to mention either here or in Section 3. I'm not sure what's the
%best way to justify it though, but for the conference at least we can just claim it. (we
%won't have the place for a proof anyway).

Given a signature $\Sig$, we write $\thD$ to refer to the \emph{theory} of (co)datatypes,
which in addition to $\Sig$ defines a class of $\Sig$-interpretations $\mathbf{I}$,
namely the ones that satisfy the axioms mentioned in this section.
In particular, this means that each interpretation in $\mathbf{I}$ has a fixed interpretation
for constructor terms and correctly applied selector terms, but may differ on its interpretation for
wrongly applied selector terms and variables.
A formula $\varphi$ is $\thD$-satisfiable if there exists an interpretation in $\mathbf{I}$ that satisfies $\varphi$;
otherwise, it is $\thD$-unsatisfiable.
\rem{more?}

When looking at the ground theory, induction can be replaced by the acyclicity
axiom schema, which states that any ground constructor term cannot be equal to
a variable it contains \cite{xxx}. Dually, coinduction can be replaced by the
uniqueness axiom schema, which asserts that (co)recursive definitions giving
rise to the same infinite expansion---e.g., $x \teq \const{C}(x)$ and $y \teq
\const{C}(\const{C}(y))$---must be equal.

\begin{report}
TODO: State more precisely and proof?
\end{report}

%    * :
%        enough to consider acyclicity -- no way to specify infinite objects
%        otherwise

%    * codatatypes:
%      * when looking at the ground theory, enough to
%        consider uniqueness -- no way to express that certain infinite
%        acyclic objects do not exist

%\paragraph{Special Cases.}
Some codatatypes are so degenerate as to have infinite values
even though they are finite. The simplest example is
\vthinspace$\keyw{codatatype}~\ty{a} = \const{A}(\ty{a})$, whose
only value is $\MU a.\; A(a)$. Other specimens are
\begin{paper}%
\vthinspace$\keyw{codatatype}~\ty{b} = \const{B}(\ty{b},\: \ty{c},\: \ty{b},\: \ty{unit})
~\keyw{and}~ \ty{c} = \const{C}(\ty{a},\: \ty{unit},\: \ty{b},\: \ty{c})$,
\end{paper}%
\begin{report}%
\[\begin{aligned}[t]
      \keyw{codatatype}\;\, \ty{b} & \,=\, \const{B}(\ty{b},\: \ty{c},\: \ty{b},\: \ty{unit}) \\[-1\jot]
      \keyw{and}\;\, \ty{c} & \,=\, \const{C}(\ty{a},\: \ty{unit},\: \ty{b},\: \ty{c})
\end{aligned}
\]
\end{report}
where \ty{unit} is a datatype with the single constructor $\const{Unity} :
\ty{unit}$, as well as $\ty{stream}_{\,\ty{unit}\,}$. We call such types
\emph{corecursive singletons}. For the decision procedure, it will be
important to detect these types. %, even if they rarely arise in practice.
A type may also be a corecursive singleton only in some models. If the example
above is altered to leave \ty{unit} uninterpreted, \ty{b} and \ty{c} will be
singletons precisely when \ty{unit} is interpreted as a singleton.
Fortunately, given cardinalities for the ordinary types, it is easy to
characterize this degenerate case:

% In other words, all finite corecursive codatatypes are corecursive singletons.

\begin{lemma}%[Corecursive Singletons]%
\label{lem:corecursive-singletons}%
\afterDot
Let $\delta$ be a corecursive codatatype. The domain interpreting $\delta$ is
either infinite or a singleton. In the latter case, $\delta$ necessarily has a
single constructor, whose arguments have types that are interpreted as
singletons.
\end{lemma}

\begin{report}
\begin{proof}
By definition, the type is equipped with at least one (directly or indirectly)
corecursive constructor $\const{C}$. If it additional has second
corecursive constructor $\const{D}$, it is possible to encode infinitely many
alternation patterns---e.g.,
$\const{C}(\const{D}(\const{C}(\const{C}(\ldots))))$---all of which correspond
to distinct values (by distinctness and injectivity). If the type has a
noncorecursive constructor $\const{E}$, it is possible to create terms of
arbitrary depths---e.g., $\const{C}(\ldots(\const{C}(\const{E}))\ldots)$. In
both cases, there can be no finite models.

Therefore, $\const{C}$ must be the only constructor.
If any of its noncorecursive arguments has a cardinality greater than 1,
it is possible to encode alternation patterns using it---e.g.,
$\const{C}(0,\: \const{C}(1,\: \const{C}(0,\: \const{C}(0,\: \ldots))))$---which
again excludes finite models. Otherwise, the coinduction principle ensures
that the type has at most one value.
\qed
\end{proof}
\end{report}

%  * assume for simplicity no indirect recursion, but this does not radically
%    change the argument
%  * assume there are at least two values built with C.
%    they must be different at some point, e.g.
%    C(0, C(1, C(0, ...))) and C(0, C(1, C(1, ...)))
%    can use that to create infinitely alternation patterns
%  * leaves us with the case of a single constructor
% * since we are looking at a specific model, we can assume all ordinary
%   types are finite datatypes with nullary constructors corresponding to their
%   elements
% * if two
% * either there is only one ``path'' from ctr to itself
%   or at least two;

\section{The Ground Decision Procedure} % for (Co)datatypes}
\label{sec:a-ground-decision-procedure-for-co-datatypes}

The decision procedure for the ground theory of (co)datatypes $\thD$ determines the
$\thD$-satisfiability of sets of ground constraints over a fixed
signature~$\Sig$. It is formulated as a calculus, whose rules are applied
until a contradiction is detected or until saturation.
%
The rules operate on a finite set $\Ec$ of equalities and disequalities
between $\Sig$-terms, where $\Ec$ is interpreted as a conjunction.
We write $\tEc$ to denote the set of $\Sig$-terms occurring in $\Ec$.
%We will commonly denote tuples of terms $( t_1, \ldots, t_n )$ in bold font, as $\vec t$.
%We assume that all $\Sig$-terms in $\Ec$ are \emph{normalized}, meaning that all subterms of the form $\const{s}^{\,k}_j( \const{C}_j(t_1,\ldots,t_n) )$
%are simplified to $t_k$. All constraints added to $\Ec$ are also implicitly
%normalized in this manner.

To simplify the presentation, we make the following assumptions about $\Sig$.
First, all codatatypes in $\Codata$ are corecursive. This is not restrictive
because noncorecursive codatatypes can be considered as nonrecursive
datatypes.
Second, all types $\tau \in \Nondata$ have infinite cardinality.
This is not overly restrictive, because each interpreted type $\tau \in \Nondata$
having finite cardinality~$n$
can be replaced by an enumeration datatype with $n$~nullary constructors.
Moreover, since the constraints are ground, they cannot entail an upper bound
on the cardinality of any uninterpreted type $\tau \in \Nondata$; thus,
we may without loss of generality or completeness treat all types in $\Nondata$ as infinite.

The calculus consists of three sets of rules, given in \figuresname~\ref{fig:cc-rules} to
\ref{fig:split-rule}, corresponding to three phases. The first
phase computes the bidirectional closure of $\Ec$. The second phase makes
inferences based on acyclicity (for datatypes) and uniqueness (for
codatatypes). The third phase performs case splitting on constructors for
various terms in $\tEc$.
%Following the conventions from~\cite{},
%The derivation rules are given in \relax{guarded assignment form},
%where
A rule can be applied to $\Ec$ if all the specified preconditions are met.
The conclusion of a rule either describes equalities to be added to $\Ec$
or is $\bot$.
% (in which case we call an application of it \emph{nonterminal})
% (in which case we call an application of it \emph{terminal}).
A rule may have multiple conclusions separated by $\parallel$,
denoting nondeterministic branching. The rules associated with a phase have
priority over those of the previous phases. The rules are applied until
saturation (i.e., until no rule can be applied to extend~$\Ec$
further).

%We assume that all $\Sig$-terms in $\Ec$ are \emph{normalized}, meaning that all subterms of the form $\const{s}^{\,k}_j( \const{C}_j(t_1,\ldots,t_n) )$
%are simplified to $t_i$, and moreover assume that all %additional
%constraints added to $\Ec$ are normalized in this manner.
%We present the calculus in three steps.
%In the first step, we compute the bidirectional closure of $\Ec$;
%in the second step, we make inferences based on cyclicity and uniqueness;
%and in the third step, %(when necessary),
%we branch on constructor types for various terms in $\tEc$.
%Following the conventions from~\cite{},
%the derivation rules of our calculus are given in \emph{guarded assignment form},
%where a rule can be applied to $\Ec$ if it meets all of the specified preconditions for $\Ec$.
%The conclusion of a rule either describes equalities to be added to $\Ec$ (in which case we call an application of it \emph{nonterminal}),
%or is $\bot$ (in which case we call an application of it \emph{terminal}).
%A rule may have multiple conclusions separated by $\parallel$, which denotes nondeterministic branching.

\begin{figure}[t]
\normalsize
\centering
\begin{tabular}{c}
\(
\inferrule{
  t \in \tEc
}{
  \Ec := \Ec,\: t \teq t
}
\)
\rn{Refl}
\qquad
\(
\inferrule{
 t \teq u \in \Ec
}{
 \Ec := \Ec,\: u \teq t
}
\)
\rn{Sym}
\qquad
\(
\inferrule{
  t \teq u,\; t \tneq u \in \Ec
}{
  \bot
}
\)
\rn{Conflict}
\\[5\jot]
\(
\inferrule{
  s \teq t,\; t \teq u \in \Ec
}{
  \Ec := \Ec,\: s \teq u
}
\)
\rn{Trans}
\qquad
\(
\inferrule{
  \vec t \teq \vec u \in \Ec \quad \const f( \vec t \,),\, \const f( \vec u ) \in \tEc
}{
  \Ec := \Ec,\: \const f( \vec t \,) \teq \const f( \vec u )
}
\)
\rn{Cong}
\\[5\jot]
\(
\inferrule{
  \const{C}( \vec t \,) \teq \const{C}( \vec u ) \in \Ec
}{
  \Ec := \Ec,\: \vec t \teq \vec u
}
\)
\rn{Inject}
\qquad
\(
\inferrule{
  \const{C}( \vec t \,) \teq \const{D}( \vec u ) \in \Ec
  \quad
  \const{C} \not= \const{D}
}{
  \bot
}
\)
\rn{Clash}
\end{tabular}
\caption{\,Derivation rules for bidirectional closure%.
}
\label{fig:cc-rules}
\end{figure}

\paragraph{Phase 1: Computing the Bidirectional Closure.}
In conjunction with \rn{Refl}, \rn{Sym}, and \rn{Trans}, the \rn{Cong} rule computes the (upward) congruence closure,
whereas the \rn{Inject} and \rn{Clash} rules together compute (downward) unification.
For unification, additional equalities are inferred based on the injectivity of constructors by \rn{Inject},
and failures to unify equated terms are recognized by \rn{Clash}.
The rule \rn{Conflict} recognizes when an equality and its negation both occur in $\Ec$, in which case $\Ec$ has no model.

At the end of this phase, $\Ec$ induces an equivalence
relation over $\tEc$ such that two terms $t$ and $u$ are equivalent if and
only if $t \teq u \in \Ec$.
Thus, we can regard $\Ec$ as a set of
equivalence classes of terms. For a term $t \in \tEc$, we write $\ec{t}$ to
denote the equivalence class in $\Ec$ that contains $t$.

\begin{figure}[t]
\normalsize
\centering
\begin{tabular}{c}
\(
\inferrule{
  \delta \in \Data
  \quad
  t : \delta
  \quad
  %\ttpath{\Ec}{\ec{t}}{\ec{t}} \neq \emptyset
  \Val \ec{t} = \MU x.\; u
  \quad
  x \in \FV( u )
}{
  \bot
}
\)
\rn{Acyclic}
\\[4\jot]
\(
\inferrule{
 \delta \in \Codata
 \quad
 t, u : \delta
 \quad
 %\tpath{\Ec}{\ec{t}} = \tpath{\Ec}{\ec{u}}\sigma \neq \emptyset
 \Val \ec{t} \aequiv \Val \ec{u}
}{
 \Ec := \Ec,\: t \teq u
}
\)
\rn{Unique}
\end{tabular}
\caption{\,Derivation rules for acyclicity and uniqueness%.
}
\label{fig:ab-rules}
\end{figure}

\paragraph{Phase 2: Applying Acyclicity and Uniqueness.}
%For presentation of the rules in this phase, we rely on a representation of terms in the $\mu$-notation.
The rules of the second phase contain premises that involve a mapping $\Val$
that associates a $\mu$-term as representative with each equivalence class.
%Recall that $\mu$-bindings can be used for representing possibly cyclic terms and values.
%(Section~\ref{sec:introduction}).
% for example, $\MU x.\; \const{C}( \const{0}, x )$ represents the cyclic value $\const{C}( \const{0}, \const{C}( \const{0}, \ldots ))$.
A $\mu$-term $t$ of type $\tau$ describes a class of values of
$\tau$ that terms in that equivalence class can take in the models of $\Ec$;
%either in the case when $\tau$ is a codatatype or datatype type,
when $\tau \in \Data$, a cyclic $t$ describes an infeasible class of values.
%$\tau \not\in \Codata$.
Formally, $\mu$-terms are defined recursively as being either a variable $x$
or a node of the form
$\MU x.\: \const{C}( \vec t\, )$ for some constructor $\const{C} \in \Ctr$ and
$\mu$-terms $\vec t$ with the expected types.
The variable $x$ need not occur freely under the binder's body, in which case the
binder can be omitted.
In the \rn{Acyclic} rule,
$\FV( u )$ denotes the variables occurring freely in $u$.

%%% But there are no constants of type $\tau \in \Nondata$ -- at most variables!
%
%For uniformity, we also consider $%\MU x.\;
%\const{c}$ to be a $\mu$-term if $\const{c}$ is a constant of type $\tau \in \Nondata$.

%%% I think this should be clear enough from the "Conventions" paragraph at the
%%% end of the introduction.
%%
% which we define recursively:
%if $\const{C} : \vec \tau \rightarrow \upsilon$
%and $\vec v$ are well-typed $\mu$-terms of type $\vec \tau$ under the assumption that $x$ has type $\upsilon$,
%then $\MU x.\; \const{C}( \vec v )$ is a well-typed term of type $\upsilon$.

A $\mu$-term is \emph{closed} if %and only if --- by convention, "and only if" is not necessary for *definitions* (but add it back if you disagree)
it contains no free variables. It is \emph{cyclic} if %and only if --- ditto
it contains an occurrence of a bound variable.
The notation $t \aequiv u$, expressing $\alpha$-\emph{equivalence},
indicates that the $\mu$-terms $t$ and $u$
are syntactically equivalent for some capture-avoiding renaming of $\mu$-bound variables---e.g.,
%$\MU x.\; \const{C}( x ) \aequiv \MU y.\; \const{C}( y )$ and
$\MU x.\; \const{D}( y, x ) \aequiv \MU z.\; \const{D}( y, z )$\begin{report},
but
$\MU x.\; \const{C}( x ) \not\aequiv \MU x.\; \const{D}( y, x ) \not\aequiv \MU x.\; \const{D}( z, x )
\not\aequiv \MU y.\; \const{D}( y, x )$\end{report}.
Two $\mu$-terms can represent the same value while not being $\alpha$-equivalent---e.g.,
$\MU x.\; \const{C}( x ) \not\aequiv \MU x.\; \const{C}( \const{C}( x ) )$.
%, or informally are \emph{observationally equivalent}.
%For convienience, we use $\mu$-terms to refer to (classes of) values for both codatatype and datatype terms,
%where in the latter case, a $\mu$-term with a bound variable denotes an infeasible term.
%where the latter case adds the restriction on $\mu$-terms $t$ that no subterms of $t$ contain are bound variables.

The mapping $\Val$ is computed as follows.
%
For each equivalence class $\ec{x}$, we associate a fresh variable ${\Varec{x}}$ of the same type as $x$
%not occurring in $\tEc$,
and let $\Val\ec{x} = {\Varec{x}}$.
Thus, there are initially no constraints on the values for any equivalence class $\ec{x}$.
The mapping $\Val$ is then modified by applying the following unfolding rule exhaustively:
\[
\hbox{\(
\inferrule{
  {\Varec{x}} \in \FV( \Val )
  \quad
  \const{C}( t_1, \ldots, t_n ) \in \ec{x}
  \quad
  \const{C} \in \Ctr
}{
  \Val := \Val \{ {\Varec{x}} \mapsto \MU {\Varec{x}}.\; \const{C}( {\Varec{t_1}}, \ldots, {\Varec{t_n}} ) \}
}
\)
%\rn{Unfold}}
\]
$\FV( \Val )$ denotes the union of the free variables occurring in $\Val$'s range.
It is easy to see that the height of terms produced as a result of the unfolding
is bounded by the number of equivalence classes of $\Ec$,
and thus the construction of $\Val$ will terminate.

\begin{examplex}
Suppose that $\Ec$ contains distinct equivalence classes $\ec{w}$, $\ec{x}$, $\ec{y}$, and $\ec{z}$
where $\const{C}(z,x) \in \ec{y}$ and $\const{C}(w,y) \in \ec{x}$ for some $\const{C} \in \Ctr$.
A possible sequence of unfoldings is given below, omitting
trivial entries such as $\ec{w} \mapsto {\Varec{w}}$.
%
\begin{enumerate}
\item \noindent\rlap{Initially:}\phantom{Unfold $\Varec{x}$:\enskip}$\{  \}$
\item \noindent\rlap{Unfold $\Varec{x}$:}\phantom{Unfold $\Varec{x}$:\enskip}$\{\vthinspace  \ec{x} \mapsto \MU {\Varec{x}}.\; \const{C}( {\Varec{w}},\, {\Varec{y}} ) \vthinspace\}$
\item \noindent\rlap{Unfold $\Varec{y}$:}\phantom{Unfold $\Varec{x}$:\enskip}$\{\vthinspace  \ec{x} \mapsto \MU {\Varec{x}}.\; \const{C}( {\Varec{w}},\; \MU {\Varec{y}}.\; \const{C}( {\Varec{z}},\, {\Varec{x}} ) ),\;
  \ec{y} \mapsto \MU {\Varec{y}}.\; \const{C}( {\Varec{z}},\, {\Varec{x}} ) \vthinspace\}$
\item \noindent\rlap{Unfold $\Varec{x}$:}\phantom{Unfold $\Varec{x}$:\enskip}$\{\vthinspace  \ec{x} \mapsto \MU {\Varec{x}}.\; \const{C}( {\Varec{w}},\; \MU {\Varec{y}}.\; \const{C}( {\Varec{z}},\, {\Varec{x}} ) ),\;
  \ec{y} \mapsto \MU {\Varec{y}}.\; \const{C}( {\Varec{z}},\; \MU {\Varec{x}}.\; \const{C}( {\Varec{w}},\, {\Varec{y}} ) ) \vthinspace\}$
\end{enumerate}
%
This indicates that the values for $x$ and $y$ in models of $\Ec$
are of the forms $\const{C}( {\Varec{w}}, \const{C}( {\Varec{z}}, \const{C}( {\Varec{w}},\allowbreak \const{C}( {\Varec{z}},\ldots ))))$
and $\const{C}( {\Varec{z}}, \const{C}( {\Varec{w}}, \const{C}( {\Varec{z}}, \const{C}( {\Varec{w}}, \ldots ))))$,
respectively. %, for some values of ${\Varec{w}}$ and ${\Varec{z}}$.
\xend
\end{examplex}

Given $\Val$, the rules for acyclicity and uniqueness can be stated as follows.
For acyclicity, if there is an equivalence class $\ec{t}$ of datatype type whose class of values $\Val \ec{t} = \MU x.\; u$ are cyclic,
as indicated by the assumption $x \in \FV( u )$,
then we can conclude that $\Ec$ is unsatisfiable.
For uniqueness, if there are two equivalence classes $\ec{t}$ and $\ec{u}$
of codatatype type whose classes of values $\Val \ec{t}$ and $\Val \ec{u}$ are equivalent for a capture-avoiding renaming of $\mu$-bound variables,
then we can conclude $t \teq u$.
We demonstrate the uniqueness rule concretely with the following example.

%% @ANDY: Minor terminology point:
%% A function symbol can have a "type signature" (but we're trying to avoid that terminology);
%% unless it's a constant, it doesn't have a (first-order) type. So I'm rephrasing.

\begin{examplex}
Let $\const{C} : $ $\tau \times \delta \rightarrow \delta$ be a constructor,
and let $\Ec = \{ x \teq \const{C}(y,\const{C}(y,x)) \}$.
After phase~1, the equivalence classes of $\Ec$ are
$\{ x,\, \const{C}(y,\const{C}(y,x)) \}$, $\{ \const{C}(y,x) \}$, and $\{ y \}$.
Constructing $\Val$ as described above yields
\[\begin{array}{rcrlrl}
\Val \ec{x} & \,=\, &
\MU {\Varec{x}}. & \const{C}( {\Varec{y}},\, & \smash{\MU {\VAREC{\const{C}(y, x)}}}. & \const{C}( {\Varec{y}},\, {\Varec{x}} ) ) \\
\Val \ec{\const{C}(y,x)} & = &
\MU {\VAREC{\const{C}(y,x)}}. & \const{C}( {\Varec{y}},\, & \MU {\Varec{x}}. & \const{C}( {\Varec{y}},\, {\VAREC{\const{C}(y,x)}} ) )
\end{array}\]
Since $\Val \ec{x}$ and $\Val \ec{\const{C}(y,x)}$ are $\alpha$-equivalent,
%for the renaming
%$\{ {\Varec{x}} \mapsto {\VAREC{\const{C}(y,x)}}, {\VAREC{\const{C}(y,x)}} \mapsto {\Varec{x}} \}$,
the calculus can infer $x \teq \const{C}(y,x)$.
%Intuitively, this equality holds, since the values of $x$ and $\const{C}( y, x )$
%are equivalent for any value of ${\Varec{y}}$.
\xend
\end{examplex}

\begin{figure}[t]
\normalsize
\centering
\begin{tabular}{c}
\(
\inferrule{
  t : \delta \in \tEc
  \quad
  ( \const s( t ) \in \tEc \text{ and } \const s \in \Sel^\delta )
  \text{ or }
  ( \delta \in \Data \text{ and } \delta \text{ finite} )
}{
  \Ec := \Ec,\: t \teq \const{C}_1(\const s^1_1( t ), \ldots,\const s^{n_1}_1( t ) ) \ror \cdots \ror \Ec := \Ec,\: t \teq \const{C}_m(\const s^1_m( t ), \ldots,\const s^{n_m}_m( t ) )
}
\)
\rn{Split}
\\[5\jot]
\(
\inferrule{
  \delta \in \Codata
  \quad
  \left|\delta\right| = 1
  \quad
  t, u : \delta \in \tEc
}{
  \Ec := \Ec,\: t \teq u
}
\)
\rn{Singleton}
\end{tabular}
\caption{\,Derivation rules for branching%.
%All pairs of terms whose type has cardinality 1 are entailed to be equal (the degenerate case).
%Constructors must be assigned for all terms $t$ if has a selector is applied to it, or if $t$ has finite datatype type.
}
\label{fig:split-rule}
\end{figure}

\paragraph{Phase 3: Branching.}
If a selector is applied to a term $t$, or if $t$'s type is a finite datatype,
the equivalence class of $t$ must contain an application of one of
$\delta$'s constructors
$\Ctr^\delta = \{ \const{C}_1, \ldots, \const{C}_m \}$.
This is enforced in the third phase by the \rn{Split} rule.
A companion rule, \rn{Singleton}, handles the degenerate case where two terms
from $\tEc$ have a corecursive singleton type, in which case they must be
equivalent. Both the finiteness assumption on the datatype in \rn{Split} and
the cardinality-1 constraint on the codatatype in \rn{Singleton} are easy to
check based on a recursive computation of the cardinalities of the
constructors' argument types.

\paragraph{Correctness.}
An application of a rule is \emph{redundant} if at least one branch in the
conclusion does not add a new equality to $\Ec$ and is not $\bot$.
A \emph{derivation tree} is a tree whose nodes are finite sets of equalities, where non-root nodes are obtained by
a nonredundant application of a derivation rule to its parent node.
A derivation tree is \emph{closed} if all of its leaf nodes are $\bot$.
A node is \emph{saturated} if no nonredundant instance of a rule can be applied to it.
%
If there exists a closed derivation tree with root node $\Ec$, we conclude that $\Ec$ is $\thD$-unsatisfiable.
If there exists a derivation tree with root node $\Ec$ that contains a saturated node, we conclude that $\Ec$ is $\thD$-satisfiable.

\begin{theorem}[Termination]%
\label{thm:t}%
\afterDot
All derivation trees are finite.
\end{theorem}
\begin{proof}
Consider a derivation tree with root node $\Ec$.
Let $\SSS$ be the set of terms occurring as the argument of a selector in $\tEc$.
Let $T$ be the set of terms in $\tEc$ whose types are finite datatypes.
For each term $t \in T$,
let $\SSSS 0_t$ be the set $\{ t \}$,
for $i \geq 0$ let $\SSSS {i+1}_t =$ $\SSSS i_t \mathrel\cup \{ \const s( u ) \mid u : \upsilon \in \SSSS i, \upsilon \in \Data, \upsilon \text{ finite}, s \in \Sel^{\upsilon}  \}$,
and let $\SSSS \ast_t$ be the fixed point of this sequence.
We know this is a finite set for each $t$ since the values of the type of $t$ are of finite size.
Let $\SSSS \ast$ be the union of $\SSSS \ast_t$ for all $t \in T$,
and let $\tcEc$ be the set of subterms of $\Ec \mathrel\cup \{ \const C_j( \const s^1_j( t ), \ldots, \const s^{n_j}_j( t ) ) \mid t : \delta \in \SSS \mathrel\cup \SSSS \ast,\, \const C_j \in \Ctr^\delta \}$.
In a derivation tree with root node~$\Ec$,
it can be shown by case analysis on the rules of the calculus that each non-root node $\Fc$ is such that
$\mathcal{T}(\Fc) \subseteq \tcEc$, and hence contains an equality between two terms from $\tcEc$ not occurring in its parent node.
Thus, the depth of a branch in a derivation tree with root node $\Ec$ is at most $\left| \smash{\tcEc}\vphantom{X} \right|{\!}^2$,
which is finite since $\tcEc$ is finite.
\qed
\end{proof}

\begin{theorem}[Refutation Soundness]%
\label{thm:rs}%
\afterDot
If there exists a closed derivation tree with root node\/ $\Ec$, then\/ $\Ec$ is $\thD$-unsatisfiable.
\end{theorem}
\begin{proof}
The proof is by structural induction on the derivation tree with root node $\Ec$.
If the tree is an application of \rn{Conflict}, \rn{Clash}, or \rn{Acyclic},
then $\Ec$ is $\thD$-unsatisfiable.
For \rn{Conflict}, this is a consequence of equality reasoning.
For \rn{Clash}, this is a consequence of distinctness.
For \rn{Acyclic}, the construction of $\Val$ indicates that the class of values that $t$ can take in models of $\Ec$ is infeasible,
and thus $\Ec$ is unsatisfiable.
If the children of $\Ec$ are closed derivation trees
whose root node is the result of applying the rule \rn{Split} on term $t$ of type $\delta$,
by the induction hypothesis $\Ec \mathrel\cup t \teq \const C_j( \const s^1_j( t ), \ldots, \const s^{n_j}_j( t ) )$ is unsatisfiable
for each $\const C_j \in \Ctr^\delta$.
Since by exhaustiveness, all models of $\thD$ entail (exactly) one equality $t \teq \const C_j( \const s^1_j( t ), \ldots, \const s^{n_j}_j( t ) )$,
we know $\Ec$ is $\thD$-unsatisfiable.
Otherwise, the child of $\Ec$ is a closed derivation tree
whose root node is $\Ec \mathrel\cup t \teq u$ obtained by applying one of the rules \rn{Refl}, \rn{Sym}, \rn{Trans}, \rn{Cong}, \rn{Inject}, \rn{Unique}, or \rn{Singleton}.
In all cases, we have that $\Ec \models_{\thD} t \teq u$.
For \rn{Refl}, \rn{Sym}, \rn{Trans}, \rn{Cong}, this is a consequence of equality reasoning.
For \rn{Inject}, this is a consequence of injectivity.
For \rn{Unique}, our construction of $\Val$ indicates that the value of $t$ and $u$ are equivalent in all models of $\Ec$.
For \rn{Singleton}, $t$~and~$u$ must have the same value since the cardinality of their type is $1$.
By the induction hypothesis, we have $\Ec \mathrel\cup t \teq u$ is $\thD$-unsatisfiable,
and thus $\Ec$ is $\thD$-unsatisfiable.
\qed
\end{proof}

It remains to show the converse of the previous theorem: When a derivation tree
with root node $\Ec$ contains a saturated node, then $\Ec$ is
$\thD$-satisfiable.
To do so, we exhibit a specific model $\M$ of $\thD$ that satisfies $\Ec$.

First, we need additional terminology concerning $\mu$-terms.
For a $\mu$-term $t$ with subterm $u$,
the \emph{interpretation of\/ $u$ in\/ $t$} is the $\mu$-term $t\interp{u}^\emptyset$ as returned by the following recursive procedure,
where $x \mapsto \MU x.\; \const{C}( \vec u ) \in t$ indicates that $\MU x.\; \const{C}( \vec u )$ is the subterm of $t$ that binds this occurrence of variable $x$:
\[\begin{array}{r@{}c@{}l}
t\interp{x}^M & {} \,=\, {} &
\textstyle\begin{cases}
    \MU x.\; \const{C}( t\interp{ \vec u}^{M \mathrel\cup \{ x \}}) & \text{if }x \not\in M, x \mapsto \MU x.\; \const{C}( \vec u ) \in t  \\[-\jot]
    x & \text{otherwise}
\end{cases} \\
t\interp{\MU x.\; \const{C}( \vec u )}^M & = &
\textstyle\begin{cases}
    \MU x.\; \const{C}( t\interp{ \vec u }^{M \mathrel\cup \{ x \}} ) & \text{if }x \not\in M \\[-\jot]
    x & \text{otherwise}
\end{cases}
\end{array}\]
We write $t\interp{u}$ to abbreviate $t\interp{u}^\emptyset$.

Given a $\mu$-term $t$ of the form $\MU x.\; \const{C}( t_1, \ldots, t_n )$ with subterm $u$,
we say $u$ is a \emph{bisimilar subterm} of $t$ if it is of the form
$\MU y.\; \const{C}( u_1, \ldots, u_n )$ and $t\interp{ t_k } \aequiv t\interp{ u_k }$ for $k = 1,\ldots, n$.
The term $t$ is \emph{normal} if it does not contain a strict, bisimilar subterm
and all of its strict subterms are also normal.
For example, the $\mu$-term $t = \MU x.\; \const{C}( \MU y.\; \const{C}( y ) )$ is abnormal,
since $\MU y.\; \const{C}( y )$ is a bisimilar subterm of $t$.
In particular, note that their arguments have the same interpretation in $t$,
that is,
$t\interp{\MU y.\; \const{C}( y )}^\emptyset =$
$\MU y.\; \const{C}( t\interp{y}^{\{y\}} ) =$
$\MU y.\; \const{C}( y )$
is $\alpha$-equivalent to
$t\interp{y}^\emptyset =$
$\MU y.\; \const{C}( t\interp{y}^{\{y\}} ) =$
$\MU y.\; \const{C}( y )$.
The $\mu$-term $t$ of the form $\MU x.\; \const{C}( \MU y.\; \const{C}( x ) )$ is also abnormal,
since $\MU y.\; \const{C}( x )$ is a bisimilar subterm of $t$,
noting that
$t\interp{\MU y.\; \const{C}( x )}^\emptyset =
\MU y.\; \const{C}( t\interp{x}^{\{y\}} ) =
\MU y.\; \const{C}( t\interp{\MU x.\; \const{C}( \MU y.\; \const{C}( x ) ) }^{\{y\}} ) =
\MU y.\; \const{C}( \MU x.\; \const{C}( t\interp{\MU y.\; \const{C}( x )}^{\{x,y\}} ) ) =
\MU y.\allowbreak\; \const{C}( \MU x.\; \const{C}( y ) )$
is $\alpha$-equivalent to $t\interp{x}^\emptyset = t$.
% for the renaming $\{ x \mapsto y, y \mapsto x \}$.

For any $\mu$-term $t$ of the form $\MU x.\; \const C( \vec u )$, we can
recursively construct its \emph{normal form} $\nf{t}$,
which is a renaming of $v$ by replacing all of the bisimilar subterms of $t$ with $x$
%and by replacing all of the abnormal subterms of $t$ with their corresponding normal forms.
and by normalizing $t$'s subterms.
For example, $\nf{\MU x.\; \const{C}( \MU y.\; \const{C}( x ) )} = \MU x.\; \const{C}( x )$.

\begin{lemma}
\label{lem:mu-norm-arg}
If $\vec u$ are in normal form and $t = \nf{\MU x.\; \const{C}( \vec u )} = \MU x.\; \const{C}( \vec w )$,
then $\vec u \vsim t\interp{\vec w}$.
\end{lemma}
\begin{proof}
%Since $u_k$ is normal, $w_k$ is the result of replacing all subterms $v$ of $u_k$ such that $t\interp{v} \aequiv t$ with $x$.
\rem{TODO}
\end{proof}

\begin{lemma}
\label{lem:mu-cong}
If $t_u = \MU x.\; \const{C}( \vec u )$ and $t_w = \MU y.\; \const{C}( \vec w )$ are in normal form,
then $t_u\interp{ \vec u } \vsim t_w\interp{ \vec w }$ if and only if $t_u \vsim t_w$.
\end{lemma}
\begin{proof}
\rem{TODO}
\end{proof}

We now define a class of models that we consider for a saturated set of equalities~$\Ec$.
Let $\M( \tau )$ denote the interpretation type $\tau$ in $\M$,
that is, a set of domain elements for that type.
For a term $t$, let $\M( t )$ denote the interpretation of $t$ in $\M$,
that is, an element of $\M( \tau )$ where $\tau$ is the type of $t$.
\rem{Clarify that non-codatatype terms are interpreted as $\mu$-terms, although dropping the $\mu$'s gives the standard representation?
(GOOD IDEA. A BIT OF REDUNDANCY CANNOT HURT.)}

\begin{definition}[Normal Model]
\afterDot%
\label{def:norm-model}%
\rm
A model $\M$ is \emph{normal} if these conditions are met:
\begin{enumerate}
\item
For all types $\tau$,
$\M( \tau )$ is a maximal set of closed normal $\mu$-terms of that type that are
unique up to renaming of $\mu$-bound variables,
and acyclic when $\tau \not\in \Codata$.
\item
For all constructor terms $\const{C}( \vec t \,)$ of type $\tau$,
$\M( \const{C}( \vec t \,) )$ is the value
in $\M( \tau )$ that is $\alpha$-equivalent to
$\nf{\MU x.\; \const{C}( \M( \vec t \,) )}$ where $x$ is fresh.
\item
For all selector terms $\const s^k_j( t )$ of type $\tau$, % for some $\vec u$,
$\M( \const s^k_j( t ) )$ is the value
in $\M( \tau )$ that is $\alpha$-equivalent to
$\M( t )\interp{u_j}$
when $\M( t )$ is of the form $\MU x.\; \const{C}_j( \vec u )$.
\end{enumerate}
\end{definition}

In the following, we consider only normal models.
When constructing a model $\M$ for $\Ec$,
it remains only to define how $\M$ interprets wrongly applied selector terms and variables.
For the latter, this will be based on the mapping $\Val$ constructed in phase~2 of the calculus.
We compute the \emph{completion} $\Val^\ast$ of $\Val$ for normal model $\M$
by assigning values from $\M$ to unassigned variables in the domain of $\Val$.

%First, we need the following definition.
We write $t \vsimv{x} u$ if $\mu$-terms $t$ and $u$ are syntactically equivalent
for some renaming that avoids capturing any variable other than $x$.
For example,
$\MU x.\; \const{D}( x ) \vsimv{y} \MU x.\; \const{D}( y )$,
$\MU x.\; \const{C}( x, x ) \vsimv{x} \MU y.\; \const{C}( x, y )$ and
$\MU x.\; \const{C}( z, x ) \vsimv{z} \MU y.\; \const{C}( z, y )$,
but
$\MU x.\; \const{D}( x ) \not\vsimv{x} \MU x.\; \const{D}( y )$ and
$\MU x.\; \const{C}( x, x ) \not\vsimv{y} \MU y.\; \const{C}( x, y )$.
For a variable $x : \tau$ and a fixed normal model $\M$,
we write $\mathcal{T}^\M_x( \Val )$ to denote the set consisting of all values $v$ from $\M( \tau )$
such that $v \vsimv{x} t\interp{u}$ for some term $t$ with subterm $u$ occurring in the range of $\Val$.

We construct $\Val^\ast$ by exhaustively applying the following rule to $\nf{\Val}$:
\[
\hbox{\(
\inferrule{
  {\Varec{x}} : \tau \in \FV( \Val )
  \quad
  \MU {\Varec{x}}.\; t \aequiv v
  \quad
  v \in \M( \tau )
  \quad
  v \not\in \mathcal{T}^\M_{\Varec{x}}(\Val)
}{
  \Val := \nf{\Val \{ {\Varec{x}} \mapsto \MU {\Varec{x}}.\; t \}}
}
\)
%\rn{Assign}}
\]
%
The rule chooses an unassigned variable in $\Val$
and assigns it a value that is not $\alpha$-equivalent to one occurring in $\mathcal{T}^\M_x(\Val)$.
Since this update removes one variable from the set $\FV( \Val )$ and does not add any variables to $\FV( \Val )$,
it can only be applied a finite number of times.
After assigning this value, we normalize all terms in the range of $\Val$.

\begin{examplex}
Let $\delta$ be a codatatype with the constructors $\const{C}, \const{D}, \const{E} :\delta \rightarrow \delta$.
Let $\Ec$ be the set
$\{
w_1 \teq \const{C}( x ),\;
w_2 \teq \const{E}( w_3 ),\;
x \not\teq y_2,\;
y_1 \teq \const{C}( y_2 ),\;
y_2 \teq \const{D}( x ),\;
z_1 \teq \const{E}( z_2 ),\;
z_2 \teq \const{C}( z_1 )
\}$.
After running the calculus to saturation on $\Ec$, the mapping $\Val$ contains
\[\begin{array}{r@{}c@{}l@{\;}l@{\qquad}r@{}c@{}r@{\;}l@{}l@{\;}l}
\Val \ec{w_1} & {}\,=\,{} & \MU {\Varec{w_1}}. & \const{C}( {\Varec{x}} ) &
\Val \ec{y_1} & {}\,=\,{} & \MU {\Varec{y_1}}. & \const{C}( & \MU {\Varec{y_2}}. & \const{D}( {\Varec{x}} ) ) \\
\Val \ec{w_2} & = & \MU {\Varec{w_2}}. & \const{E}( {\Varec{w_3}} ) &
\Val \ec{y_2} & = & \MU {\Varec{y_2}}. & \multicolumn{2}{@{}l@{}}{\const{D}( {\Varec{x}} )} \\
\Val \ec{w_3} & = & {\Varec{w_3}} &&
\Val \ec{z_1} & = & \MU {\Varec{z_1}}. & \const{E}( & \MU {\Varec{z_2}}. & \const{C}( {\Varec{z_1}} ) ) \\
\Val \ec{x} & = & {\Varec{x}} &&
\Val \ec{z_2} & = & \MU {\Varec{z_2}}. & \const{C}( & \MU {\Varec{z_1}}. & \const{E}( {\Varec{z_2}} ) )
\end{array}\]
%
To construct a completion of $\Val$, we must choose values for the free variables of $\Val$,
namely ${\Varec{w_3}}$ and ${\Varec{x}}$.
The content of the set \smash{$\mathcal{T}^\M_{{\Varec{x}}}( \Val )$} is $\alpha$-equivalent to
\[%\begin{array}{c}
\{
\MU x.\; \const{C}( x ),\;
\MU x.\; \const{C}( \const{D}( x )),\;
\const{C}( \MU x.\; \const{D}( x )),\;
\MU x.\; \const{C}( \const{E}( x )),\;
\MU x.\; \const{D}( x ),\;
\MU x.\; \const{E}( \const{C}( x ))
\}
%\end{array}
\]
Consider a model $\M$ that interprets variables in $\Ec$ based on the mapping $\Val$:
$x$ is interpreted as $\Val \ec{x}$, $y_1$ as $\Val \ec{y_1}$, and so on.
Assigning a value for ${\Varec{x}}$ that is $\alpha$-equivalent to a value in $\mathcal{T}^\M_{{\Varec{x}}}( \Val )$
may cause values in the range of $\Val$ to become $\alpha$-equivalent,
which in turn may cause $\M$ to be inconsistent.
For example, assign $\MU {\Varec{x}}.\; \const{D}( {\Varec{x}} )$ for ${\Varec{x}}$.
After this substitution, $\Val \ec{y_2}$ is $\MU {\Varec{y_2}}.\; \const{D}( \MU {\Varec{x}}.\; \const{D}( {\Varec{x}} ) )$,
which has normal form $\MU {\Varec{y_2}}.\; \const{D}( {\Varec{y_2}} )$,
which is $\alpha$-equivalent to $\MU {\Varec{x}}.\; \const{D}( {\Varec{x}} )$.
However, this contradicts the disequality $x \not\teq y_2$ in~$\Ec$.
On the other hand, if the value assigned to ${\Varec{x}}$ is not $\alpha$-equivalent to any term in $\mathcal{T}^\M_{{\Varec{x}}}( \Val )$,
the values in the range of $\Val$ remain $\alpha$-disequivalent.
For example, we may assign values such as 
$\MU {\Varec{x}}.\; \const{E}( {\Varec{x}} )$,
$\MU {\Varec{x}}.\; \const{E}( \MU x_1.\; \const{C}( x_1) )$, or
$\MU {\Varec{x}}.\; \const{D}( \const{C}( {\Varec{x}} ) )$
to ${\Varec{x}}$.
Legal substitutions for ${\Varec{x}}$ may cause the range of $\Val$ to contain abnormal terms.
After applying the substitution for the third term mentioned above,
$\Val \ec{w_1}$ is $\MU {\Varec{w_1}}.\; \const{C}( \MU {\Varec{x}}.\; \const{D}( \const{C}( {\Varec{x}} ) ) )$,
which has normal form
$\MU {\Varec{w_1}}.\; \const{C}( \MU {\Varec{x}}.\; \const{D}( {\Varec{w_1}} ) )$.
\xend
\end{examplex}

We first state the following properties of $\Val^\ast$,
where we write $\muvar( t )$ to denote $t$ if $t$ is a variable, or ${\Varec{x}}$ if $t$ is of the form $\MU {\Varec{x}}.\; u$.

\begin{lemma}
\label{lem:model-completion}
If $\Val$ is constructed for a saturated set $\Ec$
and $\Val^\ast$ is a completion of $\Val$ for normal model $\M$, the following holds:
\begin{enumerate}
\item[\rm 1.] $\Val^\ast \ec{x}$ is $\alpha$-equivalent to a value in $\M( \tau )$, where $\ec{x}$ has type $\tau$.
\item[\rm 2.]
All subterms $t$ of $\Val^\ast \ec{y}$ with $\muvar(t) = {\Varec{x}}$ are such that
$\Val^\ast \ec{y} \interp{ t } = \Val^\ast \ec{x}$. 
%If $\const{C}( t_1, \ldots, t_n ) \in \ec{x}$,
%then all subterms $\MU v_{\ec{x}}.\; u$ occurring in $\Val^\ast \ec{y}$ 
%are of the form $\MU v_{\ec{x}}.\; \const{C}( w_1, \ldots, w_n )$,
%where 
%and $\Val^\ast \ec{y} \interp{ w_i } = \Val^\ast \ec{t_i}$ for $i = 1, \ldots, n$.
%If $\Val^\ast \ec{x}$ contains a subterm of the form $\MU v_{\ec{x}}.\; \const{C}( w_1, \ldots, w_n )$,
%and $\muvar( w_i ) = v_{\ec{t_i}}$ for $i = 1, \ldots, n$,
%\item
%$t_1 \interp{ t_2 } = \Val^\ast \ec{x}$
%for all $t_1$ with subterm $t_2$ in the range of $\Val^\ast$ where $\muvar(t_2)={\Varec{x}}$,
\item[\rm 3.]
$\Val^\ast \ec{x} \vsim \Val^\ast \ec{y}$ if and only if $\ec{x} = \ec{y}$.
\end{enumerate}
\end{lemma}
\begin{proof}
To show 1, we first show that $\Val^\ast$ contains no free variables.
Assume by contradiction that $\Val^\ast$ contained a free variable ${\Varec{y}}$ for some $\ec{y}$ of type $\tau$.
Then it must be the case that $\ec{y}$ does not contain a constructor term,
or else ${\Varec{y}}$ would not occur as a free variable in $\Val$.
Consider the case when $\tau$ is finite.
By assumption, $\tau \not\in \Nondata$.
Since \rn{Split} does not apply to $\Ec$, we have $\tau \not\in \Data$.
If $\tau \in \Codata$, then $\tau$ is corecursive by assumption, and by Lemma~\ref{lem:corecursive-singletons},
the cardinality of $\tau$ must be $1$.
Since \rn{Singleton} does not apply to $\Ec$,
there is only one equivalence class of type $\tau$ in $\Ec$,
and thus there are no terms in $\mathcal{T}^\M_x(\Val^\ast)$ of type $\tau$.
This is a contradiction, since our model completion may assign the value in the domain of $\tau$ to ${\Varec{x}}$.
Now, consider the case when $\tau$ is infinite.
This is also a contradiction,
since there are only a finite number of closed terms in $\mathcal{T}^\M_x(\Val^\ast)$,
and thus our model completion can assign a value not occurring in $\mathcal{T}^\M_x(\Val^\ast)$ to ${\Varec{y}}$.
By construction, $\Val^\ast \ec{x}$ is normal.
Since \rn{Acyclic} does not apply, $\Val \ec{x}$ is acyclic when $\tau \in \Data$.
Moreover, our construction of $\Val^\ast$ applies substitutions of the form
$\{ y \mapsto t \}$, where $t$ is acyclic when the type of $y$ is not a codatatype.
Thus, $\Val^\ast \ec{x}$ is acyclic when $\tau \not\in \Codata$.
Therefore, by definition, $\Val^\ast \ec{x}$ is $\alpha$-equivalent to a value in $\M( \tau )$.

We first show that 2 and 3 hold initially for $\Val$.
Since \rn{Clash} does not apply to $\Ec$,
for all equivalence classes $\ec{z}$,
each pair of constructor terms $\const{C}_j( \vec t )$ and $\const{C}_{j'}( \vec u )$ in $\ec{z}$
are such that $j = j'$ since \rn{Clash} does not apply to $\Ec$,
and are such that $\ec{ \vec t } = \ec{ \vec u }$ since \rn{Decomp} does not apply to $\Ec$.
Thus, 
$\Val$ was constructed by applying a sequence of substitutions
where all substitutions for each variable ${\Varec{z}}$ 
were uniquely of the form $\{ {\Varec{z}} \mapsto \const{C}_j( {\Varec{t_1}}, \ldots, {\Varec{t_n}} ) \}$
for $\ec{z}$ that contain a constructor $\const{C}_j( t_1, \ldots, t_n )$.
Say $\Val \ec{y}$ has a subterm $t$ where $\muvar(t) = {\Varec{x}}$.
Both $\Val \ec{x}$ and the subterm $t$ of $\Val \ec{y}$ were
constructed by applying a sequence of substitutions of the form mentioned above to ${\Varec{x}}$.
Moreover, free variables ${\Varec{z}}$ in $\MU {\Varec{x}}.\; t$ that are bound in $\Val \ec{y}$ are interpreted in 
the expansion of $\Val \ec{y} \interp{ \MU {\Varec{x}}.\; t }$ as a term
constructed by a sequence of substitutions of the form mentioned above to ${\Varec{z}}$. \rem{more detail}
Thus, we have
$\Val \ec{y} \interp{ \MU {\Varec{x}}.\; t } = \Val \ec{x} \interp{ \Val \ec{x} } = \Val \ec{x}$, and thus 2 holds for $\Val$.
Statement 3 holds for $\Val$ since \rn{Unique} does not apply.

We now show that $\Val = \nf{(\Val)}$.
Assume by contradition $\Val \ec{x} \neq \nf{(\Val \ec{x})}$ for some $\Val \ec{x}$ of minimal size.
We have that $\Val \ec{x}$ is of the form $\MU {\Varec{x}}.\; \const{C}( t_1, \ldots, t_n )$.
Due to our construction of $\Val$, 
we know $\ec{x}$ contains a constructor $\const{C}( z_1, \ldots, z_n )$ and $\muvar( t_i ) = z_i$ for $i = 1, \ldots, n$.
Since $\Val \ec{x}$ is a minimal, it
contain a subterm of the form $\MU {\Varec{y}}.\; \const{C}( u_1, \ldots, u_n )$
where $\Val \ec{x} \interp{ t_i } \aequiv \Val \ec{x} \interp{ u_i }$ for $i = 1, \ldots, n$.
Due to our construction of $\Val$, $\ec{y}$ contains a constructor $\const{C}( w_1, \ldots, w_n )$ and $\muvar( u_i ) = w_i$ for $i = 1, \ldots, n$.
Since \rn{Cong} does not apply to $\Ec$
we have $\ec{w_j}$ and $\ec{z_j}$ are distinct for some $j$.
By statement 2, $\Val \ec{x} \interp{ t_j } = \Val \ec{z_j}$
and $\Val \ec{x} \interp{ u_j } = \Val \ec{w_j}$,
which are not $\alpha$-equivalent by statement 3, contradicting the fact that $\MU {\Varec{y}}.\; \const{C}( u_1, \ldots, u_n )$ is a bisimilar subterm of $\Val \ec{x}$.
Thus, $\Val = \nf{(\Val)}$, and statements 2 and 3 hold for $\nf{(\Val)}$.
%For each $i = 1, \ldots, n$,
%if ${\Varec{z_i}} = {\Varec{w_i}}$, then $w_i \teq z_i \in \Ec$.
%If ${\Varec{z_i}} \neq {\Varec{w_i}}$, then by statement 2, $\Val \ec{x} \interp{ t_i } = \Val \ec{z_i}$
%and $\Val \ec{x} \interp{ u_i } = \Val \ec{w_i}$.
%By statement 3, we have that $\ec{z_i} = \ec{w_i}$, and thus $u_i \teq t_i \in \Ec$ for each $i = 1, \ldots, n$.
%This is a contradiction since $\ec{x}$ and $\ec{y}$ are distinct, and \rn{Cong} does not apply to $\Ec$.
%Thus, statements 2 and 3 hold for $\nf{(\Val)}$.

We now show that if 2 and 3 hold for some $\Val_1$,
then 2 and 3 also hold for $\nf{(\Val_1 \sigma)}$,
where $\sigma$ is a substitution of the form $\{ {\Varec{x}} \mapsto \MU {\Varec{x}}.\; t \}$,
where $\MU {\Varec{x}}.\; t$ is not $\alpha$-equivalent to a term in $\mathcal{T}^\M_{\Varec{x}}(\Val)$.


%\rem{TODO}
%Thus, the set of subterms which $\Val \ec{x}$ and $\MU v_{\ec{x}}.\; t$ differ 
%of the form $\MU {\Varec{z}}.\; u$ and $v_{\ec{z}}$ respectively, where $v_{\ec{z}}$ is a bound variable in $\Val \ec{y}$.
%In the latter case, $\Val \ec{y} \interp{ {\Varec{z}} } = \MU {\Varec{z}}.\; \const{C}( \Val \ec{y} \interp{\vec u} )$,
%where $\MU v_{\ec{z}}.\; u$ and $\MU v_{\ec{z}}.\; u'$ were constructed by applying a sequence of substitutions of the form above to $v_{\ec{z}}$.
%Since $\Val^\ast$ is obtained by applying the same substitutions and normalizations to all terms in the range of $\Val$,
%we have $\Val^\ast \ec{y} \interp{ \MU {\Varec{x}}.\; t} = \Val^\ast \ec{x}$.

%To show 3,
%first note that since \rn{Unique} does not apply,
%$\Val \ec{x} \aequiv \Val \ec{y}$ if and only if $\ec{x} = \ec{y}$.
%Due to part 2, we have $\Val = \nf{(\Val)}$, and thus
%$\nf{(\Val \ec{x})} \aequiv \nf{(\Val \ec{y})}$ if and only if $\ec{x} = \ec{y}$.
%We show that for any substitution $\sigma$ applied to $\Val$ while constructing its completion is such that
%$\nf{(\Val \ec{x} \sigma)} \aequiv \nf{(\Val \ec{y} \sigma)}$ if and only if $\ec{x} = \ec{y}$.
%\rem{TODO}
%Let $P$ be the set of positions for which $\Val \ec{x}$ and $\Val \ec{y}$ are not $\alpha$-equivalent,
%which is non-empty by assumption.

\qed
\end{proof}

\begin{theorem}[Solution Soundness]%
\label{thm:ss}%
\afterDot
If there exists a derivation tree with root node $\Ec$ containing a saturated node, then $\Ec$ is $\thD$-satisfiable.
\end{theorem}
\begin{proof}
Let $\Fc$ be a saturated node in a derivation tree with root node $\Ec$.
%We will construct a model $\M$ for a set of equalities $\Fc$ that is equivalent to $\Fc_0$, and where
%all equivalence classes of $\Fc$ contain at least one variable, and all selectors in $\Fc$ are applied to variables only.
%The former comes with no loss of generality since new equalities of the form $y \teq t$ for fresh variable $y$ can be added to $\Fc$ without affecting its satisfiability,
%The latter also comes with no loss of generality since nested applications of selectors in $\Fc_0$ can be replaced by fresh variables while adding equalities to $\Fc$.
We consider a normal model $\M$
that interprets wrongly applied selectors based on equality information in $\Fc$,
and interprets the variables of $\Fc$ based on the completion $\Val^\ast$ of the mapping $\Val$ from phase~2.
For the latter, let $\M( x )$ be the value in $\M$ that is $\alpha$-equivalent with $\Val^\ast \ec{x}$ for each variable $x$ in $\mathcal{T}(\Fc)$.

We first show $\M$ satisfies all equalities in $t_1 \teq t_2 \in \Fc$, where $t_1$ and $t_2$ have type $\tau$.
We show,
by structural induction on $t$,
that $\M( t ) \aequiv \Val^\ast \ec{t}$ for all terms $t \in \mathcal{T}( \Fc )$,
which since $\M$ is normal, implies $\M \models t_1 \teq t_2$.

If $t$ is a variable, then $\M( t ) \vsim \Val^\ast \ec{ t }$ by construction.

If $t$ is a constructor term of the form $\const{C}( u_1, \ldots, u_n )$,
then $\M( t )$ is $\alpha$-equivalent with $\nf{\MU x.\; \const{C}( \M( u_1 ), \ldots, \M( u_n ) ) }$ for some fresh $x$,
which by the induction hypothesis is $\alpha$-equivalent with $\nf{\MU x.\; \const{C}( \Val^\ast \ec{ u_1 }, \ldots, \Val^\ast \ec{ u_n } )}$, call this term $t_u$.
By Lemma~\ref{lem:model-completion}.2 and due to our construction of $\Val^\ast$, we have $\Val^\ast \ec{t}$ is a term
$t_w$ of the form $\MU {\Varec{t}}.\; \const{C}( w_1, \ldots, w_n )$
where $t_w\interp{w_i} = \Val^\ast \ec{u_i}$ for $i = 1, \ldots, n$.
For each $i = 1, \ldots, n$, let $u_i'$ be the $i$\vvthinspace th argument of $t_u$.
By Lemma~\ref{lem:mu-norm-arg}, $t_u\interp{u_i'} \vsim \Val^\ast \ec{u_i}$,
and thus $t_u\interp{u_i'} \vsim t_w\interp{ w_i }$. % for each $i = 1, \ldots, n$.
By Lemma~\ref{lem:mu-cong}, we have $t_u \vsim t_w$.
Since $\M( t ) \vsim t_u \vsim t_w = \Val^\ast \ec{t}$,
we have $\M( t ) \vsim \Val^\ast \ec{t}$.

If $t$ is a selector term of the form $\const s^j_k( u )$,
since \rn{Split} does not apply,
$\ec{u}$ must contain a term of the form $\const C_j( \const s^1_j( u ), \ldots, \const s^{n}_j( u ) )$ for some $j$.
By Lemma~\ref{lem:model-completion}.2 and due to our construction of $\Val^\ast$, we have $\Val^\ast \ec{u}$ is a term $t_w$ of the form
$\MU {\Varec{u}}.\; \const C_j( w_1, \ldots, w_n )$,
where $t_w \interp{ w_j } = \Val^\ast \ec{ \const s^j_k( u )}$. 
If $k = i$, then $\M( t )$ is $\alpha$-equivalent with $t_w\interp{w_j} = \Val^\ast \ec{ \const s^j_k( u )}$,
which is $\Val^\ast \ec{t}$.
If $k \neq i$, we interpret $\const s^j_k( \M( u ) )$ as the value in $\M( \tau )$ that is $\alpha$-equivalent with $\Val^\ast \ec{ t }$.
Since \rn{Cong} does not apply and due to Lemma~\ref{lem:model-completion}.3,
pairs of wrongly applied selectors are assigned the same value if and only if they reside in the same equivalence class,
and thus this definition is well-defined.

We now show that all disequalities in $\Fc$ are satisfied by $\M$.
Say $t_1 \tneq t_2 \in \Fc$.
Since \rn{Conflict} does not apply, $t_1 \teq t_2 \not\in \Fc$ and thus $\ec{t_1}$ and $\ec{t_2}$ are distinct.
Since $\M( t_1 ) \vsim \Val^\ast \ec{t_1}$ and $\M( t_2 ) \vsim \Val^\ast \ec{t_2}$,
by Lemma~\ref{lem:model-completion}.3, $\M( t_1 ) \neq \M( t_2 )$, and thus $\M \models t_1 \tneq t_2$.

Since by assumption $\Fc$ contains only equalities and disequalities, we have $\M \models \Fc$,
and since $\Fc$ is a superset of $\Ec$, we have that $\Ec$ is satisfied by $\M$.
\qed
\end{proof}

By Theorems~\ref{thm:t},~\ref{thm:rs}, and~\ref{thm:ss}, the calculus is sound and complete for $\thD$.

\section{Extension to Quantified Formulas}
\label{sec:extension-to-quantified-formulas}

  * universal conjecture is no problem:
    * falls into the ground fragment via negation
      and skolemization
  * nor is existential axiom a problem
  * what's interesting: universal axioms and existential conjectures

Blah.

\section{Implementation as a Theory Solver in CVC4}
\label{sec:the-theory-solver}

This section describes how the calculus in Section~\ref{sec:a-ground-decision-procedure-for-co-datatypes} is implemented within the SMT solver CVC4.

\paragraph{Optimizations}
We first discuss several optimizations that are not reflected in the presentation of the calculus, which closely follow the approach outlined by Barrett et al in~\cite{}.
We only briefly mention these optimizations, since each applies to datatypes as well as codatatypes, and most have been presented thoroughly in~\cite{}.

Discriminators are treated as predicate symbols, so a discriminator $\const{d}_j( t )$ is such that $\const{d}_j$
is a predicate symbol, instead of reducing this constraint to $t \teq \const{C}_j( \const s^1_j( t ), \ldots, \const s^n_j( t ) )$.
We have found that this leads to better performance since this reduction introduces terms more eagerly to $\tEc$.
Handling discriminators requires extending the decision procedure with several additional rules (see~\cite{} for more details), which apply uniformly to both datatypes and codatatypes.
Also, selectors are collapsed eagerly:
if $\const s^k_j( t )$ is a term in $\tEc$ and $t$ contains the constructor
$\const{C}_j( \vec u )$, we immediately infer $\const s^k_j( t ) \teq u_k$, whereas the calculus we presented would apply \rn{Split} and \rn{Inject} before inferring this equality.
For the sake of reducing the number of unique constraints considered by the calculus, we compute a normal form for constraints as a preprocessing step.
In particular, we
replace $t \teq s$ by $s \teq t$ if $s$ is less than $t$ based on a term ordering,
replace $\const{C}_j( \vec t ) \teq \const{C}_{j'}( \vec u )$ with $\bot$ when $j \neq j'$,
replace all selector terms of the form $\const{s}^{\,k}_j( \const{C}_j(t_1,\ldots,t_n) )$ by $t_k$,
and replace all occurrences of discriminators $\const{d}_j( \const{C}_{j'}( \vec t ) )$ by $\top$ if $j=j'$ and $\bot$ otherwise.

\paragraph{Integration into DPLL(T)}
The calculus is implemented as \emph{theory solver} of CVC4,
that is, a specialized solver for determining the satisfiability of conjunctions of constraints for its theory.
Given a theory $T = T_1 \mathrel\cup \ldots T_n$ and a input set of clauses $F$ in CNF,
the DPLL(T) \rem{CDCL(T)?} procedure
(incrementally) builds partial assignments from the atomic formulas of $F$ to truth values such that no clause in $F$ is falsified.
We may interpret this partial assignment as a set of literals where $a \in M$ for all atoms $a$ that it assigned the value $\top$, and $\neg a \in M$ for all atoms that it assigns the value $\bot$.
Then, at a high level, by the Nelson--Oppen combination framework,
each $T_i$-solver for $i = 1, \ldots, l$ takes as input a combination of (1) the purified form of $T_i$-constraints occurring in $M$ where terms containing symbols not belonging to $T_i$ are replaced by fresh variables of the same type,
(2) additional equalities and disequalities between variables of types not belonging to $T_i$.
Let us call this set $M_i$.
Each $T_i$ solver either
reports that a subset $C$ of $M_i$ is $T_i$-unsatisfiable, in which case $\neg C$ is added to $F$,
adds a clause $C$ to $F$,
or does nothing.
When $M$ is a complete assignment for $F$, a theory solver can only choose to do nothing when $M_i$ is indeed $T_i$-satisfiable.

Assume $\Ec$ is initially the set $M_i$ described above.
For each equality added to $\Ec$, we associate a set of equalities from $M_i$ that together entail $t \teq s$,
which we call its \emph{explanation}.
Similarly, each $\Val \ec{x}$ is also associated an explanation, that is,
a set of equalities from $M_i$ that entail that the values of $\ec{x}$ in models of $\Ec$ are of the form $\Val \ec{x}$.
For example, if $x \teq \const{C}( x ) \in M_i$, then $x \teq \const{C}( x )$ is a (possible) explanation for $\Val \ec{x} = \MU {\Varec{x}}.\; \const{C}( {\Varec{x}} )$.
Thus, the rules of the calculus are implemented as follows.
For all rules with conclusion $\bot$,
we report the union of the explanations for all premises is $\thD$-unsatisfiable.
For the \rn{Split} rule, we add a clause of the form
$(\const{C}_1( \const s^1_1( t ), \ldots, \const s^{n_1}_1( t ) ) \vee \ldots \vee t \teq \const{C}_m( \const s^1_m( t ), \ldots, \const s^{n_m}_m( t ) ))$
to $F$.
Notice that decisions on which branch to take are thus performed externally by the SAT solver, and not by the theory solver.
All other rules add equalities to the internal state of the theory solver.
The rules in phase~1 (along with the optimization for collapsing selectors) and the \rn{Singleton} rule are performed eagerly,
that is for partial satisfying assignments $M$, while the rules in phase~2 and the \rn{Split} rule are performed only for complete satisfying assignments $M$,
and in that order.

    * sharing is caring (let's cite it for a change)
    * theory combination more complicated (and Theorem Completeness too weak)


%\section{Examples}
%\label{sec:examples}

\section{Evaluation on Isabelle Problems}
\label{sec:experimental-results}

\newcommand\gandl{G\&L}
\newcommand\HD[1]{\hbox to2.5em{\hfill#1\hfill}}

\begin{table*}[tbh!]
\normalsize
\begin{center}\begin{tabular}{l@{\kern1.5em}c@{\kern.5em}c@{\kern.5em}c@{\kern1.5em}c}
  & \HD{Distro} & \HD{AFP} & \HD{\gandl} & All
\MIDRULE
No (co)datatypes
  & 221 & 760 & \phantom{0}57 & 1038 \\
Datatypes without acyclicity
  & 227 & 765 & \phantom{0}57 & 1049 \\
Datatypes with acyclicity
  & 227 & 771 & \phantom{0}57 & 1055 \\
Codatatypes without uniqueness
  & 217 & 787 & \phantom{0}55 & 1059 \\
Codatatypes with uniqueness
  & 218 & 787 & \phantom{0}58 & 1063 \\
Full (co)datatypes
  & 224 & 798 & \phantom{0}58 & 1080 \\[\jot]
Total number of goals
  & 879 & 2974\phantom{0} & 317 & 4170
\end{tabular}\end{center}
\caption{\,Number of solved goals for the three benchmark suites}
\label{tab:bench}
\end{table*}

To evaluate the decision procedure, we generated problems from existing
Isabelle formalizations using Sledgehammer \cite{paulson-blanchette-2010}.
Codatatypes being a recent addition to Isabelle
\cite{blanchette-et-al-2014-impl}, benchmarks are somewhat hard to come by. We
included the theory files from the Isabelle distribution (Distro) and the \emph{Archive
of Formal Proofs} (AFP) \cite{klein-et-al-afp} that define codatatypes falling
within the supported fragment. We also included two unpublished theories by
Peter Gammie and Andreas Lochbihler (\gandl), about Bird and Stern--Brocot trees.
To also exercise the the support
for datatypes, the benchmarks are complemented by theories about various list
and tree data structures. The theory files were selected before running the
experiments. The experimental data is publicly available \cite{our-eval-data}.

For each goal in each theory file, Sledgehammer was invoked to select
256~lemmas as axioms, which were then monomorphized and translated to SMT-LIB
along with the goal \cite{boehme-2012-phd}. The resulting problem was given to
CVC4, running for up to \textbf{TODO: XXX} seconds on the StarExec cluster
\cite{xxx}. Problems involving no (co)datatypes were filtered out.
Due to the lack of machinery for reconstructing inferences about (co)datatypes
in Isabelle, CVC4 is trusted as an oracle in these experiments.

CVC4 was run on each problem several times, with the support for datatypes and
codatatypes either enabled or disabled. The contributions of the acyclicity and
uniqueness rules were also measured, so find out whether these somewhat
expensive rules are useful in practice. Even when the decision procedure is
disabled, some of the generated axioms typically include basic properties of
constructors and selectors, which the decision procedure would recognize as
tautologies.
%This allows us to answer the question, \relax{What are the
%benefits of activating the decision procedure as opposed to letting
%Sledgehammer do what it would normally do?}

\newcommand\BAD[1]{\textcolor{red}{\textbf{#1}}}

%  * experience with such features is not extremely high -- e.g. arithmetic,
%    a most useful theory on lots of benchmarks, increases Sledgehammer's
%    success rate by 2 percentage points, or 4\%, with Z3 in earlier work \cite{xxx}

%  * so when analyzing statistics of this kind, with highly varied problems,
%    we must not overestimate the importance of a single trick
%  * on the other hand: every percentage point counts! cite Tom Hales

The results are summarized in Table~\ref{tab:bench}. The decision procedure
makes a difference across all theories, and an overall difference of
\BAD{4.7\%}. Moreover, every aspect of the procedure, including the more
expensive rules, make a contribution. \textbf{NOT TRUE}: What is not visible in the table, but
readily available when looking at the raw data \cite{our-eval-data}, is that
the stronger decision procedures subsume the weaker ones. In the context of
Sledgehammer, the power of interpreted (co)datatypes is roughly
comparable to that of arithmetic \cite{blanchette-et-al-2013-smt}.

%* and finally, we look in more detail at one or two such proofs, by presenting
%  it and explaining it (and, before that, understanding it)

Among the four uniqueness proofs, three corresponded to one-line
proofs in Isabelle, of the form \keyw{by}~\textit{coinduction}~\textit{auto}
\cite{blanchette-et-al-2014-impl}. The fourth proof was somewhat more elaborate:
%
\begin{quote}
\keyw{lemma} \,\textit{X0\_unique}: \,$x = \const{Node}\;0\;\const{num}\; x \Longrightarrow x = \const{X0}$ \\
\keyw{proof} \,(\textit{coinduction arbitrary}: $x$ \textit{rule}: \textit{tree.coinduct\_strong}) \\
\noindent\hbox{}\quad  \keyw{case} (\textit{Eq\_tree} $x$) \keyw{show} \textit{?case} \\
\noindent\hbox{}\qquad  \keyw{by} (\textit{subst} (1 2 3 4) \textit{Eq\_tree}) (\textit{simp add}: \textit{eqTrueI}[OF \textit{Eq\_tree}]) \\
\keyw{qed}
\end{quote}
%
\noindent
where \const{X0} is defined as $\const{X0} =
\const{Node}\;0\;\const{num}\;\const{X0}$.

\section{Conclusion}
\label{sec:conclusion}

We introduced a decision procedure for the ground theory of datatypes and
codatatypes and implemented it in the SMT solver CVC4. Our main theoretical
contribution has been the support for codatatypes. These are not very
difficult per se, but there are tricky corner cases to take care of if we care
about completeness (which we do).
%% alliteration
On the practical side, we obtained respectable results on benchmarks generated
from Isabelle theories.

This work is part of a larger program that aims at enriching automatic provers
with high-level features and at reducing the gap between automatic and
interactive theorem proving. As future work, we want to implement proof
reconstruction for CVC4's (co)datatype inferences in Isabelle. We also want to
try out CVC4 for higher-order model finding in Isabelle, as an alternative to
the counterexample generator Nitpick \cite{blanchette-nipkow-2010}. We also
see some opportunities to enrich SMT solvers with recursive and corecursive
functions. Finally, it might be possible to go further in terms of supporting
nested and mixed (co)recursion and quantified formulas over (co)datatypes in
solvers.

\def\ackname{Acknowledgment}
\paragraph{\ackname.}
We owe a great debt to Clark Barrett and Cesare Tinelli for datatype case blah
blah blah. \textbf{TODO FIXME}
Morgan Deters?
%
Our present and former bosses, Viktor Kuncak, Stephan Merz, Tobias Nipkow,
Cesare Tinelli, and Christoph Weidenbach, have either encouraged the research on
codatatype or at least endured
%tolerated?
it, both of which we are thankful for.
%
Peter Gammie and Andreas Lochbihler shared their private
theories with us so we could include them in the benchmarks.
Andrei Popescu helped clarify our thoughts regarding the axiomatization of
codatatypes. Dmitriy Traytel took part in discussions about special
cases.
%
Blanchette's research was partially supported by the Deutsche
Forschungs\-gemein\-schaft (DFG) project
\relax{Hardening the Hammer} (grant Ni\,491\slash 14-1).

\bibliographystyle{splncs03}
\bibliography{bib}{}

\end{document}
