%envcountsect,
\documentclass[a4paper,oribibl,envcountsame,draft]{llncs}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{arydshln}
\usepackage[scaled=.82]{beramono}
\usepackage{booktabs}
\usepackage{bussproofs}
\usepackage{calc}
\usepackage{cite}
\usepackage{mathptmx}
%\usepackage{txfonts}
%\usepackage{mathrsfs}
%\usepackage{pifont}
%\usepackage{smallcap}
\usepackage{mathpartir} 
\usepackage{stmaryrd}
\usepackage{subfigure}
\usepackage[usenames]{color}
%\usepackage{graphicx}
%\usepackage{newcent}
\usepackage{textcomp}
%\usepackage{tipa}
\usepackage{units}
\usepackage{url}
\usepackage{version}
\usepackage[all]{xy}

\DeclareFontFamily{OT1}{pzc}{}
\DeclareFontShape{OT1}{pzc}{m}{it}{<-> s * [1.10] pzcmi7t}{}
\DeclareMathAlphabet{\mathscr}{OT1}{pzc}{m}{it}

\DeclareMathAlphabet{\mathcal}{OT1}{pzc}{m}{it}


\newcommand\Sig{\mathrm{\Sigma}}

\newcommand\keyw[1]{\textbf{#1}}
\newcommand\const[1]{\textsf{#1}}
\newcommand\ty[1]{\textit{#1}}

\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\Ec}{\mathsf{E}}
\newcommand{\tEc}{\mathcal{T}(\Ec)}
\newcommand{\tcEc}{\mathcal{T}^\ast(\Ec)}
\newcommand{\rn}[1]{\textsf{\small #1}}
\newcommand{\cvc}{\textsc{cvc}{\small 4}\xspace}
\newcommand{\teq}{\approx}
\newcommand{\tneq}{\not\teq}
\newcommand{\rem}[1]{\textcolor{red}{[#1]}}
\newcommand{\tester}[1]{is\text{-} #1}
\newcommand{\ror}{\quad \parallel \quad}
\newcommand{\tpath}[2]{\mathcal{P}_{ #2 \rightarrow \_ }( #1 )}
\newcommand{\ttpath}[3]{\mathcal{P}_{ #2 \rightarrow #3 }( #1 )}
\newcommand{\ec}[1]{ [ #1 ] }

% change?
\newcommand{\thD}{T_{D}}

%\newcommand\Types{\mathcal{T}}
\newcommand\Types{\mathcal{Y}}
\newcommand\Funcs{\mathcal{F}}

\newcommand\Data{\Types_{\mathrm{dt}}}
\newcommand\Codata{\Types_{\mathrm{cdt}}}
\newcommand\Nondata{\Types_{\mathrm{oth}}}

\newcommand\Ctr{\Funcs_{\mathrm{ctr}}}
\newcommand\Sel{\Funcs_{\mathrm{sel}}}
%\newcommand\Plainfuncs{\Funcs_{\mathrm{other}}}


%%% For final version as well?
\usepackage[
   a4paper,
   pdftex,
   pdftitle={A Decision Procedure for (Co)datatypes in SMT Solvers},
   pdfauthor={Andrew Reynolds and Jasmin Christian Blanchette},
   pdfkeywords={},
   pdfborder={0 0 0},
   draft=false,
   bookmarksnumbered,
   bookmarks,
   bookmarksdepth=2,
   bookmarksopenlevel=2,
   bookmarksopen]{hyperref}

\urlstyle{ttstyle}

\global\def\figurename{Figure}

\DeclareSymbolFont{letters}{OML}{txmi}{m}{it}

%%% REMOVE BEFORE SUBMITTING ABSOLUTELY FINAL VERSION
\makeatletter
\ps@myheadings
\makeatother

\include{defs}

\hyphenation{data-type data-types co-data-type co-data-types}

\begin{document}

\title{A Decision Procedure for (Co)datatypes in SMT Solvers}

\author {Andrew Reynolds\inst{1} \and Jasmin Christian Blanchette\inst{2,3}}
\authorrunning {A. Reynolds \and J. C. Blanchette}
\institute{
\'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL), Switzerland
\and
Inria Nancy \& LORIA, Villers-l\`es-Nancy, France
\and
Max-Planck-Institut f\"ur Informatik, Saarbr\"ucken, Germany
}

\maketitle

\begin{abstract}
Codatatypes naturally capture potentially infinite data structures and
processes. We introduce a decision procedure that combines reasoning about
datatypes and codatatypes. The dual of the cyclicity rule for datatypes is a
bisimilarity rule that identifies observationally equal, possibly cyclic values.
The procedure is complete for the universal fragment and is compatible with the
Nelson--Oppen method. It has been implemented in the latest version of CVC4, a
modern SMT solver. An evaluation based on problems generated from Isabelle
theories demonstrates the potential of the procedure for both proving and model
finding.
\end{abstract}

%% The institutions above shouldn't count as footnotes
\setcounter{footnote}{0}

\section{Introduction}
\label{sec:introduction}

Blah.

  * briefly: datatypes and why they are useful
    * Hoare's recursive data structures
    * comparatively easy to reason about and automate
    * common in practice, esp. in computer science applications

    (terminology: freely-generated, inductive, algebraic, ..., sometimes
    with different meanings; we'll clarify below what we use)

  * less briefly: codatatypes and why they are useful
    * in Agda, Coq, Matita -- recently also in Isabelle/HOL \cite{nipkow-et-al-2002}
    * but not in SMT-LIB 2 \cite{barrett-et-al-2010}

  * single decision procedure for datatypes and codatatypes
  * datatypes are implementation following the lines of Barrett et al.
  * codatatypes were added later, motivated by the use of SMT solvers as
    backends to proof assistants (more specifically, CVC4 to Isabelle/HOL)

  * setting (Section~\ref{sec:theory-of-co-datatypes}):
    * universal formulas
    * many-sorted logic
    * mutually (co)recursive types with constructors, selectors, and
      discriminators

  * codatatypes: from a theoretical and implementational point of view, like
      datatypes but:
    * codatatypes are never empty (e.g. finite streams are rejected)

\[
      \keyw{codatatype}\; \,\ty{llist} \,=\, \const{LNil} \,\mid\, \const{LCons}(\ty{int},\, \ty{llist})
\]

    * no acyclicity (e.g. xs = lcons(0, xs) is satisfiable)
    * instead: bisimilarity check
    * (also: ``enumeration'', e.g. of streams)

  * motivation:
    * acyclicity and bisimilarity cannot be axiomatized, so they really belong in
      a decision procedure
    * other properties can be done more efficiently by a decision procedure

  * consider a natural fragment---datatypes as supported in modern SMT solvers
    and the SMT-LIB 2 standard, and codatatypes as their duals
    * mutual recursion, but no polymorphism, nested recursion

  * decision procedure is described abstractly as a calculus
    (Section~\ref{sec:the-calculus})
    * includes rewriting
    * and inferences

  * integrated with Nelson-Oppen

  * implemented in CVC4 as rewriting and a theory solver
    (\ref{sec:the-theory-solver})
    * precise strategy for applying inferences
    * about 2000 lines of code, among which 1600 are shared between datatypes
      and codatatypes

  * useful both for proving and for model finding
    * in particular, acyclicity and bisimilarity are necessary for some proofs
      (and cannot be axiomatized finitely)
    * and for model finding, without them we quickly get spurious models
    * explain how finite model finding works

%\ref{sec:examples}

  * benchmarking is often an issue -- esp. codatatypes
  * the decision procedure is evaluated on two sets of benchmarks
    (Section~\ref{sec:experimental-results}):
    * first set: hand-crafted examples
    * second set: generated from Isabelle theories using the Sledgehammer tool

Polymorphic types, nested (co)recursion, and datatype--codatatype mixtures fall

\paragraph{Related Work.}

    * point to Barrett et al. for SMT datatypes
      * about their own work, they say: "our focus is on generality and
        efficiency rather than immediacy of implementation"
      * (deal more directly with finite sorts than Barrett et al., Section 6.1)
    * additional ones since then (e.g. strings?)
    * anything about codatatypes?
      * proof assistants like Agda, Coq, etc. have them
      * Dafny, CoALP
      * also a lot of theoretical research, some of which is loosely connected,
        e.g. decision procedure for corecursive functions (Henning in Nijmegen)

    * ODDITY: Oppen 1980: single-constructor, recursive -- infinite values?

\paragraph{Conventions.}
This paper assumes a monomorphic (or many-sorted) first-order logic throughout.
A signature $\Sig = (\Types, \Funcs)$ consists of a set of types $\Types$ and a
set of function symbols $\Funcs$. Types are simply atomic sorts, with no
structure, and interpreted by nonempty domains. The set $\Types$ must contain a
distinguished type \ty{bool} interpreted as the set of truth
values. %, and may contain other interpreted types (e.g., \ty{int}, \ty{real}).
Predicates are simply functions that return $\ty{bool}$.
The metavariables $\delta, \tau$ range over types, with $\delta$ reserved
for (co)datatypes.

Function symbols are written in a sans-serif font (e.g., $\const{f}$, $\const{g}$) to
distinguish them from variables (e.g., $x$, $y$). With each function symbol \const{f}
is associated a list of argument types $\tau_1,\ldots,\tau_n$ (with $n \ge 0$)
and a return type $\tau$. This connection can be expressed compactly as
$\const{f} : \tau_1 \times \cdots \times \tau_n \to \tau$
(which collapses to $\const{f} : \tau$ if $n = 0$).
For a term $t$, the notation $t : \tau$ indicates that $t$ has type $\tau$.
Functions are applied the standard way, with $\const{f}(t_1,\ldots,t_n)$
applying the $n$-ary function symbol
\const{f} to $n$ well-typed arguments $t_1 : \tau_1$, \ldots, $t_n :
\tau_n$. Nullary function symbols are called constants and can appear without
parentheses in terms.

%* although nothing prevents composing the decision procedure with theories
%  providing polymorphic types (parametric sorts), such as for arrays (e.g., $\ty{array}(\alpha,\beta)$)

\section{Theory of (Co)datatypes}
\label{sec:theory-of-co-datatypes}

We assume a signature $\Sig = (\Types, \Funcs)$. The types are partioned into
$\Types = \Data \mathrel{\uplus} \Codata \mathrel{\uplus} \Nondata$, where $\Data$ are the
datatypes, $\Codata$ are the codatatypes, and $\Nondata$ are the remaining
types. The functions are partitioned into $\Funcs = \Ctr \mathrel{\uplus} \Sel$, where
$\Ctr$ are the constructors and $\Sel$ are the selectors. (There is no need to
consider other function symbols, because they can be abstracted away as
variables when combining theories.)

In practice (e.g., in an SMT problem), the signature is given by specifying the
uninterpreted types first (in any order), then the (co)datatypes with their
constructors and selectors in groups of mutually (co)recursive groups of
(co)datatypes, and finally any other function symbols.

A (co)datatype specification consists of $l$~mutually recursive types which are
either all datatypes or all codatatypes. Each datatype $\delta$ is equipped by
$m \ge 1$ constructors, and each constructor for $\delta$ takes zero or more
arguments and returns a $\delta$ value. The argument types must be either
plain, be or be one of the newly introduced (co)datatypes. To every
argument corresponds a selector. The introduced names for the (co)datatypes, the
constructors, and the selectors must be distinct and different from already
introduced ones.%
\footnote{In practice, it can be useful to specify the same selector
for several constructors of the same (co)datatype,
as long as the argument types coincide \cite[Section~3]{blanchette-et-al-2014-codata}.
However, this is not allowed by SMT-LIB 2.}
Schematically, using a syntax similar to Standard ML, Haskell,
or SMT-LIB:
%
\[
\begin{aligned}[t]
(\keyw{co})\keyw{datatype}\;\,
  \delta_1 & {}=\, \const{C}_{1}\rlap{${}_{1}$}\phantom{{}_{m}}(\bigl[\const{s}_{111}{:}\bigr]\; \tau_{111}, \,\ldots,\, \bigl[\const{s}_{11n_{11}}{:}\bigr]\; \tau_{11n_{11}}) & \\
           & {}\;\phantom{=\,}\;{} \smash{\,\,\,\vdots} \\[-\jot] % {}\;\phantom{=}\llap{\ensuremath{\mid}}\; \cdots \\
           & {}\;\phantom{=\,}\llap{\ensuremath{\,\mid\,}}\; \const{C}_{1m}(\bigl[\const{s}_{1m1}{:}\bigr]\; \tau_{1m1}, \,\ldots,\, \big[\const{s}_{1mn_{1m}}{:}\big]\; \tau_{1mn_{1m}}) \\[-1\jot]
   \smash{\vdots\,\,\,} \\[-1\jot]
  \keyw{and}\; \,\delta_l & =\, \ldots
\end{aligned}
\]
%
with
$\const{C}_{ij} : \tau_{ij1}\times\cdots\times\tau_{ijk_{ij}} \to \delta_i$
and $\const{s}_{ijk} : \delta_i \to \tau_{ijk}$. Defaults are assumed for
the selector names if they are omitted.

Polymorphic types, nested (co)recursion, and datatype--codatatype mixtures fall
outside this fragment. For example, the specification
\[\begin{aligned}[t]
      \keyw{datatype}\;\, \ty{tree} & \,=\, \const{Node}(\ty{int},\, \ty{forest}) \\[-\jot]
      \keyw{and}\;\, \ty{forest} & \,=\, \const{FNil} \,\mid\, \const{FCons}(\ty{tree},\, \ty{forest})
\end{aligned}
\]
is supported, whereas
\[\begin{aligned}[t]
      \keyw{codatatype}\; \,\ty{pllist}(\alpha) & \,=\, \const{PLNil} \,\mid\, \const{PLCons}(\alpha,\, \ty{pllist}(\alpha)) \\[-.5\jot]
      \keyw{datatype}\;\, \ty{tree} & \,=\, \const{Node}(\ty{int},\, \ty{pllist}(\ty{tree}))
\end{aligned}
\]
is beyond the fragment considered here. In principle, rank-1 (top-level)
polymorphism would be easy to support; nesting datatypes inside datatypes,
and likewise for codatatypes, can be reduced to the mutual case. So the only
genuinely interesting cases missing are mixed nested (co)recursion
(as in the \ty{tree} example above) as well as (co)recursion through a
non-(co)datatype (both of which make sense \cite{blanchette-et-al-2014-codata}).

Axiomatization:


discriminators go here


specifies the 

    * ``no junk, no confusion''



Because the types are inhabited (nonempty), a datatype specification is
admissible only if a ground term can be exhibited that belongs to that datatype.
This rules out ill-founded specifications such as
%
\[\keyw{datatype}\;\, \ty{fstream} \,=\, \const{FSCons}(\ty{int},\,\ty{fstream})\]
%
For codatatypes, no such check is necessary. Given the specification
%
\[\keyw{codatatype}\;\, \ty{stream} \,=\, \const{SCons}(\ty{int},\,\ty{stream})\]
%
the infinite value $\const{SCons}(0, \const{SCons}(0, \ldots))$ witnesses
nonemptiness.

Datatypes can be defined semantically as the initial model of an equational
specification of the selector--constructor equations. This is the view followed
by Barrett et al.\ \cite{barrett-et-al-2010}. A disadvantage with this approach
is that it does not naturally account for selectors applied to wrong
constructors. Barrett et al.\ address this by parameterizing the construction by
default values, but these give rise to spurious equalities between unrelated
terms (e.g., $hd(nil1) \teq hd(nil2)$). This could be corrected, but the added
compexity seems to suggest that selectors are better specified axiomatically.

A related semantic view of datatypes is as initial algebra. Codatatypes are then
defined dually as a final coalgebra. The datatypes are generated by their
constructors, whereas the codatatypes are viewed through their selectors
\cite{xxx}. By uniformly focusing on the constructors, the axiomatic approach
emphasizes the commonality between datatypes and codatatypes, while sacrificing
a theoretically fruitful notion of duality.


  * final coalgebra
    * this time, no condition: always exists
    e.g. the specification

      codatatype x = X x

    gives rise to a singleton type {X (X (X ...))}.

  * discriminators/selectors for initial algebras
  * constructors for final coalgebras

  * Introduce the discriminators already here.

  * how to deal with "wrong" selectors, e.g.
        hd(nil1) = hd(nil2)?
      * leave them unspecified; hence hd(nil1) = hd(nil2) in some models,
        and not in other models

  * ODDITY: Barrett et al. overspecify things (not good w.r.t. SMT-LIB 2, or
    other solvers, e.g., Z3)

  * axiomatically
    * injectivity
      distinctness
      exhaustiveness
    * datatypes:
      * induction axiom (schema)
        * consequence: no infinite objects (in particular, no cyclic objects)

      * when looking at the universal ground (?) theory:
        enough to consider acyclicity -- no way to specify infinite objects
        otherwise

    * codatatypes:
      * coinduction axiom (schema)
        * consequence: infinite objects are allowed, but
          two objects yielding the same observations must be equal

      * again: when looking at the universal ground (?) theory, enough to
        consider bisimilarity/bisimulation

\section{The Calculus}
\label{sec:the-calculus}

  * SMT background

  * Rewriter
  * Actual calculus

  * Correctness

\rem{Discuss signature $\Sig$, theory $\thD$}
This section presents a calculus for determining the satisfiability of conjunctions of $\thD$-constraints.

Our calculus consists of derivation rules that operate on a set $\Ec$ of equalities and disequalities between $\Sig$-terms.
We will write $\tEc$ to denote the set of $\Sig$-terms occurring in $\Ec$.
We will commonly denote tuples of terms $( t_1, \ldots, t_n )$ in bold font, as $\vec t$.
We assume that all $\Sig$-terms in $\Ec$ are \emph{normalized}, meaning that all subterms of the form $s^i_j( \const{C}_j( \vec t ) )$
are replaced by $t_i$, and moreover assume that all additional constraints added to $\Ec$ are normalized in this manner.

\begin{figure}[t]
\centering
\begin{tabular}{c}
\rn{Refl}
\(
\inferrule{
  t \in \tEc
}{
  \Ec := \Ec, t \teq t
}
\)
\qquad
\rn{Symm}
\(
\inferrule{
 t_1 \teq t_2 \in \Ec
}{
 \Ec := \Ec, t_2 \teq t_1
}
\)
\qquad
\rn{Conflict}
\(
\inferrule{
  t \teq u, t \tneq u \in \Ec
}{
  \bot
}
\)
\\[3.7ex]
\rn{Trans}
\(
\inferrule{
  t_1 \teq t_2, t_2 \teq t_3 \in \Ec
}{
  \Ec := \Ec, t_1 \teq t_3
}
\)
\qquad
\rn{Cong} 
\(
\inferrule{
  \vec t \teq \vec u \in \Ec \quad f( \vec t ), f( \vec u ) \in \tEc
}{
  \Ec := \Ec, f( \vec t ) \teq f( \vec u )
}
\)
\\[3.7ex]
\rn{Unify$_1$} 
\(
\inferrule{
  \const{C}_1( \vec t ) \teq \const{C}_1( \vec u ) \in \Ec
}{
  \Ec := \Ec, \vec t \teq \vec u
}
\)
\qquad
\rn{Unify$_2$} 
\(
\inferrule{
  \const{C}_1( \vec t ) \teq \const{C}_2( \vec u ) \in \Ec
}{
  \bot
}
\)
\end{tabular}
\caption{Rules for bidirectional closure.
}
\label{fig:cc-rules}
\end{figure}

We present the calculus in three sections, shown in Figures~\ref{fig:cc-rules},~\ref{fig:ab-rules}, and~\ref{fig:split-rule}.
Following the conventions from~\cite{}, 
the derivation rules of our calculus are given in \emph{guarded assignment form},
where a rule can be applied to $\Ec$ if it meets all of the specified preconditions for $\Ec$.
The conclusion of a rule either describes equalities to be added to $\Ec$ (in which case we will call an application of it to be \emph{non-terminal}),
or is $\bot$ (in which case we will call an application of it to be \emph{terminal}).
A rule may have multiple conclusions separated by $\parallel$, which denotes a non-deterministic branching.
An application of a rule is \emph{redundant} if it is non-terminal and at least one branch in its conclusion does not add a new equality to $\Ec$.

First, Figure~\ref{fig:cc-rules} gives the rules for constructing the bidirectional closure of $\Ec$.
The rules \rn{Refl}, \rn{Symm}, \rn{Trans}, and \rn{Cong} together compute the (upwards) congruence closure,
after which a conflict may be recognized by \rn{Conflict} when an inconsistency is found.
The rules \rn{Unify$_1$} and \rn{Unify$_2$} together compute (downwards) unification,
where additional equalities are inferred based on the injectivity of constructors by \rn{Unify$_1$},
and failures to unify equivalent terms are recognized by \rn{Unify$_2$}.

\begin{figure}[t]
\centering
\begin{tabular}{c}
\rn{Cyclic}
\(
\inferrule{
  t : \tau \text{ inductive } 
  \quad
  p \in \ttpath{\Ec}{\ec{t}}{\ec{t}}
}{
  \bot
}
\)
\\[3.7ex]
\rn{Bisimilar}
\(
\inferrule{
 t_1, t_2 : \tau \text{ co-inductive }
  \quad
 \exists \sigma. p \sigma \in \tpath{\Ec}{\ec{t_1}} \text{ for each } p \in \tpath{\Ec}{\ec{t_2}}
}{
 \Ec := \Ec, t_1 \teq t_2
}
\)
\end{tabular}
\caption{Rules for cyclicity and bisimilarity.
}
\label{fig:ab-rules}
\end{figure}

Before applying the rules in Figure~\ref{fig:ab-rules}, 
we assume that $\Ec$ is saturated with respect to the rules in Figure~\ref{fig:cc-rules}, that is,
no non-redudant application of one of its rules can be applied to $\Ec$.
When this is the case, it is easy to see that $\Ec$ induces an equivalence relation over $\tEc$ such that two terms $t_1$ and $t_2$ are equivalent if and only if $t_1 \teq t_2 \in \Ec$.
Thus, we will in the following consider $\Ec$ as a set of equivalence classes of terms. 
For term $t \in \tEc$, we will write $\ec{t}$ to denote the equivalence class in $\Ec$ that containing $t$.

To explain the rules in Figure~\ref{fig:ab-rules}, we introduce the following notions.
First, an edge $\ec{t_1} \rightarrow^{C}_n \ec{t_2}$ is a transition between two equivalence classes $\ec{t_1}$ and $\ec{t_2}$ 
(which we will call its \emph{source} and \emph{destination} respectively),
labeled by a constructor $C$ and integer $n$.
We say that edge $\ec{t_1} \rightarrow^{C}_n \ec{t_2}$ is \emph{induced by $\Ec$} if and only if $C( \vec u ) \in \ec{t_1}$ for some $\vec u$ and $\ec{t_2} = \ec{u_n}$.
In other words, $t_1$ is equivalent to a $C$-application whose $n^{th}$ argument is equivalent to $t_2$.
A \emph{path} $p$ is a non-empty ordered list of edges $e_1, \ldots e_n$ such that the destination of $e_i$ is the source of $e_{i+1}$ for $i = 1, \ldots (n-1)$,
and the sources of $e_1, \ldots, e_n$ are distinct.
We say that path $p$ is \emph{induced by $\Ec$} if and only if each of its edges are induced by $\Ec$.
Notice that since $\Ec$ contains a finite set of equivalence classes, all paths induced by $\Ec$ have finite length.
We call the \emph{source} of a path is the source of its first edge, and the \emph{destination} of a path is the destination of its last edge.
The set $\ttpath{\Ec}{\ec{t_1}}{\ec{t_2}}$ is the smallest set containing all paths with source $\ec{t_1}$ and destination $\ec{t_2}$ that are induced by $\Ec$.
The set $\tpath{\Ec}{\ec{t_1}}$ is the union of $\ttpath{\Ec}{\ec{t_1}}{\ec{t_2}}$ for all $t_2 \in \tEc$.
We will write, for instance, $\ec{t_1} \rightarrow^{C_1}_{n_1} \ec{t_2} \rightarrow^{C_2}_{n_2} \ec{t_3}$ 
as shorthand for the path containing an edge from $\ec{t_1}$ to $\ec{t_2}$, followed by one from $\ec{t_2}$ to $\ec{t_3}$.

The rule \rn{Cyclic} recognizes when a path exists from an equivalence class $\ec{t}$ to itself, as indicated
by the assumption $p \in \ttpath{\Ec}{\ec{t}}{\ec{t}}$.
In this case, $\Ec$ entails that $t$ contains itself as a (strict) subterm,
and thus if $t$ is a datatype, $\Ec$ must be unsatisfiable.
The rule \rn{Bisimilar} recognizes when two equivalence classes $\ec{t_1}$ and $\ec{t_2}$ having co-datatype type are observationally equivalent.
In particular, if there is a mapping $\sigma$ over equivalence classes such that all paths $p$ from $t_2$
have a corresponding path $p \sigma$ from $t_1$,
then $t_1$ must be equal to $t_2$.
We demonstrate this rule concretely with the following example.

\begin{example}
Let $\Ec$ be the set $\{ x \teq \const{LCons}(y,\const{LCons}(y,x)), x \tneq \const{LCons}(y,x) \}$.  \rem{ensure that \const{LCons} understood}
The equivalence classes of $\Ec$ are $\{ x, \const{LCons}(y,\const{LCons}(y,x)) \}$, $\{ \const{LCons}(y,x) \}$, and $\{ y \}$.
The set $\tpath{\Ec}{\ec{x}}$ is:
\[\begin{array}{l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l}
\{ & \ec{x} \rightarrow^{\const{LCons}}_1 & \ec{y}, & & \\ 
   & \ec{x} \rightarrow^{\const{LCons}}_2 & \ec{\const{LCons}(y,x)} \rightarrow^{\const{LCons}}_1 & \ec{y},& \\
   & \ec{x} \rightarrow^{\const{LCons}}_2 & \ec{\const{LCons}(y,x)} \rightarrow^{\const{LCons}}_2 & \ec{x} & \}.
\end{array}\]
The set $\tpath{\Ec}{\ec{\const{LCons}(y,x)}}$ is:
\[\begin{array}{l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l}
\{ & \ec{\const{LCons}(y,x)} \rightarrow^{\const{LCons}}_1 & \ec{y}, & & \\ 
   & \ec{\const{LCons}(y,x)} \rightarrow^{\const{LCons}}_2 & \ec{x} \rightarrow^{\const{LCons}}_1 & \ec{y},& \\
   & \ec{\const{LCons}(y,x)} \rightarrow^{\const{LCons}}_2 & \ec{x} \rightarrow^{\const{LCons}}_2 & \ec{\const{LCons}(y,x)} & \}.
\end{array}\]
Thus, we may conclude $x \teq \const{LCons}(y,x)$ by the rule \rn{Bisimilar}
for the mapping $\sigma :=$ $\{ \ec{x} \mapsto \ec{\const{LCons}(y,x)}, \ec{\const{LCons}(y,x)} \mapsto \ec{x} \}$,
after which the rule \rn{Conflict} may be applied.
\end{example}

\rem{Change notation for inductive/co-inductive.}

\begin{figure}[t]
\centering
\begin{tabular}{c}
\rn{Split} 
\(
\inferrule{
  s^i_j( t ) \in \tEc, \text{ or } t : \tau \text{ finite }
}{
  \Ec := \Ec, t \teq \const{C}_1( s^1_1( t ), \ldots, s^{a_1}_1( t ) ) \ror \ldots \ror \Ec := \Ec, t \teq \const{C}_n( s^1_n( t ), \ldots, s^{a_n}_n( t ) ) 
}
\)
\end{tabular}
\caption{Rule for splitting.  We split on the constructor for $t$ if there is a selector applied to $t$ or if its type is finite.
}
\label{fig:split-rule}
\end{figure}

Finally, if neither a rule from Figure~\ref{fig:cc-rules} or Figure~\ref{fig:ab-rules} applies to $\Ec$, 
we split on the constructor type for certain terms $t$.
In particular, if there is a selector term applied to $t$, or if $t$ has a finite type, 
then we require the equivalence class of $t$ to contain a constructor term, which is enforced by the rule \rn{Split}.

\subsection{Correctness}

A \emph{derivation tree} is a tree whose nodes are sets of equalities, where non-root nodes are obtained by 
a non-redundant application of a derivation rule to its parent node.
A derivation tree is \emph{closed} if all of its leaf nodes are $\bot$.
A node is \emph{saturated} if no non-redundant application of a rule can be applied to it.

\begin{lemma}[Termination]
All derivation trees are finite.
\end{lemma}
\begin{proof}
Consider a derivation tree with root node $\Ec$.
Let $S^0$ be the set of terms that are arguments of a selector application in $\tEc$.
For $i \geq 0$, let $S^{i+1}$ $=$ $S_i \cup \{ s( t ) \mid t \in S^i, s \in sel( t ), t : \tau \text{ finite} \}$.
Let $S^\ast$ be the fix point of this sequence, which is guarenteed to be finite 
since $S^\ast \setminus S^0$ only includes selectors applied to terms having finite type.
Now, let $\tcEc$ be the set all subterms of $\Ec \cup \{ C_i( s^1_i( t ), \ldots, s^{a_j}_i( t ) ) \mid t \in S^\ast, C_i \in cons( t ) \}$.
In a derivation tree with root node $\Ec$, 
it can be shown by case analysis on the rules of the calculus that each non-root node is 
obtained as a result of adding an equality between two terms from $\tcEc$ to its parent node.
Thus, the maximum depth of a branch in a derivation tree with root node $\Ec$ is $\mid \tcEc \mid^2$,
which is finite since $\tcEc$ is finite.
\end{proof}

\begin{lemma}[Refutation Soundness]
If there exists a closed derivation tree with root node $\Ec$, then $\Ec$ is unsatisfiable in $\thD$.
\end{lemma}
\begin{proof}
TODO
\end{proof}

\begin{lemma}[Solution Soundness]
If there exists a derivation tree containing a saturated node with root node $\Ec$, then $\Ec$ is satisfiable in $\thD$.
\end{lemma}
\begin{proof}
TODO
\end{proof}

\rem{Thus, sound and complete.}
  
\section{The Theory Solver}
\label{sec:the-theory-solver}

  * Strategies
  * Implementation
    * what is an SMT theory solver
    * cooperation with Nelson-Oppen / integration into SMT solver
    * "mu" stuff
    * no "internal search"
  * Enumerator?
    * for model generation

%\section{Examples}
%\label{sec:examples}

\section{Experimental Results}
\label{sec:experimental-results}

  * Constructed examples
    * proving
    * model finding?

  * Isabelle benchmarks


\section{Conclusion}
\label{sec:conclusion}

Future work:

  * more evaluation
    * use it in a new Nitpick-like tool
  * recursive and corecursive functions
    (and rewriting)
  * extensions, perhaps straightforward, to polymorphism and nested
    (co)recursion

\def\ackname{Acknowledgment}
\paragraph{\ackname.}

Clark Barrett and Cesare Tinelli.

Bosses: Viktor Kuncak, Stephan Merz, Tobias Nipkow, and Christoph Weidenbach.

The research was partially supported by the Deutsche
Forschungs\-gemein\-schaft (DFG) project
\relax{Hardening the Hammer} (grant Ni\,491\slash 14-1).

\bibliographystyle{splncs03}
\bibliography{bib}{}

\end{document}
