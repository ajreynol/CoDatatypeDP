%envcountsect,
\documentclass[a4paper,oribibl,envcountsame,draft]{llncs}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{arydshln}
\usepackage[scaled=.82]{beramono}
\usepackage{booktabs}
\usepackage{bussproofs}
\usepackage{calc}
\usepackage{cite}
\usepackage{mathptmx}
%\usepackage{txfonts}
%\usepackage{mathrsfs}
%\usepackage{pifont}
%\usepackage{smallcap}
\usepackage{mathpartir} 
\usepackage{stmaryrd}
\usepackage{subfigure}
\usepackage[usenames]{color}
%\usepackage{graphicx}
%\usepackage{newcent}
\usepackage{textcomp}
%\usepackage{tipa}
\usepackage{units}
\usepackage{url}
\usepackage{version}
\usepackage[all]{xy}

\DeclareFontFamily{OT1}{pzc}{}
\DeclareFontShape{OT1}{pzc}{m}{it}{<-> s * [1.10] pzcmi7t}{}
\DeclareMathAlphabet{\mathscr}{OT1}{pzc}{m}{it}

\DeclareMathAlphabet{\mathcal}{OT1}{pzc}{m}{it}


\newcommand\jPrime{j\vthinspace'\negvthinspace}

\newcommand\Sig{\mathrm{\Sigma}}

\newcommand\keyw[1]{\textbf{#1}}
\newcommand\const[1]{\textsf{#1}}
\newcommand\ty[1]{\textit{#1}}

\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\Ec}{\mathsf{E}}
\newcommand{\tEc}{\mathcal{T}(\Ec)}
\newcommand{\tcEc}{\mathcal{T}^\ast(\Ec)}
\newcommand{\rn}[1]{\textsf{\small #1}}
\newcommand{\cvc}{\textsc{cvc}{\small 4}\xspace}
\newcommand{\teq}{\approx}
\newcommand{\tneq}{\not\teq}
\newcommand{\rem}[1]{\textcolor{red}{[#1]}}
%\newcommand{\is}[1]{is\text{-} #1}
\newcommand{\is}[1]{\const{is#1}}
\newcommand{\ror}{\quad \parallel \quad}
\newcommand{\tpath}[2]{\mathcal{P}_{ #2 \rightarrow \_ }( #1 )}
\newcommand{\ttpath}[3]{\mathcal{P}_{ #2 \rightarrow #3 }( #1 )}
\newcommand{\ec}[1]{ [ #1 ] }

% change?
\newcommand{\thD}{T_{D}}

%\newcommand\Types{\mathcal{T}}
\newcommand\Types{\mathcal{Y}}
\newcommand\Funcs{\mathcal{F}}

\newcommand\Data{\Types_{\mathrm{dt}}}
\newcommand\Codata{\Types_{\mathrm{cdt}}}
\newcommand\Nondata{\Types_{\mathrm{oth}}}

\newcommand\Ctr{\Funcs_{\mathrm{ctr}}}
\newcommand\Sel{\Funcs_{\mathrm{sel}}}
%\newcommand\Plainfuncs{\Funcs_{\mathrm{other}}}

\newcommand\vthinspace{\kern+0.083333em}
\newcommand\negvthinspace{\kern-0.083333em}

%%% For final version as well?
\usepackage[
   a4paper,
   pdftex,
   pdftitle={A Decision Procedure for (Co)datatypes in SMT Solvers},
   pdfauthor={Andrew Reynolds and Jasmin Christian Blanchette},
   pdfkeywords={},
   pdfborder={0 0 0},
   draft=false,
   bookmarksnumbered,
   bookmarks,
   bookmarksdepth=2,
   bookmarksopenlevel=2,
   bookmarksopen]{hyperref}

\urlstyle{ttstyle}

\global\def\figurename{Figure}

\DeclareSymbolFont{letters}{OML}{txmi}{m}{it}

%%% REMOVE BEFORE SUBMITTING ABSOLUTELY FINAL VERSION
\makeatletter
\ps@myheadings
\makeatother

\include{defs}

\hyphenation{data-type data-types co-data-type co-data-types}

\begin{document}

\title{A Decision Procedure for (Co)datatypes in SMT Solvers}

\author {Andrew Reynolds\inst{1} \and Jasmin Christian Blanchette\inst{2,3}}
\authorrunning {A. Reynolds \and J. C. Blanchette}
\institute{
\'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL), Switzerland
\and
Inria Nancy \& LORIA, Villers-l\`es-Nancy, France
\and
Max-Planck-Institut f\"ur Informatik, Saarbr\"ucken, Germany
}

\maketitle

\begin{abstract}
Codatatypes naturally capture potentially infinite data structures and
processes. We introduce a decision procedure that combines reasoning about
datatypes and codatatypes. The dual of the cyclicity rule for datatypes is a
bisimilarity rule that identifies observationally equal, possibly cyclic values.
The procedure is complete for the universal fragment and is compatible with the
Nelson--Oppen method. It has been implemented in the latest version of CVC4, a
modern SMT solver. An evaluation based on problems generated from Isabelle
theories demonstrates the potential of the procedure for both proving and model
finding.
\end{abstract}

%% The institutions above shouldn't count as footnotes
\setcounter{footnote}{0}

\section{Introduction}
\label{sec:introduction}

Blah.

  * briefly: datatypes and why they are useful
    * Hoare's recursive data structures
    * comparatively easy to reason about and automate
    * common in practice, esp. in computer science applications

    (terminology: freely-generated, inductive, algebraic, ..., sometimes
    with different meanings; we'll clarify below what we use)

  * less briefly: codatatypes and why they are useful
    * in Agda, Coq, Matita -- recently also in Isabelle/HOL \cite{nipkow-et-al-2002}
    * but not in SMT-LIB 2 \cite{barrett-et-al-2010}

  * single decision procedure for datatypes and codatatypes
  * datatypes are implementation following the lines of Barrett et al.
  * codatatypes were added later, motivated by the use of SMT solvers as
    backends to proof assistants (more specifically, CVC4 to Isabelle/HOL)

  * setting (Section~\ref{sec:theory-of-co-datatypes}):
    * universal formulas
    * many-sorted logic
    * mutually (co)recursive types with constructors, selectors, and
      discriminators

  * codatatypes: from a theoretical and implementational point of view, like
      datatypes but:
    * codatatypes are never empty (e.g. finite streams are rejected)

\[
      \keyw{codatatype}\; \,\ty{llist} \,=\, \const{LNil} \,\mid\, \const{LCons}(\ty{int},\, \ty{llist})
\]

    * no acyclicity (e.g. xs = lcons(0, xs) is satisfiable)
    * instead: bisimilarity check
    * (also: ``enumeration'', e.g. of streams)

  * motivation:
    * acyclicity and bisimilarity cannot be axiomatized, so they really belong in
      a decision procedure
    * other properties can be done more efficiently by a decision procedure

  * consider a natural fragment---datatypes as supported in modern SMT solvers
    and the SMT-LIB 2 standard, and codatatypes as their duals
    * mutual recursion, but no polymorphism, nested recursion

  * decision procedure is described abstractly as a calculus
    (Section~\ref{sec:the-calculus})
    * includes rewriting
    * and inferences

  * integrated with Nelson-Oppen

  * implemented in CVC4 as rewriting and a theory solver
    (\ref{sec:the-theory-solver})
    * precise strategy for applying inferences
    * about 2000 lines of code, among which 1600 are shared between datatypes
      and codatatypes

  * useful both for proving and for model finding
    * in particular, acyclicity and bisimilarity are necessary for some proofs
      (and cannot be axiomatized finitely)
    * and for model finding, without them we quickly get spurious models
    * explain how finite model finding works

%\ref{sec:examples}

  * benchmarking is often an issue -- esp. codatatypes
  * the decision procedure is evaluated on two sets of benchmarks
    (Section~\ref{sec:experimental-results}):
    * first set: hand-crafted examples
    * second set: generated from Isabelle theories using the Sledgehammer tool

Polymorphic types, nested (co)recursion, and datatype--codatatype mixtures fall

\paragraph{Related Work.}

    * point to Barrett et al. for SMT datatypes
      * about their own work, they say: "our focus is on generality and
        efficiency rather than immediacy of implementation"
      * (deal more directly with finite sorts than Barrett et al., Section 6.1)
    * additional ones since then (e.g. strings?)
    * anything about codatatypes?
      * proof assistants like Agda, Coq, etc. have them
      * Dafny, CoALP
      * also a lot of theoretical research, some of which is loosely connected,
        e.g. decision procedure for corecursive functions (Henning in Nijmegen)

    * ODDITY: Oppen 1980: single-constructor, recursive -- infinite values?

\paragraph{Conventions.}
This paper assumes a monomorphic (or many-sorted) first-order logic throughout.
A signature $\Sig = (\Types, \Funcs)$ consists of a set of types $\Types$ and a
set of function symbols $\Funcs$. Types are simply atomic sorts, with no
structure, and interpreted by nonempty domains. The set $\Types$ must contain a
distinguished type \ty{bool} interpreted as the set of truth
values. %, and may contain other interpreted types (e.g., \ty{int}, \ty{real}).
The only predicate is $\teq$, and it is treated as a logical symbol,
just like the connectives and quantifiers of first-order logic.
Other predicates can be represented as functions that return $\ty{bool}$.
The metavariables $\delta, \tau$ range over types, with $\delta$ reserved
for datatypes and codatatypes.

Function symbols are written in a sans-serif font (e.g., $\const{f}$, $\const{g}$) to
distinguish them from variables (e.g., $x$, $y$). Upper case names (e.g., $\const{C}$,
$\const{Nil}$) are reserved for constructors. With each function symbol \const{f}
is associated a list of argument types $\tau_1,\ldots,\tau_n$ (with $n \ge 0$)
and a return type $\tau$. This connection can be expressed compactly as
$\const{f} : \tau_1 \times \cdots \times \tau_n \to \tau$
(which collapses to $\const{f} : \tau$ if $n = 0$).
For a term $t$, the notation $t : \tau$ indicates that $t$ has type $\tau$.
Functions are applied the standard way, with $\const{f}(t_1,\ldots,t_n)$
applying the $n$-ary function symbol
\const{f} to $n$ well-typed arguments $t_1 : \tau_1$, \ldots, $t_n :
\tau_n$. Nullary function symbols are called constants and can appear without
parentheses in terms.
%
Finally, the notation $\bar x$ abbreviates a list or tuple $x_1,\ldots,x_n$.

%* although nothing prevents composing the decision procedure with theories
%  providing polymorphic types (parametric sorts), such as for arrays (e.g., $\ty{array}(\alpha,\beta)$)

\section{Theory of (Co)datatypes}
\label{sec:theory-of-co-datatypes}

We assume a signature $\Sig = (\Types, \Funcs)$. The types are partioned into
$\Types = \Data \mathrel{\uplus} \Codata \mathrel{\uplus} \Nondata$, where $\Data$ are the
datatypes, $\Codata$ are the codatatypes, and $\Nondata$ are the remaining
types. The functions are partitioned into $\Funcs = \Ctr \mathrel{\uplus} \Sel$, where
$\Ctr$ are the constructors and $\Sel$ are the selectors. (There is no need to
consider other function symbols, because they can be abstracted away as
variables when combining theories.)

In practice (e.g., in an SMT problem), the signature is given by specifying the
uninterpreted types first (in any order), then the (co)datatypes with their
constructors and selectors in groups of mutually (co)recursive groups of
(co)datatypes, and finally any other function symbols.

A (co)datatype specification consists of $l$~mutually recursive types which are
either all datatypes or all codatatypes. Each datatype $\delta$ is equipped by
$m \ge 1$ constructors, and each constructor for $\delta$ takes zero or more
arguments and returns a $\delta$ value. The argument types must be either
plain, be or be one of the newly introduced (co)datatypes. To every
argument corresponds a selector. The introduced names for the (co)datatypes, the
constructors, and the selectors must be distinct and different from already
introduced ones.%
\footnote{In practice, it can be useful to specify the same selector
for several constructors of the same (co)datatype,
as long as the argument types coincide \cite[Section~3]{blanchette-et-al-2014-codata}.
However, this is not allowed by SMT-LIB 2.}
Schematically, using a syntax similar to Standard ML, Haskell,
or SMT-LIB:
%
\[
\begin{aligned}[t]
(\keyw{co})\keyw{datatype}\;\,
  \delta_1 & {}=\, \const{C}_{1}\rlap{${}_{1}$}\phantom{{}_{m}}(\bigl[\const{s}_{11}^1{:}\bigr]\; \tau_{11}^1, \,\ldots,\, \bigl[\const{s}_{11}^{n_{11}}{:}\bigr]\; \tau_{11}^{n_{11}}) & \\
           & {}\;\phantom{=\,}\;{} \smash{\,\,\,\vdots} \\[-\jot] % {}\;\phantom{=}\llap{\ensuremath{\mid}}\; \cdots \\
           & {}\;\phantom{=\,}\llap{\ensuremath{\,\mid\,}}\; \const{C}_{1m}(\bigl[\const{s}_{1m}^1{:}\bigr]\; \tau_{1m}^1, \,\ldots,\, \big[\const{s}_{1m}^{n_{1m}}{:}\big]\; \tau_{1m}^{n_{1m}}) \\[-1\jot]
   \smash{\vdots\,\,\,} \\[-1\jot]
  \keyw{and}\; \,\delta_l & =\, \ldots
\end{aligned}
\]
%
with
$\const{C}_{i\negvthinspace j} : \tau_{i\negvthinspace j}^1\times\cdots\times\tau_{i\negvthinspace j}^{\,k_{\smash{i\negvthinspace j}}} \to \delta_i$
and $\const{s}_{i\negvthinspace j}^{\,k} : \delta_i \to \tau_{i\negvthinspace j}^{\,k}$. Defaults are assumed for
the selector names if they are omitted.

Polymorphic types, nested (co)recursion, and datatype--codatatype mixtures fall
outside this fragment. For example, the specification
\[\begin{aligned}[t]
      \keyw{datatype}\;\, \ty{tree} & \,=\, \const{Node}(\ty{int},\, \ty{forest}) \\[-\jot]
      \keyw{and}\;\, \ty{forest} & \,=\, \const{FNil} \,\mid\, \const{FCons}(\ty{tree},\, \ty{forest})
\end{aligned}
\]
is supported, whereas
\[\begin{aligned}[t]
      \keyw{codatatype}\; \,\ty{gllist}(\alpha) & \,=\, \const{GLNil} \,\mid\, \const{GLCons}(\alpha,\, \ty{gllist}(\alpha)) \\[-.5\jot]
      \keyw{datatype}\;\, \ty{tree} & \,=\, \const{Node}(\ty{int},\, \ty{gllist}(\ty{tree}))
\end{aligned}
\]
is beyond the fragment considered here. In principle, rank-1 (top-level)
polymorphism would be easy to support; nesting datatypes inside datatypes,
and likewise for codatatypes, can be reduced to the mutual case. So the only
genuinely interesting cases missing are mixed nested (co)recursion
(as in the \ty{tree} example above) as well as (co)recursion through a
non-(co)datatype (both of which make sense \cite{blanchette-et-al-2014-codata}).

Because the types are inhabited (nonempty), a datatype specification is
admissible only if a ground term can be exhibited that belongs to that datatype.
This rules out ill-founded specifications such as
%
\[\keyw{datatype}\;\, \ty{fstream} \,=\, \const{FSCons}(\ty{int},\,\ty{fstream})\]
%
For codatatypes, no such check is necessary. Given the specification
%
\[\keyw{codatatype}\;\, \ty{stream} \,=\, \const{SCons}(\ty{int},\,\ty{stream})\]
%
the infinite value $\const{SCons}(0, \const{SCons}(0, \ldots))$ witnesses
nonemptiness.

discriminators go here

Datatypes and codatatypes can be characterized axiomatically. They share basic
properties of constructors and selectors. All properties below are implicitly
universally quantified and range over all
$i$, $j$, $\jPrime$, and $k$ within bounds:
% and to all possible splits of the
%$n$-ary constructor $\const{C}_{i\negvthinspace j}$'s argument list into $\bar x,
%y, \bar z$:
%
\[
\begin{aligned}[t]
\text{Distinctness:}\quad
  & %\forall \bar x, \bar y.\;\,
    \const{C}_{i\negvthinspace j}(\bar x) \tneq \const{C}_{i\negvthinspace \jPrime}(\bar y) \qquad\text{if $j \not= \jPrime$}
  \\
\text{Injectivity:}\quad
  & %\forall x_1,\ldots,x_{n_{i\negvthinspace j}} y.\;\,
    \const{C}_{i\negvthinspace j}(x_1,\ldots,x_{n_{i\negvthinspace j}}) \teq \const{C}_{i\negvthinspace j}(x_1,\ldots,x_{k-1},y,x_{k+1},\ldots,x_{n_{i\negvthinspace j}}) \longrightarrow x_k \teq y
  \\
\text{Exhaustiveness:}\quad
  & \is{C}_{i1}(x) \mathrel\lor \cdots \mathrel\lor \is{C}_{im_i}(x)
  \\
\text{Selection:}\quad
  & s_{ij}^k(\const{C}_{i\negvthinspace j}(x_1,\ldots,x_{n_{i\negvthinspace j}})) = x_k
\end{aligned}
\]
%
Expressed in the algebraic jargon,
exhaustiveness ensures that ``no junk'' arises, whereas
distinctness and injectivity ensure that ``no confusion'' occur,
whereas 

%Sometimes, the requirements on constructors are stipulated as ``no junk, no
%confusion.''

    * datatypes:
      * induction axiom (schema)
        * consequence: no infinite objects (in particular, no cyclic objects)

      * when looking at the universal ground (?) theory:
        enough to consider acyclicity -- no way to specify infinite objects
        otherwise

    * codatatypes:
      * coinduction axiom (schema)
        * consequence: infinite objects are allowed, but
          two objects yielding the same observations must be equal

      * again: when looking at the universal ground (?) theory, enough to
        consider bisimilarity/bisimulation

specifies the 



  * how to deal with "wrong" selectors, e.g.
        hd(nil1) = hd(nil2)?
      * leave them unspecified; hence hd(nil1) = hd(nil2) in some models,
        and not in other models




Datatypes can be defined semantically as the initial model of an equational
specification of the selector--constructor equations. This is the view followed
by Barrett et al.\ \cite{barrett-et-al-2010}. A disadvantage with this approach
is that it does not naturally account for selectors applied to wrong
constructors. Barrett et al.\ address this by parameterizing the construction by
default values, but these give rise to spurious equalities between unrelated
terms---for example, $\const{s}_{11}(\const{C}_2) \teq \const{s}_{11}(\const{C}_3)$.
This could be corrected, but the added
complexity seems to suggest that selectors are better specified axiomatically.

A related semantic view of datatypes is as initial algebra. Codatatypes are then
defined dually as a final coalgebra. The datatypes are generated by their
constructors, whereas the codatatypes are viewed through their selectors
\cite{xxx}. By uniformly focusing on the constructors, the axiomatic approach
emphasizes the commonality between datatypes and codatatypes, while sacrificing
a theoretically fruitful notion of duality.

\section{The Calculus}
\label{sec:the-calculus}

  * SMT background

  * Rewriter
  * Actual calculus

  * Correctness

\rem{Discuss signature $\Sig$, theory $\thD$}
This section presents a calculus for determining the satisfiability of conjunctions of $\thD$-constraints.

Our calculus consists of derivation rules that operate on a set $\Ec$ of equalities and disequalities between $\Sig$-terms.
We will write $\tEc$ to denote the set of $\Sig$-terms occurring in $\Ec$.
We will commonly denote tuples of terms $( t_1, \ldots, t_n )$ in bold font, as $\vec t$.
We assume that all $\Sig$-terms in $\Ec$ are \emph{normalized}, meaning that all subterms of the form $s^i_j( \const{C}_j( \vec t ) )$
are replaced by $t_i$, and moreover assume that all additional constraints added to $\Ec$ are normalized in this manner.

We present the calculus in three sections, shown in Figures~\ref{fig:cc-rules},~\ref{fig:ab-rules}, and~\ref{fig:split-rule}.
Following the conventions from~\cite{}, 
the derivation rules of our calculus are given in \emph{guarded assignment form},
where a rule can be applied to $\Ec$ if it meets all of the specified preconditions for $\Ec$.
The conclusion of a rule either describes equalities to be added to $\Ec$ (in which case we will call an application of it to be \emph{non-terminal}),
or is $\bot$ (in which case we will call an application of it to be \emph{terminal}).
A rule may have multiple conclusions separated by $\parallel$, which denotes a non-deterministic branching.
An application of a rule is \emph{redundant} if it is non-terminal and at least one branch in its conclusion does not add a new equality to $\Ec$.

\begin{figure}[t]
\centering
\begin{tabular}{c}
\rn{Refl}
\(
\inferrule{
  t \in \tEc
}{
  \Ec := \Ec, t \teq t
}
\)
\qquad
\rn{Symm}
\(
\inferrule{
 t_1 \teq t_2 \in \Ec
}{
 \Ec := \Ec, t_2 \teq t_1
}
\)
\qquad
\rn{Conflict}
\(
\inferrule{
  t_1 \teq t_2, t_1 \tneq t_2 \in \Ec
}{
  \bot
}
\)
\\[3.7ex]
\rn{Trans}
\(
\inferrule{
  t_1 \teq t_2, t_2 \teq t_3 \in \Ec
}{
  \Ec := \Ec, t_1 \teq t_3
}
\)
\qquad
\rn{Cong} 
\(
\inferrule{
  \vec t \teq \vec u \in \Ec \quad f( \vec t ), f( \vec u ) \in \tEc
}{
  \Ec := \Ec, f( \vec t ) \teq f( \vec u )
}
\)
\\[3.7ex]
\rn{Unify$_1$} 
\(
\inferrule{
  \const{C}_1( \vec t ) \teq \const{C}_1( \vec u ) \in \Ec
}{
  \Ec := \Ec, \vec t \teq \vec u
}
\)
\qquad
\rn{Unify$_2$} 
\(
\inferrule{
  \const{C}_1( \vec t ) \teq \const{C}_2( \vec u ) \in \Ec
}{
  \bot
}
\)
\end{tabular}
\caption{Rules for bidirectional closure.
}
\label{fig:cc-rules}
\end{figure}

Figure~\ref{fig:cc-rules} gives the basic rules of our calculus.
Together with the rules \rn{Refl}, \rn{Symm}, \rn{Trans}, the rule \rn{Cong} computes the (upwards) congruence closure,
while the rules \rn{Unify$_1$} and \rn{Unify$_2$} together compute (downwards) unification.
In the unification rules, additional equalities are inferred based on the injectivity of constructors by \rn{Unify$_1$},
and failures to unify equated terms are recognized by \rn{Unify$_2$}.
The rule \rn{Conflict} recognizes when an equality and its negation both occur in $\Ec$, in which case $\Ec$ has no model.

\begin{figure}[t]
\centering
\begin{tabular}{c}
\rn{Cyclic}
\(
\inferrule{
  t : \tau
  \quad
  \tau \in \Data
  \quad
  \ttpath{\Ec}{\ec{t}}{\ec{t}} \neq \emptyset
}{
  \bot
}
\)
\\[3.7ex]
\rn{Bisimilar}
\(
\inferrule{
 t_1, t_2 : \tau
  \quad
 \tau \in \Codata
  \quad
 \tpath{\Ec}{\ec{t_1}} = \tpath{\Ec}{\ec{t_2}}\sigma \neq \emptyset
}{
 \Ec := \Ec, t_1 \teq t_2
}
\)
\end{tabular}
\caption{Rules for cyclicity and bisimilarity.
}
\label{fig:ab-rules}
\end{figure}

Before applying the rules in Figure~\ref{fig:ab-rules}, 
we assume that $\Ec$ is saturated with respect to the rules in Figure~\ref{fig:cc-rules}, that is,
no non-redudant application of one of its rules can be applied to $\Ec$.
When this is the case, it is easy to see that $\Ec$ induces an equivalence relation over $\tEc$ such that two terms $t_1$ and $t_2$ are equivalent if and only if $t_1 \teq t_2 \in \Ec$.
Thus, we will in the following consider $\Ec$ as a set of equivalence classes of terms. 
For term $t \in \tEc$, we will write $\ec{t}$ to denote the equivalence class in $\Ec$ that containing $t$.

To explain the rules in Figure~\ref{fig:ab-rules}, we introduce the following notions.
First, an edge $\ec{t_1} \rightarrow^{C}_n \ec{t_2}$ is a transition between two equivalence classes $\ec{t_1}$ and $\ec{t_2}$ 
(which we will call its \emph{source} and \emph{destination} respectively),
labeled by a constructor $C$ and integer $n$.
We say that edge $\ec{t_1} \rightarrow^{C}_n \ec{t_2}$ is \emph{induced by $\Ec$} if and only if $C( \vec u ) \in \ec{t_1}$ for some $\vec u$ and $\ec{t_2} = \ec{u_n}$.
In other words, $t_1$ is equivalent to a $C$-application whose $n^{th}$ argument is equivalent to $t_2$.
A \emph{path} $p$ is a non-empty ordered list of edges $e_1, \ldots e_n$ such that the destination of $e_i$ is the source of $e_{i+1}$ for $i = 1, \ldots (n-1)$,
and the sources of $e_1, \ldots, e_n$ are distinct.
We say that path $p$ is \emph{induced by $\Ec$} if and only if each of its edges are induced by $\Ec$.
Notice that since $\Ec$ contains a finite set of equivalence classes, all paths induced by $\Ec$ have finite length.
We call the \emph{source} of a path is the source of its first edge, and the \emph{destination} of a path is the destination of its last edge.
We say a path $p$ is \emph{maximal} if its destination $\ec{t}$ is either
the source of an edge in $p$, 
or does not contain an application of a constructor (including the case when $t$ is not of datatype/codatatype type).
The set $\ttpath{\Ec}{\ec{t_1}}{\ec{t_2}}$ is the smallest set containing all maximal paths with source $\ec{t_1}$ and destination $\ec{t_2}$ that are induced by $\Ec$.
The set $\tpath{\Ec}{\ec{t_1}}$ is the union of $\ttpath{\Ec}{\ec{t_1}}{\ec{t_2}}$ for all $t_2 \in \tEc$.
We will write, for instance, $\ec{t_1} \rightarrow^{C_1}_{n_1} \ec{t_2} \rightarrow^{C_2}_{n_2} \ec{t_3}$ 
as shorthand for the path containing an edge from $\ec{t_1}$ to $\ec{t_2}$, followed by one from $\ec{t_2}$ to $\ec{t_3}$.

The rule \rn{Cyclic} recognizes when a path exists from an equivalence class $\ec{t}$ to itself, as indicated
by the assumption $\ttpath{\Ec}{\ec{t}}{\ec{t}} \neq \emptyset$.
In this case, $\Ec$ entails that $t$ contains itself as a (strict) subterm,
and thus if $t$ is a datatype, $\Ec$ must be unsatisfiable.
The rule \rn{Bisimilar} recognizes when two equivalence classes $\ec{t_1}$ and $\ec{t_2}$ having co-datatype type are observationally equivalent.
In particular, if there is a mapping $\sigma$ over equivalence classes such that all paths $p$ from $t_2$
have a corresponding path $p \sigma$ from $t_1$,
then $t_1$ must be equal to $t_2$.
We demonstrate this rule concretely with the following example.
\rem{ensure that \const{LCons} understood}

\begin{example}
Let $\Ec$ be the set $\{ x \teq \const{LCons}(y,\const{LCons}(y,x)) \}$.
After taking the bidirectional closure of $\Ec$, we obtain equivalence classes 
$\{ x, \const{LCons}(y,\const{LCons}(y,x)) \}$, $\{ \const{LCons}(y,x) \}$, and $\{ y \}$.
The set $\tpath{\Ec}{\ec{x}}$ is:
\[\begin{array}{l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l}
\{ & \ec{x} \rightarrow^{\const{LCons}}_1 & \ec{y}, & & \\ 
   & \ec{x} \rightarrow^{\const{LCons}}_2 & \ec{\const{LCons}(y,x)} \rightarrow^{\const{LCons}}_1 & \ec{y},& \\
   & \ec{x} \rightarrow^{\const{LCons}}_2 & \ec{\const{LCons}(y,x)} \rightarrow^{\const{LCons}}_2 & \ec{x} & \}.
\end{array}\]
The set $\tpath{\Ec}{\ec{\const{LCons}(y,x)}}$ is:
\[\begin{array}{l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l}
\{ & \ec{\const{LCons}(y,x)} \rightarrow^{\const{LCons}}_1 & \ec{y}, & & \\ 
   & \ec{\const{LCons}(y,x)} \rightarrow^{\const{LCons}}_2 & \ec{x} \rightarrow^{\const{LCons}}_1 & \ec{y},& \\
   & \ec{\const{LCons}(y,x)} \rightarrow^{\const{LCons}}_2 & \ec{x} \rightarrow^{\const{LCons}}_2 & \ec{\const{LCons}(y,x)} & \}.
\end{array}\]
Thus, we may infer $x \teq \const{LCons}(y,x)$ by the rule \rn{Bisimilar}
for the mapping $\sigma :=$ $\{ \ec{x} \mapsto \ec{\const{LCons}(y,x)}, \ec{\const{LCons}(y,x)} \mapsto \ec{x} \}$.
\qed
\end{example}

\begin{figure}[t]
\centering
\begin{tabular}{c}
\rn{Singleton}
\(
\inferrule{
  t, u \in \tEc
  \quad
  t, u : \tau,
  \tau \in \Codata,
  \mid \tau \mid = 1
}{
  \Ec := \Ec, t \teq u
}
\)
\\[3.7ex]
\rn{Split} 
\(
\inferrule{
  s^i_j( t ) \in \tEc \quad \text{ or } \quad t : \tau, \tau \in \Data, \tau \text{ finite }
}{
  \Ec := \Ec, t \teq \const{C}_1( s^1_1( t ), \ldots, s^{a_1}_1( t ) ) \ror \ldots \ror \Ec := \Ec, t \teq \const{C}_n( s^1_n( t ), \ldots, s^{a_n}_n( t ) ) 
}
\)
\end{tabular}
\caption{Rules for splitting.  
%All pairs of terms whose type has cardinality 1 are entailed to be equal (the degenerate case).
%Constructors must be assigned for all terms $t$ if has a selector is applied to it, or if $t$ has finite datatype type.
}
\label{fig:split-rule}
\end{figure}

\rem{Require : all co-datatypes either have infinite cardinality, or have cardinality 1.}

Finally, if neither a rule from Figure~\ref{fig:cc-rules} or Figure~\ref{fig:ab-rules} applies to $\Ec$, 
the rules from Figure~\ref{fig:split-rule} are applied.
The rule \rn{Singleton} handles the degenerate case when there are two terms from $\tEc$ having a singleton codatatype type,
in which case we can infer they are equal.
Otherwise, in the case there is a selector term applied to $t$, or if $t$ has a finite datatype type, 
then we require the equivalence class of $t$ to contain a constructor term, which is enforced by the rule \rn{Split}.

\subsection{Correctness}

A \emph{derivation tree} is a tree whose nodes are sets of equalities, where non-root nodes are obtained by 
a non-redundant application of a derivation rule to its parent node.
A derivation tree is \emph{closed} if all of its leaf nodes are $\bot$.
A node is \emph{saturated} if no non-redundant application of a rule can be applied to it.

\begin{lemma}[Termination]
All derivation trees are finite.
\end{lemma}
\begin{proof}
Consider a derivation tree with root node $\Ec$.
Let $S^0$ be the set of terms that are arguments of a selector application in $\tEc$.
For $i \geq 0$, let $S^{i+1}$ $=$ $S_i \cup \{ s( t ) \mid t \in S^i, t : \tau, \tau \in \Data, \tau \in  \text{ finite}, s \in \Sel^\tau  \}$.
Let $S^\ast$ be the fixed point of this sequence, which is guarenteed to be a finite set 
since $S^i \setminus S^0$ only includes selectors applied to terms having finite datatype type.
Now, let $\tcEc$ be the set of subterms of $\Ec \cup \{ C_i( s^1_i( t ), \ldots, s^{a_i}_i( t ) ) \mid t \in S^\ast, t : \tau, C_i \in \Ctr^\tau \}$.
In a derivation tree with root node $\Ec$, 
it can be shown by case analysis on the rules of the calculus that each non-root node is 
the result of adding an equality between two terms from $\tcEc$ to its parent node.
Thus, the depth of a branch in a derivation tree with root node $\Ec$ is at most $\mid \tcEc \mid^2$,
which is finite since $\tcEc$ is finite.
\qed
\end{proof}

\begin{lemma}[Refutation Soundness]
If there exists a closed derivation tree with root node $\Ec$, then $\Ec$ is unsatisfiable in $\thD$.
\end{lemma}
\begin{proof}
We prove this by structural induction on the (closed) derivation tree with root node $\Ec$.
First, if the derivation tree is an application of \rn{Conflict}, \rn{Unify$_2$}, or \rn{Cyclic},
then $\Ec$ is unsatisfiable in $\thD$.
\rem{Elaborate on cyclic?}
If the children of $\Ec$ are closed derivation trees 
whose root node is the result of applying the rule \rn{Split} on term $t$ of type $\tau$,
then by the induction hypothesis $\Ec \cup t \teq C_i( s^1_i( t ), \ldots, s^{a_i}_i( t ) )$ is unsatisfiable
for each $C_i \in \Ctr^\tau$.
Since all models of $\thD$ entail exactly one equality $t \teq C_i( s^1_i( t ), \ldots, s^{a_i}_i( t ) )$,
we know $\Ec$ is unsatisfiable in $\thD$.
Otherwise, the child of $\Ec$ is a closed derivation tree 
whose root node is $\Ec \cup t_1 \teq t_2$ obtained by applying one of the rules \rn{Refl}, \rn{Symm}, \rn{Trans}, \rn{Cong}, \rn{Unify$_1$}, \rn{Bisimilar}, or \rn{Singleton}.
In all cases, we have that $\Ec \models_{\thD} t_1 \teq t_2$.
\rem{Elaborate on Bisimilar?}
By the induction hypothesis, we have $\Ec \cup t_1 \teq t_2$ is unsatisfiable in $\thD$, 
and thus $\Ec$ is unsatisfiable in $\thD$.
\qed
\end{proof}

\begin{lemma}[Solution Soundness]
If there exists a derivation tree containing a saturated node with root node $\Ec$, then $\Ec$ is satisfiable in $\thD$.
\end{lemma}
\begin{proof}
TODO
\end{proof}

\rem{Thus, sound and complete.}
  
\section{The Theory Solver}
\label{sec:the-theory-solver}

  * Strategies
  * Implementation
    * what is an SMT theory solver
    * cooperation with Nelson-Oppen / integration into SMT solver
    * "mu" stuff
    * no "internal search"
  * Enumerator?
    * for model generation

%\section{Examples}
%\label{sec:examples}

\section{Experimental Results}
\label{sec:experimental-results}

  * Constructed examples
    * proving
    * model finding?

  * Isabelle benchmarks


\section{Conclusion}
\label{sec:conclusion}

Future work:

  * more evaluation
    * use it in a new Nitpick-like tool
  * recursive and corecursive functions
    (and rewriting)
  * extensions, perhaps straightforward, to polymorphism and nested
    (co)recursion

\def\ackname{Acknowledgment}
\paragraph{\ackname.}

Clark Barrett and Cesare Tinelli.

Bosses: Viktor Kuncak, Stephan Merz, Tobias Nipkow, and Christoph Weidenbach.

The research was partially supported by the Deutsche
Forschungs\-gemein\-schaft (DFG) project
\relax{Hardening the Hammer} (grant Ni\,491\slash 14-1).

\bibliographystyle{splncs03}
\bibliography{bib}{}

\end{document}
