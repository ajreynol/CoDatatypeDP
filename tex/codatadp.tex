\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{arydshln}
\usepackage[scaled=.82]{beramono}
\usepackage{booktabs}
\usepackage{bussproofs}
\usepackage{calc}
\usepackage{cite}
\usepackage{mathptmx}
%\usepackage{txfonts}
%\usepackage{mathrsfs}
%\usepackage{pifont}
%\usepackage{smallcap}
\usepackage{mathpartir} 
\usepackage{stmaryrd}
\usepackage{subfigure}
\usepackage[usenames]{color}
%\usepackage{graphicx}
%\usepackage{newcent}
\usepackage{textcomp}
%\usepackage{tipa}
\usepackage{units}
\usepackage{url}
\usepackage[all]{xy}

\def\thewordpaper{paper}
\newcommand\dotReportFootnote[1]{.}

\newcommand\afterDot{\;} %%% Too little space by default after "Lemma Foo."

\begin{report}
\def\thewordpaper{report}
\renewcommand\dotReportFootnote[1]{.\footnote{#1}}
\end{report}

\newcommand\afterLdots{\kern.1em} %% TYPESETTING

% for "bussproofs" package
\EnableBpAbbreviations
\def\ScoreOverhang{1.5pt}
\def\proofSkipAmount{\vskip 0pt}
\def\defaultHypSeparation{\hskip0.75em}

\DeclareFontFamily{OT1}{pzc}{}
\DeclareFontShape{OT1}{pzc}{m}{it}{<-> s * [1.10] pzcmi7t}{}
\DeclareMathAlphabet{\mathscr}{OT1}{pzc}{m}{it}

\DeclareMathAlphabet{\mathcal}{OT1}{pzc}{m}{it}

\let\labelitemi=\labelitemii %% CHEAT!

\newcommand\cpp{C\nobreak\raisebox{.05ex}{+}\nobreak\raisebox{.05ex}{+}}

\newcommand\iPrime{i\vthinspace'\negvthinspace}
\newcommand\jPrime{j\vthinspace'\negvthinspace}

\newcommand\Sig{\mathrm{\Sigma}}

\newcommand\keyw[1]{\textbf{#1}}
\newcommand\const[1]{\textsf{#1}}
\newcommand\ty[1]{\textit{#1}}

%\renewcommand{\vec}[1]{\mathbf{#1}}
\renewcommand{\vec}[1]{\bar #1}
\newcommand{\Ec}{\mathsf{E}}
\newcommand{\Fc}{\mathsf{F}}
\newcommand{\Gc}{\mathsf{G}}
\newcommand{\Ac}{\mathsf{A}}
\newcommand{\Dc}{\mathsf{D}}
\newcommand{\Rc}{\mathsf{R}}
\newcommand{\vrange}{\mathsf{range}}
\newcommand{\vdom}{\mathsf{dom}}
\newcommand{\tEc}{\mathcal{T}(\Ec)}
\newcommand{\tcEc}{\mathcal{T}^\ast(\Ec)}
\newcommand{\rn}[1]{\textsf{\small #1}}
\newcommand{\cvc}{\textsc{cvc}{\small 4}\xspace}
\newcommand{\teq}{\approx}
\newcommand{\tneq}{\not\teq}
\newcommand{\rem}[1]{\textcolor{red}{[#1]}}
%\newcommand{\is}[1]{is\text{-} #1}
\newcommand{\is}[1]{\const{is#1}}
\newcommand{\ror}{\quad \parallel \quad}
\newcommand{\tpath}[2]{\mathcal{P}_{ #2 \rightarrow \_ }( #1 )}
\newcommand{\ttpath}[3]{\mathcal{P}_{ #2 \rightarrow #3 }( #1 )}
\newcommand{\interp}[1]{[\![ #1 ]\!]}
\newcommand{\dpath}[3]{\delta^{#1}_{#2}( #3 )}
\newcommand{\ec}[1]{ [ #1 ] }
\newcommand{\M}{\mathcal{M}}
\newcommand{\Val}{\mathcal{A}}
\newcommand{\nf}[1]{{#1}\!\!\downarrow}
\newcommand{\vsim}{\sim}
\newcommand{\aequiv}{\mathrel{=_\alpha}}
\newcommand{\vsimv}[1]{\vsim_{#1}}
\newcommand{\tpos}[2]{#1\!\mid_{#2}}
\newcommand{\muvar}{\mathcal{Var}}

% change?
\newcommand{\thO}{T_{o}}
\newcommand{\thD}{T_{d}}

%\newcommand\Types{\mathcal{T}}
\newcommand\Types{\mathcal{Y}}
\newcommand\Funcs{\mathcal{F}}

\newcommand\Data{\Types_{\mathrm{dt}}}
\newcommand\Codata{\Types_{\mathrm{codt}}}
\newcommand\Nondata{\Types_{\mathrm{ord}}}

\newcommand\Ctr{\Funcs_{\mathrm{ctr}}}
\newcommand\Sel{\Funcs_{\mathrm{sel}}}
%\newcommand\Plainfuncs{\Funcs_{\mathrm{other}}}

\newcommand\vthinspace{\kern+0.083333em}
\newcommand\negvthinspace{\kern-0.083333em}

%%% For final version as well?
\usepackage[
   a4paper,
   pdftex,
   pdftitle={A Decision Procedure for (Co)datatypes in SMT Solvers},
   pdfauthor={Andrew Reynolds and Jasmin Christian Blanchette},
   pdfkeywords={},
   pdfborder={0 0 0},
   draft=false,
   bookmarksnumbered,
   bookmarks,
   bookmarksdepth=2,
   bookmarksopenlevel=2,
   bookmarksopen]{hyperref}

\urlstyle{ttstyle}

\global\def\figurename{Figure}

\DeclareSymbolFont{letters}{OML}{txmi}{m}{it}

%%% REMOVE BEFORE SUBMITTING ABSOLUTELY FINAL VERSION
\makeatletter
\ps@myheadings
\makeatother

\include{defs}

\hyphenation{data-type data-types co-data-type co-data-types}


\begin{document}

\title{A Decision Procedure for (Co)datatypes in SMT Solvers}

\author {Andrew Reynolds\inst{1} \and Jasmin Christian Blanchette\inst{2,3}}
\authorrunning {A. Reynolds \and J. C. Blanchette}
\institute{
\'Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL), Switzerland
\and
Inria Nancy \& LORIA, Villers-l\`es-Nancy, France
\and
Max-Planck-Institut f\"ur Informatik, Saarbr\"ucken, Germany
}

\maketitle

\begin{abstract}
Codatatypes naturally capture potentially infinite data structures and
processes. We present a decision procedure that combines reasoning about
datatypes and codatatypes. The dual of the cyclicity rule for datatypes is a
bisimilarity rule that identifies equal values, also in the presence of cyclic
($\omega$-regular) data. The procedure decides ground and universal
problems and is composable via the Nelson--Oppen method. It has been
implemented in the latest version of CVC4, a state-of-the-art SMT solver. An
evaluation based on problems generated from Isabelle theories demonstrates the
potential of the procedure.
\end{abstract}

%% The institutions above shouldn't count as footnotes
\setcounter{footnote}{0}

\section{Introduction}
\label{sec:introduction}

Freely generated inductive datatypes are ubiquitous in functional programs and
logical specifications. They are especially
useful to represent finite data structures in computer science applications but
also arise when formalizing mathematics.
They can be implemented efficiently and enjoy
properties that can be exploited in automated reasoners. 
%
%However, because datatype values correspond to finite ground terms, they
%are generally not adequate to represent infinite objects.
%For example, the datatype of natural numbers
%constructed by $\const{Z} : \ty{nat}$ and $\const{S} : \ty{nat} \to \ty{nat}$
%only allow values of the form $\const{S}(\ldots(\const{S}(\const{Z}))\ldots)$.

To represent infinite objects, % such as $\const{S}(\const{S}(\const{S}(\ldots))$,
a natural choice is to turn to coinductive datatypes, or \emph{codatatypes},
the non-well-founded dual of inductive \emph{datatypes}.
%
Despite their reputation for being esoteric, codatatypes have a
role to play in computer science. The verified C compiler CompCert
\cite{leroy-2009}, the verified Java compiler Jinja\-Threads
\cite{lochbihler-2010-jinja}, and the formalized Java memory model
\cite{lochbihler-2014-jmm} all depend on codatatypes to capture infinite
processes.

Codatatypes are freely generated by their constructors, but in contrast with datatypes,
infinit\-e constructor terms are also legitimate values for codatatypes
(Section~\ref{sec:the-theory-of-co-datatypes}). Intuitively, the
values of a codatatype consist of all well-typed finite and infinite ground constructor
terms, and only those. For example, the coinductive specification
%
\[\keyw{codatatype}~\,\ty{enat} \,=\, \const{Z} \,\mid\, \const{S}(\ty{enat})\]
%
(using an ML-like syntax) introduces a type that
models the natural numbers $\const{Z}$, $\const{S}(\const{Z})$, $\const{S}(\const{S}(\const{Z}))$, $\ldots$\afterLdots{},
using Peano notation but extended with an
infinity value $\infty = \const{S}(\const{S}(\const{S}(\ldots)))$. Compared
with the more conventional, inductive definition with a dedicated constructor
for representing infinity,
%\[\keyw{datatype}~\,\ty{enat} \,=\, \const{Z} \,\mid\, \const{S}(\ty{enat}) \,\mid\, \const{Infty}\]
%
the codatatype avoids one case by unifying the finite and infinite nonzero cases.
Moreover, equations such as $\const{S}(\infty) \teq \infty$ hold by default,
because both sides expand to the infinite term
$\const{S}(\const{S}(\const{S}(\ldots)))$, which uniquely identifies the
value~$\infty$.

\nopagebreak

Datatypes and codatatypes are an integral part of modern proof assistants,
including Agda, Coq, Isabelle, Matita, and PVS. In recent years, datatypes
have made their appearance in a few automatic theorem provers. The SMT-LIB~2
\cite{barrett-et-al-2010} syntax, implemented by most SMT (satisfiability
modulo theories) solvers, includes a theory of datatypes.

\pagebreak

In this \thewordpaper, we introduce a unified decision procedure for ground
problems involving datatypes and codatatypes in combination
(Section~\ref{sec:a-ground-decision-procedure-for-co-datatypes})
and discuss extensions  of the procedure for handling quantifiers
(Section~\ref{sec:extension-to-quantified-formulas}).
The procedure is described abstractly as a calculus and is
designed to be composable via the Nelson--Oppen method \cite{nelson-oppen-1979}.
For the datatype case, it follows the lines of Barrett et al.\ \cite{barrett-et-al-2007}.
To our knowledge, our procedure is the first of its kind for the theory of
codatatypes. 

Datatypes and codatatypes share many of the same properties, so it makes sense
to consider them together. There are, however, at least three important
differences.

First, \emph{codatatypes need not be well-founded.}
For example, the type
%
\[\keyw{codatatype}~\;\ty{stream}_{\,\tau} \,=\, \const{SCons}(\tau,\: \ty{stream}_{\,\tau})\]
%
of infinite sequences, or streams, over an element type $\tau$ is allowed; the
corresponding datatype would be rejected as non-well-founded \cite{blanchette-et-al-2015-esop}.

Second, \emph{a bisimilarity rule takes the place of the cyclicity rule of datatypes.}
Cyclic constraints such as
$\const{x} \teq \const{S}(\const{x})$ %, where $\const{C}$ is a constructor,
are unsatisfiable for datatypes but satisfiable for codatatypes.
The bisimilarity principle states that two values having the same (possibly
infinite) expansion must be equal; from $\const{x} \teq \const{S}(\const{y})$ and
$\const{y} \teq \const{S}(\const{x})$, it deduces $\const{x} \teq \const{y}$.
The cyclicity and bisimilarity rules are needed to ensure completeness on
ground problems and the absence of spurious models. They cannot be replaced by
finite axiomatizations, so they naturally belong in a decision procedure.
%    * in particular, acyclicity and bisimilarity are necessary for some proofs
%%      (and cannot be axiomatized finitely)
%    * and for model finding, without them we quickly get spurious models
%    * explain how finite model finding works
%(For the other (co)datatype properties---the injectivity, distinctness, and
%exhaustiveness of constructors and the selector laws---it is
%widely recognized that decision procedures can be more efficient than
%axiomatizations.)
%axiom.

Third, \emph{it must be possible to express cyclic }(\emph{$\omega$-regular}) \emph{values as closed terms and
to enumerate them.} This is necessary both for finite model finding (modulo theories)
and for theory combinations. The $\mu$-binder notation associates a name with
a (sub)term; it is used to represent cyclic values in the generated models and
in the metatheory. For example,
the $\mu$-term $\const{SCons}(1,\: \mu s.\; \const{SCons}(0,\: \const{SCons}(9,\: s)))$
stands for the lasso-shaped sequence $1, 0, 9, 0, 9, 0, 9, \ldots$\afterLdots.

%%% 1090909 is a prime number


\begin{paper}
Proofs of soundness and completeness are included in the technical report
associated with this paper \cite{our-report}.
\end{paper}%
The procedure is implemented in the SMT solver CVC4 as a combination
of rewriting and a theory solver
(Section~\ref{sec:the-theory-solver}).
%\textbf{TODO: CHECK WITH IMPLEMENTATION, but round to nearest 50 or 1000.}
It consists of about 2000 lines of \cpp{} code, among which 1600 are
shared between datatypes and codatatypes. The code is integrated in the
development version of the solver and is expected to be part of the CVC4~1.5 release.
%
An evaluation on %hand-crafted examples and on
problems generated from Isabelle theories using the Sledgehammer tool
demonstrates the usefulness of the approach (Section~\ref{sec:experimental-results}).

%  * useful both for proving and for model finding

%\ref{sec:examples}

%  * benchmarking is often an issue -- esp. codatatypes
%
%Polymorphic types, nested (co)recursion, and datatype--codatatype mixtures fall

%  * setting: FOL
%    * core procedure is restricted to ground
%      * but theory solver cooperates

%  * codatatypes were added later, motivated by the use of SMT solvers as
%    backends to proof assistants (more specifically, CVC4 to Isabelle/HOL)

%  * setting :
%    * universal formulas
%    * many-sorted logic
%   * mutually (co)recursive types with constructors, selectors, and
%      discriminators

%  * codatatypes: from a theoretical and implementational point of view, like
%      datatypes but:
%    * infinite values (infinitely many nested constructors)
%    * codatatypes are never empty (e.g. finite streams are rejected)

%\[
%      \keyw{codatatype}\; \,\ty{llist} \,=\, \const{LNil} \,\mid\, \const{LCons}(\ty{int},\: \ty{llist})
%\]

%  * consider a natural fragment---datatypes as supported in modern SMT solvers
%    and the SMT-LIB 2 standard, and codatatypes as their duals
%    * mutual recursion, but no polymorphism, nested recursion
%  * integrated with Nelson-Oppen

% * SMT-Lib

%  * one implication is that if $m$ equals $ES(n)$ and $n$ equals $ES(m)$, necessarily
%    $m$ and $n$ must be equal.

%  * perhaps the most commonly used codatatype is that of lazy lists or sequences.
%    using a syntax similar to Standard ML, Haskell, or SMT-LIB

%  * less briefly: codatatypes and why they are useful
%    * in Agda, Coq, Matita -- recently also in Isabelle/HOL \cite{nipkow-et-al-2002}
%    * but not in SMT-LIB 2 \cite{barrett-et-al-2010}

\paragraph{Related Work.}
Although it was written several years ago, the account of related work in
Barrett et al.\ \cite{barrett-et-al-2007} is still a good starting point.
Since then, datatypes have been added to the SMT solver
Z3 in unpublished work by Leonardo de Moura and to a SPASS-like prototype
superposition prover called Pirate by Daniel Wand.
Closely related is the automatic structural
induction in CVC4 by Reynolds and Kuncak \cite{reynolds-kuncak-2015} and in
Pirate by Wand and Weidenbach \cite{wand-weidenbach-201x};
both methods naturally depend on a notion of datatype.

%     * point to Barrett et al. for SMT datatypes
%       * about their own work, they say: "our focus is on generality and
%         efficiency rather than immediacy of implementation"
%       * (deal more directly with finite sorts than Barrett et al., Section 6.1)
%     * SPASS-Pirate
%     * additional ones since then (e.g. strings?)
%     * anything about codatatypes?
%       * proof assistants like Agda, Coq, etc. have them
%       * Dafny, CoALP
%       * also a lot of theoretical research, some of which is loosely connected,
%         e.g. decision procedure for corecursive functions (Henning in Nijmegen)
% 
%     * ODDITY: Oppen 1980: single-constructor, recursive -- infinite values?

\paragraph{Conventions.}
The setting is a monomorphic (or many-sorted) first-order logic.
A signature $\Sig = (\Types, \Funcs)$ consists of a set of types $\Types$ and a
set of function symbols $\Funcs$. Types are simply atomic sorts, with no
structure, and interpreted by nonempty domains. The set~$\Types$ must contain a
distinguished type \ty{bool}\begin{report} interpreted as the set of truth
values $\{\bot, \top\}$\end{report}. %, and may contain other interpreted types (e.g., \ty{int}, \ty{real}).
The only predicate is equality ($\teq$)\begin{report} and belongs to the logical symbols\end{report}.
Other predicates can be represented as functions to $\ty{bool}$,
with $\const{p}(\ldots)$ abbreviating $\const{p}(\ldots) \teq \const{true}$.
\begin{report}
The metavariables $\delta,\:\varepsilon$ range over (co)datatypes,
whereas $\tau,\:\upsilon$ range over arbitrary types.
When applied to terms, the symbol $=$ denotes syntactic equality.\end{report}

\begin{report}
Function symbols are written in a sans-serif font (e.g., $\const{f}$, $\const{g}$) to
distinguish them from variables (e.g., $x$, $y$).
\end{report}
Symbols starting with an uppercase letter (e.g.,
$\const{S}$, $\const{SCons}$) are reserved for constructors. With each function symbol \const{f}
is associated a list of argument types $\tau_1,\ldots,\tau_n$ (with $n \ge 0$)
and a return type $\tau$. This connection can be expressed %compactly
as $\const{f} : \tau_1 \times \cdots \times \tau_n \to \tau$\begin{report},
which collapses to $\const{f} : \tau$ if $n = 0$\end{report}.
For a term $t$, the notation $t : \tau$ indicates that it has type $\tau$.
Functions are invoked in the standard way, with $\const{f}(t_1,\ldots,t_n)$
applying the $n$-ary function symbol
\const{f} to $n$ well-typed arguments $t_1 :\nobreak \tau_1$, \ldots, $t_n :
\tau_n$. Nullary function symbols are called constants and can appear without
parentheses in terms.
%
Finally, the notation $\bar x$ abbreviates a list or tuple $x_1,\ldots,x_n$
and $\bigwedge_{\,i}\, \varphi_i$ abbeviates a conjunction
$\varphi_1 \mathrel\land \cdots \mathrel\land \varphi_n$.

%* although nothing prevents composing the decision procedure with theories
%  providing polymorphic types (parametric sorts), such as for arrays (e.g., $\ty{array}(\alpha,\beta)$)

\section{The Theory of (Co)datatypes}
\label{sec:the-theory-of-co-datatypes}

%    (terminology: freely-generated, inductive, algebraic, ..., sometimes
%    with different meanings; we'll clarify below what we use)

We fix a signature $\Sig = (\Types, \Funcs)$. The types are partioned into
$\Types = \Data \mathrel{\uplus} \Codata \mathrel{\uplus} \Nondata$, where $\Data$ are the
\emph{datatypes}, $\Codata$ are the \emph{codatatypes}, and $\Nondata$ are the %remaining
\emph{ordinary types}. The function symbols are partitioned into $\Funcs = \Ctr
\mathrel{\uplus} \Sel$, where $\Ctr$ are the \emph{constructors} and $\Sel$ are the
\emph{selectors}. There is no need to consider further function symbols
because they can be abstracted away as variables when combining theories.
Exceptionally, it is convenient to use natural number
constants ($0$, $1$, \ldots)\ in examples.

\paragraph{Specifications.}
In an SMT problem, the signature is normally given by specifying the
uninterpreted types in any order, the (co)datatypes with their constructors
and selectors in groups of mutually (co)recursive groups of (co)datatypes, and
finally any other function symbols.
%
A (co)datatype specification consists of $l$~mutually recursive types which are
either all datatypes or all codatatypes. Polymorphic types, nested
(co)recursion, and datatype--codatatype mixtures fall outside this fragment%
\dotReportFootnote{%
In principle, rank-1 (top-level) polymorphism \cite{blanchette-paskevich-2013}
should not raise any special difficulties. Nesting datatypes inside datatypes,
and likewise for codatatypes, can be reduced to the mutual case
\cite{gunter-1993-not}. So the only genuinely interesting cases missing are
mixed nested (co)recursion as well as
(co)recursion through a non-(co)datatype (both of which make sense
\cite{blanchette-et-al-2014-codata}).}
In the presentation, we allow ourselves some metalevel parameterization
% at the metalevel
through subscripts---for example, $\ty{stream}_{\,\tau}$ denotes a
family of ground types including
$\ty{stream}_{\,\ty{int}}$, $\ty{stream}_{\,\ty{bool}}$,
and \smash{$\ty{stream}_{\,\ty{stream}_{\,\ty{real}}}$}.

\newcommand\elll{\kern.18ex l\kern.11ex}
\newcommand\elllx{\kern.11ex l\kern.18ex}

Each datatype $\delta$ is equipped with
$m \ge 1$ constructors, and each constructor for $\delta$ takes zero or more
arguments and returns a $\delta$ value. The argument types must be either
ordinary, among the already known (co)datatypes, or among the (co)datatypes
being introduced.
%
To every argument corresponds a selector. The names for the (co)data\-types, the
constructors, and the selectors must be distinct and different from
existing names%
\dotReportFootnote{It can be convenient to specify the same selector
for several constructors associated with the same (co)data\-type,
as long as the argument types coincide. % \cite[Section~3]{blanchette-et-al-2014-codata}.
However, this is disallowed by SMT-LIB 2, so we do not consider it here.}
Schematically:
%
\[
\begin{aligned}[t]
\!(\keyw{co})\keyw{datatype}\;\,
  \delta_1 & {}= \smash{\const{C}_{11\!}(\bigl[\const{s}_{11\!}^1{:}\bigr]\vthinspace \tau_{11\!}^1, \ldots, \bigl[\const{s}_{11\!}^{n_{11\!}}{:}\bigr]\vthinspace \tau_{11\!}^{n_{11\!}})} \mid \cdots \mid \smash{\const{C}_{1m_1\!}(\ldots)} \\
   \smash{\vdots\,\,\,} \\[-1\jot]
  \keyw{and}\; \,\delta_{\elllx} & =\, \smash{\const{C}_{\elll 1\!}(\bigl[\const{s}_{\elll 1\!}^1{:}\bigr]\vthinspace \tau_{\elll 1\!}^1, \ldots, \bigl[\const{s}_{\elll 1\!}^{n_{\elll 1\!}}{:}\bigr]\vthinspace \tau_{\elll 1\!}^{n_{\elll 1\!}})} \mid \cdots \mid \smash{\const{C}_{\elll m_{\elllx}\!}(\ldots)}
\end{aligned}
\]
%
with
$\const{C}_{i\negvthinspace j} : \tau_{i\negvthinspace j}^1\times\cdots\times\tau_{i\negvthinspace j}^{\,k_{\smash{i\negvthinspace j}}} \to \delta_i$
and $\const{s}_{i\negvthinspace j}^{\,k} : \delta_i \to \tau_{i\negvthinspace j}^{\,k}$. Defaults are assumed for
the selector names if they are omitted.

For types with several constructors, it is customary to provide discriminators
$\const{d}_{i\negvthinspace j} : \delta_i \to \ty{bool}$. However,
it is not necessary to extend the signature:
The discriminator term $\const{d}_{i\negvthinspace j}(x)$ can be seen as an abbreviation for
$x = \const{C}_{i\negvthinspace j}\bigl(\const{s}_{i\negvthinspace j}^1(x), \ldots, \const{s}_{i\negvthinspace j}^{\,n_{\smash{{i\negvthinspace j}}}}(x)\bigr)$.
%This will simplify the presentation. % of the decision procedure.

Here are a few examples of legal specifications of (co)datatype families:
\[\begin{aligned}[t]
      \keyw{codatatype}\; \,\ty{llist}_{\,\tau} & \,=\, \const{LNil} \,\mid\, \const{LCons}(%\const{lhead}{:}\;
      \tau,\: %\const{ltail}{:}\;
      \ty{llist}_{\,\tau}) \\%[-.5\jot]
      \keyw{datatype}\;\, \ty{tree}_{\,\tau} & \,=\, \const{Node}(\tau,\:\, \ty{forest}_{\,\tau}) \\[-\jot]
      \keyw{and}\;\,\, \ty{forest}_{\,\tau} & \,=\, \const{FNil} \,\mid\, \const{FCons}(\ty{tree}_{\,\tau},\:\, \ty{forest}_{\,\tau})
\end{aligned}
\]

\begin{report}%
Because all types must be inhabited (nonempty), a datatype specification is
admissible only if a ground constructor term can be exhibited.
This rules out non-well-founded specifications such as
\[\keyw{datatype}\;\, \ty{fstream}_{\,\tau} \,=\, \const{FSCons}(\tau,\:\, \ty{fstream}_{\,\tau})\]
For codatatypes, no admissibility check is necessary because there is always a term,
finite or infinite, that witnesses nonemptiness \cite{blanchette-et-al-2015-esop}.
\end{report}
%Given the specification
%
%\[\keyw{codatatype}\;\, \ty{stream} \,=\, \const{SCons}(\ty{int},\:\ty{stream})\]
%
%the infinite value $\const{SCons}(0, \const{SCons}(0, \ldots))$ witnesses
%nonemptiness.

\paragraph{Characterization.}
Datatypes can be defined semantically as the initial model of the
selector--constructor equations. This is the view followed by Barrett et al.\
\cite{barrett-et-al-2010}.
\begin{report}
A drawback of this approach is that it does
not naturally account for selectors applied to wrong constructors. Barrett et
al.\ address this by parameterizing the construction by default values, but
this gives rise to spurious equalities between unrelated terms---e.g.,
$\const{s}_{11}(\const{C}_2) \teq \const{s}_{11}(\const{C}_3)$. This flaw
could be corrected, but the added complexity seems to suggest that selectors
are better characterized axiomatically.

\end{report}
A related semantic view of datatypes is as initial algebras \cite{xxx}.
Codatatypes are then defined dually as final coalgebras \cite{xxx}. The
datatypes are generated by their constructors, whereas the codatatypes are
viewed through their selectors.
%By uniformly focusing on the constructors, the
%axiomatic approach emphasizes the commonality between datatypes and
%codatatypes, while sacrificing a theoretically fruitful notion of duality.

Datatypes and codatatypes share many basic properties pertaining to
constructors and selectors. All properties below are implicitly universally
quantified and range over all $i$, $j$, $\jPrime$, and $k$ within bounds:
% and to all possible splits of the
%$n$-ary constructor $\const{C}_{i\negvthinspace j}$'s argument list into $\bar x,
%y, \bar z$:
%
\[
\begin{aligned}[t]
\text{Distinctness:}\quad
  & %\forall \bar x, \bar y.\;\,
    \smash{\const{C}_{i\negvthinspace j}(\bar x) \tneq \const{C}_{i\negvthinspace \jPrime}(\bar y) \quad\text{if $j \not= \jPrime$}}
  \\[-.5\jot]
\text{Injectivity:}\quad
  & %\forall x_1,\ldots,x_{n_{i\negvthinspace j}} y.\;\,
    \smash{\const{C}_{i\negvthinspace j}(x_1,\ldots,x_{n_{i\negvthinspace j}}) \teq \const{C}_{i\negvthinspace j}(x_1,\ldots,x_{k-1},y,x_{k+1},\ldots,x_{n_{i\negvthinspace j}}) \longrightarrow x_k \teq y}
  \\[-.5\jot]
\text{Exhaustiveness:}\quad
  & \smash{\is{C}_{i1}(x) \mathrel\lor \cdots \mathrel\lor \is{C}_{im_i}(x)}
  \\[-.5\jot]
\text{Selection:}\quad
  & \smash{\const{s}_{i\negvthinspace j}^{\,k}(\const{C}_{i\negvthinspace j}(x_1,\ldots,x_{n_{i\negvthinspace j}})) = x_k}
\end{aligned}
\]
%
\begin{report}
Expressed in the algebraic jargon, exhaustiveness helps ensure that ``no
junk'' exists, whereas distinctness and injectivity guarantee that ``no
confusion'' can arise.
The result of selectors applied to the wrong
constructor is left completely unspecified.
\end{report}

%  * how to deal with "wrong" selectors, e.g.
%        hd(nil1) = hd(nil2)?
%      * leave them unspecified; hence hd(nil1) = hd(nil2) in some models,
%        and not in other models

Datatypes are additionally characterized by an induction axiom schema\begin{report}:
%
\[
\begin{aligned}[t]
\text{Induction:}\quad
\AXC{\strut$\bigwedge_{\,i,j}\, \forall x_1 \ldots \vthinspace x_{n_{i\negvthinspace j}}.\; \bigl(\bigwedge_{\,k}\, \mathit{IH}_{i\negvthinspace j}^k[x_k]\bigr) \longrightarrow P_i[C_{i\negvthinspace j}(x_1,\ldots,x_{n_{ij}})]$}
\UIC{\strut$\bigwedge_{\,i}\, P_i[v_i]$}
\DP
\end{aligned}
\]
where the induction hypothesis $\mathit{IH}_{i\negvthinspace j}^k(x)$
denotes either $P_{\iPrime}(x)$ if there exists some $\iPrime$ such that
the formula is type-correct or else $\top$\end{report}.
%
The axiom schema ensures that the interpretation of datatypes
is a standard model. For example,
for a datatype of natural numbers constructed from $\const{Z}$ and $\const{S}$,
induction prohibits nonstandard models, which could contain cyclic values---e.g.,
an $n$ such that $n \teq \const{S}(n)$---or even infinite acyclic values
$\const{S}(\const{S}(\ldots))$.
%
\begin{report}\par\end{report}
%
For codatatypes, the dual notion is called coinduction. \begin{report}It depends on
witnesses $R_i$ that are required to be bisimulations:
%
\[
\begin{aligned}[t]
\text{Coinduction:}\kern.8em %%% TYPESETTING: should be \quad
\AXC{\strut$\begin{gathered}\textstyle \bigwedge_{\,i}\, R_i[v_i, w_i] \\[-\jot]\textstyle
\bigwedge_{\,i}\, \forall v\; w.\;\, R_i[v, w] \longrightarrow
  \bigwedge_{\,j}\, \const{d}_j(v) \teq \const{d}_j(w)
  \mathrel\land
  \const{d}_j(v) \longrightarrow \bigwedge_{\,k}\, \const{s}_{i\negvthinspace j}^{\,k}(v) \sim \const{s}_{i\negvthinspace j}^{\,k}(w)
\end{gathered}$}
\UIC{\strut$\bigwedge_{\,i}\, v_i \teq w_i$}
\DP
\end{aligned}
\]
where $x \sim y$ denotes either $R_{\iPrime}[x, y]$ if there exists some
$\iPrime$ such that the formula is type-correct or $x \teq y$ otherwise.
\end{report}%
This axiom schema guarantees that two values that yield the same
observations must be equal, where the observations are made by using the
selectors and discriminators.
%
\begin{report}\par\end{report}
  %
In addition, codatatypes are guaranteed to contain all values corresponding to
infinite ground constructor terms. In general, this cannot be captured by a
first-order axiomatization, since there may be uncountably many of them.
\begin{report}
For example, $\ty{stream}_{\,\ty{int}}$ is isomorphic to the uncountable
function space $\ty{nat} \to \ty{int}$.
\end{report}

% TODO: where does this go?
%      * when looking at the universal ground (?) theory:
%        enough to consider acyclicity -- no way to specify infinite objects
%        otherwise

%    * codatatypes:
%      * coinduction axiom (schema)
%        * consequence: infinite objects are allowed, but
%          two objects yielding the same observations must be equal

%      * again: when looking at the universal ground (?) theory, enough to
%        consider bisimilarity/bisimulation

% specifies the 

\paragraph{Special Cases.}
A type $\delta$ depends on another type $\varepsilon$ if $\varepsilon$ is the
type of an argument to one of $\delta$'s constructors. Semantically, a set of
types is mutually (co)recursive if and only if the associated dependency graph
is strongly connected. Types can be declared together as mutually
(co)recursive even if they are not actually (co)recursive; however, the
semantic notion is more precise and is the one that interests us.
%
In addition, nothing forbids non(co)recursive specifications
such~as
\begin{paper}%
\vthinspace$\keyw{datatype}~\vthinspace\ty{option}_{\,\tau} = \const{None} \mid \const{Some}(\tau)$.%
\end{paper}%
\begin{report}%
\[\begin{aligned}[t]
      \keyw{datatype}\;\, \ty{option}_{\,\tau} & \,=\, \const{None} \mid \const{Some}(\tau) \\[-.5\jot]
      \keyw{codatatype}\; \,\ty{complex} & \,=\, \const{Complex}(\const{re}{:}\; \ty{real},\; \const{im}{:}\;\ty{real})
\end{aligned}
\]
At the semantic level, it makes no difference whether such types are
introduced as datatypes or as codatatypes.
\end{report}%
%Without loss of generality, we consider that these types are datatypes
%instead of codatatypes.

Some codatatypes are so degenerate as to have infinite values
even though they are finite. The simplest example is
\vthinspace$\keyw{codatatype}~\ty{a} = \const{A}(\ty{a})$, whose
only value is $\mu a.\; A(a)$. Other specimens are
\begin{paper}%
\vthinspace$\keyw{codatatype}~\ty{b} = \const{B}(\ty{b},\: \ty{c},\: \ty{b},\: \ty{unit})
~\keyw{and}~ \ty{c} = \const{C}(\ty{a},\: \ty{unit},\: \ty{b},\: \ty{c})$,
\end{paper}%
\begin{report}%
\[\begin{aligned}[t]
      \keyw{codatatype}\;\, \ty{b} & \,=\, \const{B}(\ty{b},\: \ty{c},\: \ty{b},\: \ty{unit}) \\[-1\jot]
      \keyw{and}\;\, \ty{c} & \,=\, \const{C}(\ty{a},\: \ty{unit},\: \ty{b},\: \ty{c})
\end{aligned}
\]
\end{report}
where \ty{unit} is a datatype with the single constructor $\const{Unity} :
\ty{unit}$, as well as $\ty{stream}_{\,\ty{unit}\,}$. We call such types
\emph{corecursive singletons}. For the decision procedure, it will be
important to detect these types. %, even if they rarely arise in practice.
A type may also be a corecursive singleton only in some models. If the example
above is altered to leave \ty{unit} uninterpreted, \ty{b} and \ty{c} will be
singletons precisely when \ty{unit} is interpreted as a singleton.
Fortunately, given cardinalities for the ordinary types, it is easy to
characterize this degenerate case:

% In other words, all finite corecursive codatatypes are corecursive singletons.

\begin{lemma}[Corecursive Singletons]%
\label{lem:corecursive-singletons}%
\afterDot
Let $\delta$ be a corecursive codatatype. The domain interpreting $\delta$ is
either infinite or a singleton. In the latter case, $\delta$ necessarily has a
single constructor, whose arguments have types that are interpreted as
singletons.
\end{lemma}

\begin{report}
\begin{proof}
By definition, the type is equipped with at least one (directly or indirectly)
corecursive constructor $\const{C}$. If it additional has second
corecursive constructor $\const{D}$, it is possible to encode infinitely many
alternation patterns---e.g.,
$\const{C}(\const{D}(\const{C}(\const{C}(\ldots))))$---all of which correspond
to distinct values (by distinctness and injectivity). If the type has a
noncorecursive constructor $\const{E}$, it is possible to create terms of
arbitrary depths---e.g., $\const{C}(\ldots(\const{C}(\const{E}))\ldots)$. In
both cases, there can be no finite models.

Therefore, $\const{C}$ must be the only constructor.
If any of its noncorecursive arguments has a cardinality greater than 1,
it is possible to encode alternation patterns using it---e.g.,
$\const{C}(0,\: \const{C}(1,\: \const{C}(0,\: \const{C}(0,\: \ldots))))$---which
again excludes finite models. Otherwise, the coinduction principle ensures
that the type has at most one value.
\qed
\end{proof}
\end{report}

%  * assume for simplicity no indirect recursion, but this does not radically
%    change the argument
%  * assume there are at least two values built with C.
%    they must be different at some point, e.g.
%    C(0, C(1, C(0, ...))) and C(0, C(1, C(1, ...)))
%    can use that to create infinitely alternation patterns
%  * leaves us with the case of a single constructor
% * since we are looking at a specific model, we can assume all ordinary
%   types are finite datatypes with nullary constructors corresponding to their
%   elements
% * if two
% * either there is only one ``path'' from ctr to itself
%   or at least two;

\section{The Ground Decision Procedure} % for (Co)datatypes}
\label{sec:a-ground-decision-procedure-for-co-datatypes}

This section presents a decision procedure for \rem{introduce ``$\thD$" in previous section?}
determining the $\thD$-satisfiability of sets of constraints built from a fixed signature $\Sig$.
We will make the following assumptions about $\Sig$.
First, all codatatypes in $\Codata$ are corecursive.
This is not restrictive, since checking the $\thD$-satisfiability for constraints involving a non-corecursive co-datatype $\tau$ can be trivially reduced to
checking the satisfiability of the same constraint involving a (non-recursive) datatype of the same form as $\tau$. \rem{revise?}
Second, all types $\tau \in \Nondata$ have infinite cardinality.
This also is not restrictive, since each interpreted type $\tau \in \Nondata$ having finite cardinality $n$
can be replaced by a enumeration datatype with $n$ constructors
\footnote{Doing so simplifies the presentation of the calculus, but is not done in practice. \rem{More?}}.
Additionally, since $\Ec$ is ground, we know that $\Ec$ cannot entail an upper bound on the cardinality of any uninterpreted type $\tau \in \Nondata$, 
and thus without loss of completeness we may treat all other types as infinite.

Our calculus consists of derivation rules that operate on a set $\Ec$ of equalities and disequalities between $\Sig$-terms,
where $\Ec$ is interpreted as a conjunction.
We write $\tEc$ to denote the set of $\Sig$-terms occurring in $\Ec$.
%We will commonly denote tuples of terms $( t_1, \ldots, t_n )$ in bold font, as $\vec t$.
We assume that all $\Sig$-terms in $\Ec$ are \emph{normalized}, meaning that all subterms of the form $\const{s}^{\,k}_j( \const{C}_j(t_1,\ldots,t_n) )$
are simplified to $t_i$, and moreover assume that all %additional
constraints added to $\Ec$ are normalized in this manner.

We present the calculus in three steps.
In the first step, we compute the bidirectional closure of $\Ec$;
in the second step, we make inferences based on cyclicity and bisimilarity;
and in the third step, %(when necessary),
we branch on constructor types for various terms in $\tEc$.
Following the conventions from~\cite{}, 
the derivation rules of our calculus are given in \emph{guarded assignment form},
where a rule can be applied to $\Ec$ if it meets all of the specified preconditions for $\Ec$.
The conclusion of a rule either describes equalities to be added to $\Ec$ (in which case we call an application of it \emph{nonterminal}),
or is $\bot$ (in which case we call an application of it \emph{terminal}).
A rule may have multiple conclusions separated by $\parallel$, which denotes nondeterministic branching.

\begin{figure}[t]
\normalsize
\centering
\begin{tabular}{c}
\(
\inferrule{
  t \in \tEc
}{
  \Ec := \Ec,\: t \teq t
}
\)
\rn{Refl}
\qquad
\(
\inferrule{
 t_1 \teq t_2 \in \Ec
}{
 \Ec := \Ec,\: t_2 \teq t_1
}
\)
\rn{Sym}
\qquad
\(
\inferrule{
  t_1 \teq t_2,\; t_1 \tneq t_2 \in \Ec
}{
  \bot
}
\)
\rn{Conflict}
\\[5\jot]
\(
\inferrule{
  t_1 \teq t_2,\; t_2 \teq t_3 \in \Ec
}{
  \Ec := \Ec,\: t_1 \teq t_3
}
\)
\rn{Trans}
\qquad
\(
\inferrule{
  \vec t \teq \vec u \in \Ec \quad \const f( \vec t \,),\, \const f( \vec u ) \in \tEc
}{
  \Ec := \Ec,\: \const f( \vec t \,) \teq \const f( \vec u )
}
\)
\rn{Cong} 
\\[5\jot]
\(
\inferrule{
  \const{C}( \vec t \,) \teq \const{C}( \vec u ) \in \Ec
}{
  \Ec := \Ec,\: \vec t \teq \vec u
}
\)
\rn{Decomp} 
\qquad
\(
\inferrule{
  \const{C}( \vec t \,) \teq \const{D}( \vec u ) \in \Ec
  \quad
  \const{C} \not= \const{D}
}{
  \bot
}
\)
\rn{Clash}
\end{tabular}
\caption{\,Rules for bidirectional closure%.
}
\label{fig:cc-rules}
\end{figure}

\paragraph{Step 1: Computing the Bidirectional Closure.}
Figure~\ref{fig:cc-rules} gives the basic rules of the calculus.
Together with \rn{Refl}, \rn{Sym}, and \rn{Trans}, the \rn{Cong} rule computes the (upward) congruence closure,
whereas the \rn{Decomp} and \rn{Clash} rules together compute (downward) unification.
In the unification rules, additional equalities are inferred based on the injectivity of constructors by \rn{Decomp},
and failures to unify equated terms are recognized by \rn{Clash}.
The rule \rn{Conflict} recognizes when an equality and its negation both occur in $\Ec$, in which case $\Ec$ has no model.

\begin{figure}[t]
\normalsize
\centering
\begin{tabular}{c}
\(
\inferrule{
  \tau \in \Data
  \quad
  t_1 : \tau
  \quad
  %\ttpath{\Ec}{\ec{t}}{\ec{t}} \neq \emptyset
  \Val \ec{t_1} = \mu x.\; t_2
  \quad
  x \in FV( t_2 )
}{
  \bot
}
\)
\rn{Cyclic}
\\[4\jot]
\(
\inferrule{
 \tau \in \Codata
 \quad
 t_1, t_2 : \tau
 \quad
 %\tpath{\Ec}{\ec{t_1}} = \tpath{\Ec}{\ec{t_2}}\sigma \neq \emptyset
 \Val \ec{t_1} \vsim \Val \ec{t_2}
}{
 \Ec := \Ec,\: t_1 \teq t_2
}
\)
\rn{Bisimilar}
\end{tabular}
\caption{\,Rules for cyclicity and bisimilarity%.
}
\label{fig:ab-rules}
\end{figure}

\paragraph{Step 2: Applying Cyclicity and Bisimilarity.}
In the second step,
we assume that $\Ec$ is saturated with respect to the rules in Figure~\ref{fig:cc-rules}---that is,
no rule can be applied to extend~$\Ec$ further.
When this is the case, it is easy to see that $\Ec$ induces an equivalence relation over $\tEc$ such that two terms $t_1$ and $t_2$ are equivalent if and only if $t_1 \teq t_2 \in \Ec$.
Thus, we can consider $\Ec$ as a set of equivalence classes of terms. 
For a term $t \in \tEc$, we write $\ec{t}$ to denote the equivalence class in $\Ec$ that contains $t$.

%For presentation of the rules in this step, we rely on a representation of terms in the $\mu$-notation.
The rules of this step contain premises that involve a mapping $\Val$ from equivalence classes to terms containing $\mu$-bindings.
Recall that $\mu$-bindings can be used for representing possibly cyclic terms and values.
%(Section~\ref{sec:introduction}).
% for example, $\mu x. \const{C}( \const{0}, x )$ represents the cyclic value $\const{C}( \const{0}, \const{C}( \const{0}, \ldots ))$.
Formally, $\mu$-terms are defined recursively as being either a variable $x$
or a node of the form
$\mu x.\; \const{C}( \vec t\, )$ for some constructor $\const{C} \in \Ctr$ and
$\mu$-terms $\vec t$ with the expected types.
The variable $x$ need not occur under the binder's body, in which case the $\mu$-prefix
is optional.

%%% But there are no constants of type $\tau \in \Nondata$ -- at most variables!
%
%For uniformity, we also consider $%\mu x.\;
%\const{c}$ to be a $\mu$-term if $\const{c}$ is a constant of type $\tau \in \Nondata$.

%%% I think this should be clear enough from the "Conventions" paragraph at the
%%% end of the introduction.
%%
% which we define recursively:
%if $\const{C} : \vec \tau \rightarrow \upsilon$
%and $\vec v$ are well-typed $\mu$-terms of type $\vec \tau$ under the assumption that $x$ has type $\upsilon$,
%then $\mu x. \const{C}( \vec v )$ is a well-typed term of type $\upsilon$.

A $\mu$-term is \emph{closed} if %and only if --- by convention, "and only if" is not necessary for *definitions* (but add it back if you disagree)
it contains no free variables. It is \emph{cyclic} if %and only if --- ditto
it contains an occurrence of a bound variable.
The notation $t \aequiv u$, expressing $\alpha$-\emph{equivalence},
indicates that the $\mu$-terms $t$ and $u$
are syntactically equivalent for some capture-avoiding renaming of $\mu$-bound variables.
For example, 
%$\mu x. \const{C}( x ) \aequiv \mu y. \const{C}( y )$ and
$\mu x.\; \const{D}( y, x ) \aequiv \mu z.\; \const{D}( y, z )$,
but
$\mu x.\; \const{C}( x ) \not\aequiv \mu x.\; \const{D}( y, x ) \not\aequiv \mu x.\; \const{D}( z, x )
\not\aequiv \mu y.\; \const{D}( y, x )$.
Two $\mu$-terms may represent the same value while not being $\alpha$-equivalent, as in
$\mu x.\; \const{C}( \const{C}( x ) ) \not\aequiv \mu x.\; \const{C}( x )$.
%, or informally are \emph{observationally equivalent}.
%For convienience, we use $\mu$-terms to refer to (classes of) values for both co-datatype and datatype terms,
%where in the latter case, a $\mu$-term with a bound variable denotes an infeasible term.
%where the latter case adds the restriction on $\mu$-terms $t$ that no subterms of $t$ contain are bound variables.

Intuitively, a $\mu$-term $t$ of type $\tau$ describes a class of values of $\tau$, 
%either in the case when $\tau$ is a co-datatype or datatype type,
where a cyclic $t$ describes an infeasible class of values when
%$\tau \not\in \Codata$.
$\tau \in \Data$.
At the beginning of this step, 
we compute a mapping $\Val$ from equivalence classes to $\mu$-terms 
that describe the class of values that terms in that equivalence class can take in the models of $\Ec$. 
For each equivalence class $\ec{x}$, we associate a fresh variable $v_{\ec{x}}$ of the same type as $x$ not occurring in $\tEc$,
and initially say that $\Val$ contains $\ec{x} \mapsto v_{\ec{x}}$,
in other words, there are initially no constraints on the values for any equivalence class $\ec{x}$.
Then, $\Val$ is modified by applying the following update exhaustively:
\[
\inferrule{
  v_{\ec{x}} \in FV( \Val )
  \quad
  \const{C}( t_1, \ldots, t_n ) \in \ec{x}
  \quad
  \const{C} \in \Ctr
}{
  \Val := \Val \{ v_{\ec{x}} \mapsto \mu v_{\ec{x}}. \const{C}( v_{\ec{t_1}}, \ldots, v_{\ec{t_n}} ) \}
}
\]
Here, we write $FV( \Val )$ to denote the \emph{free variables} occurring in $\Val$, which
excludes variables that occur beneath $\mu$-binders.
It is straightforward to see that the height of terms produced as a result of this update
is bounded by the number of equivalence classes of $\Ec$,
and thus our construction of $\Val$ is terminating.

\begin{example}
Say that $\Ec$ contains (distinct) equivalence classes $\ec{x}$, $\ec{y}$, $\ec{z}$ and $\ec{w}$ 
where $\const{C}(z,x) \in \ec{y}$ and $\const{C}(w,y) \in \ec{x}$ for some $\const{C} \in \Ctr$.
A possible sequence of updates applied to $\Val$ is shown below.
In the first column, we show the equivalence class that was considered,
and in the second column, we show the content of $\Val$.
\[\begin{array}{|l|@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l|}
\hline
\text{Eqc} & \multicolumn{3}{c}{\Val} & \ 
\\
\hline
& \{ & \ec{x} \mapsto v_{\ec{x}}, & \ec{z} \mapsto v_{\ec{z}}, & \\
&    & \ec{y} \mapsto v_{\ec{y}}, & \ec{w} \mapsto v_{\ec{w}} & \} \\
\ec{x}
& \{ & \ec{x} \mapsto \mu v_{\ec{x}}. \const{C}( v_{\ec{w}}, v_{\ec{y}} ), & \ec{z} \mapsto v_{\ec{z}}, & \\
&    & \ec{y} \mapsto v_{\ec{y}}, & \ec{w} \mapsto v_{\ec{w}} & \} \\
\ec{y}
& \{ & \ec{x} \mapsto \mu v_{\ec{x}}. \const{C}( v_{\ec{w}}, \mu v_{\ec{y}}. \const{C}( v_{\ec{z}}, v_{\ec{x}} ) ), & \ec{z} \mapsto v_{\ec{z}}, & \\
&    & \ec{y} \mapsto \mu v_{\ec{y}}. \const{C}( v_{\ec{z}}, v_{\ec{x}} ), & \ec{w} \mapsto v_{\ec{w}} & \} \\
\ec{x}
& \{ & \ec{x} \mapsto \mu v_{\ec{x}}. \const{C}( v_{\ec{w}}, \mu v_{\ec{y}}. \const{C}( v_{\ec{z}}, v_{\ec{x}} ) ), & \ec{z} \mapsto v_{\ec{z}}, & \\
&    & \ec{y} \mapsto \mu v_{\ec{y}}. \const{C}( v_{\ec{z}}, \mu v_{\ec{x}}. \const{C}( v_{\ec{w}}, v_{\ec{y}} ) ), & \ec{w} \mapsto v_{\ec{w}} & \} \\
\hline
\end{array}\]
This indicates that the values for $x$ (resp. $y$) in models of $\Ec$
are of the form $\const{C}( v_{\ec{w}}, \const{C}( v_{\ec{z}}, \ldots ))$ (resp. $\const{C}( v_{\ec{z}}, \const{C}( v_{\ec{w}}, \ldots ))$) 
for some value of $v_{\ec{w}}$ and $v_{\ec{z}}$.
\qed
\end{example}

Given $\Val$, the rules for cyclicity and bisimilarity (shown in Figure~\ref{fig:ab-rules}) can be stated as follows.
For cyclicity, if there is an equivalence class $\ec{t_1}$ of datatype type whose class of values $\Val \ec{t_1} = \mu x. t_2$ are cyclic,
as indicated by the assumption $x \in FV( t_2 )$,
then we can conclude that $\Ec$ is unsatisfiable.
For bisimilarity, if there are two equivalence classes $\ec{t_1}$ and $\ec{t_2}$ 
of co-datatype type whose classes of values $\Val \ec{t_1}$ and $\Val \ec{t_2}$ are equivalent for a capture-avoiding renaming of $\mu$-bound variables,
then we can conclude $t_1 \teq t_2$.
We demonstrate the bisimilarity rule concretely with the following example.

\begin{example}
Let $\const{C}$ be a constructor of type $\tau_1 \times \tau_2 \rightarrow \tau_2$,
and let $\Ec$ be the set $\{ x \teq \const{C}(y,\const{C}(y,x)) \}$.
After applying the rules in Figure~\ref{fig:cc-rules} to completion, the equivalence classes of $\Ec$ are
$\{ x, \const{C}(y,\const{C}(y,x)) \}$, $\{ \const{C}(y,x) \}$, and $\{ y \}$.
We then construct $\Val$ using the aforementioned steps, after which we obtain:
\[\begin{array}{l@{\hspace{.5em}}l@{\hspace{.5em}}r@{\hspace{.5em}}l@{\hspace{.5em}}r@{\hspace{.5em}}l}
\Val \ec{x} & = & 
\mu v_{\ec{x}}. & \const{C}( v_{\ec{y}}, & \mu v_{\ec{\const{C}(y,x)}}. & \const{C}( v_{\ec{y}}, v_{\ec{x}} ) ) \\
\Val \ec{\const{C}(y,x)} & = & 
\mu v_{\ec{\const{C}(y,x)}}. & \const{C}( v_{\ec{y}}, & \mu v_{\ec{x}}. & \const{C}( v_{\ec{y}}, v_{\ec{\const{C}(y,x)}} ) )
\end{array}\]
Notice that $\Val \ec{x}$ and $\Val \ec{\const{C}(y,x)}$ are syntactically equivalent for the renaming
$\{ v_{\ec{x}} \mapsto v_{\ec{\const{C}(y,x)}}, v_{\ec{\const{C}(y,x)}} \mapsto v_{\ec{x}} \}$,
and thus our calculus may infer $x \teq \const{C}(y,x)$.
Intuitively, this equality holds, since the values of $x$ and $\const{C}( y, x )$ 
are equivalent for any value of $v_{\ec{y}}$.
\qed
\end{example}

\begin{figure}[t]
\normalsize
\centering
\begin{tabular}{c}
\(
\inferrule{
  t, u : \tau \in \tEc
  \quad
  \tau \in \Codata,
  \mid \tau \mid = 1
}{
  \Ec := \Ec, t \teq u
}
\)
\rn{Singleton}
\\[5\jot]
\(
\inferrule{
  t : \tau \in \tEc 
  \quad 
  ( s( t ) \in \tEc, s \in \Sel^\tau ) 
  \text{ or } 
  ( \tau \in \Data, \tau \text{ finite } )
}{
  \Ec := \Ec, t \teq \const{C}_1( s^1_1( t ), \ldots, s^{a_1}_1( t ) ) \ror \ldots \ror \Ec := \Ec, t \teq \const{C}_n( s^1_n( t ), \ldots, s^{a_n}_n( t ) ) 
}
\)
\rn{Split} 
\end{tabular}
\caption{\,Rules for branching%.  
%All pairs of terms whose type has cardinality 1 are entailed to be equal (the degenerate case).
%Constructors must be assigned for all terms $t$ if has a selector is applied to it, or if $t$ has finite datatype type.
}
\label{fig:split-rule}
\end{figure}

\paragraph{Step 3: Branching.}
If neither a rule from Figure \ref{fig:cc-rules}~or~\ref{fig:ab-rules} applies to $\Ec$, 
the rules from Figure~\ref{fig:split-rule} are applied.
The rule \rn{Singleton} handles the case when there are two terms from $\tEc$ having a co-recursive singleton type,
in which case they must be equivalent.
Otherwise, in the case there is a selector term applied to $t$, or if $t$ has a finite datatype type, 
then the equivalence class of $t$ must contain an application of one of the constructors of $\tau$ (where $\Ctr^\tau = \{ C_1, \ldots C_n \}$), 
which is enforced by the rule \rn{Split}.

\ 

An application of a rule is \emph{redundant} if it is nonterminal and at least one branch in its conclusion does not add a new equality to $\Ec$.
A \emph{derivation tree} is a tree whose nodes are sets of equalities, where non-root nodes vtained by 
a nonredundant application of a derivation rule to its parent node.
A derivation tree is \emph{closed} if all of its leaf nodes are $\bot$.
A node is \emph{saturated} if no nonredundant application of a rule can be applied to it.
If there exists a closed derivation tree with root node $\Ec$, then we conclude that $\Ec$ is $\thD$-unsatisfiable.
If there exists a derivation tree with root node $\Ec$ that contains a saturated node, then we conclude that $\Ec$ is $\thD$-satisfiable. 

\paragraph{Correctness.}

\begin{lemma}[Termination]%
\label{lem:t}%
\afterDot
All derivation trees are finite.
\end{lemma}
\begin{proof}
Consider a derivation tree with root node $\Ec$.
Let $S$ be the set of terms occurring as the argument of a selector in $\tEc$.
Let $T$ be the set of terms in $\tEc$ of finite datatype type.
For each term $t \in T$,
let $S^0_t$ be the set $\{ t \}$,
for $i \geq 0$ let $S^{i+1}_t =$ $S^i_t \cup \{ s( u ) \mid u : \upsilon \in S^i, \upsilon \in \Data, \upsilon \text{ finite}, s \in \Sel^{\upsilon}  \}$,
and let $S^\ast_t$ be the fixed point of this sequence.
We know this is a finite set for each $t$ since the values of the type of $t$ are of finite size.
Let $S^\ast$ be the union of $S^\ast_t$ for all $t \in T$,
and let $\tcEc$ be the set of subterms of $\Ec \cup \{ C_i( s^1_i( t ), \ldots, s^{a_i}_i( t ) ) \mid t : \tau \in S \cup S^\ast, C_i \in \Ctr^\tau \}$.
In a derivation tree with root node $\Ec$, 
it can be shown by case analysis on the rules of the calculus that each non-root node $\Fc$ is such that 
$\mathcal{T}(\Fc) \subseteq \tcEc$, and moreover thus contains an equality between two terms from $\tcEc$ not occurring in its parent node.
Thus, the depth of a branch in a derivation tree with root node $\Ec$ is at most $\mid \tcEc \mid^2$,
which is finite since $\tcEc$ is finite.
\qed
\end{proof}

\begin{lemma}[Refutation Soundness]%
\label{lem:rs}%
\afterDot
If there exists a closed derivation tree with root node $\Ec$, then $\Ec$ is unsatisfiable in $\thD$.
\end{lemma}
\begin{proof}
We prove this by structural induction on the (closed) derivation tree with root node $\Ec$.
First, if the derivation tree is an application of \rn{Conflict}, \rn{Clash}, or \rn{Cyclic},
then $\Ec$ is unsatisfiable in $\thD$.
For \rn{Conflict}, this is a consequence of equality reasoning.
For \rn{Clash}, this is a consequence of distinctness.
For \rn{Cyclic}, our construction of $\Val$ indicates that the class of values that $t_1$ can take in models of $\Ec$ is infeasible,
and thus $\Ec$ is unsatisfiable.
If the children of $\Ec$ are closed derivation trees 
whose root node is the result of applying the rule \rn{Split} on term $t$ of type $\tau$,
then by the induction hypothesis $\Ec \cup t \teq C_i( s^1_i( t ), \ldots, s^{a_i}_i( t ) )$ is unsatisfiable
for each $C_i \in \Ctr^\tau$.
Since by exhaustiveness, all models of $\thD$ entail (exactly) one equality $t \teq C_i( s^1_i( t ), \ldots, s^{a_i}_i( t ) )$,
we know $\Ec$ is unsatisfiable in $\thD$.
Otherwise, the child of $\Ec$ is a closed derivation tree 
whose root node is $\Ec \cup t_1 \teq t_2$ obtained by applying one of the rules \rn{Refl}, \rn{Sym}, \rn{Trans}, \rn{Cong}, \rn{Decomp}, \rn{Bisimilar}, or \rn{Singleton}.
In all cases, we have that $\Ec \models_{\thD} t_1 \teq t_2$.
For \rn{Refl}, \rn{Sym}, \rn{Trans}, \rn{Cong}, this is a consequence of equality reasoning.
For \rn{Decomp}, this is a consequence of injectivity.
For \rn{Bisimilar}, our construction of $\Val$ indicates that the value of $t_1$ and $t_2$ are equivalent in all models of $\Ec$.
For \rn{Singleton}, clearly $t_1$ and $t_2$ must have the same value since the cardinality of their type is one.
By the induction hypothesis, we have $\Ec \cup t_1 \teq t_2$ is unsatisfiable in $\thD$, 
and thus $\Ec$ is unsatisfiable in $\thD$.
\qed
\end{proof}

It remains to show the inverse of the previous lemma, that when a derivation tree with root node $\Ec$ contains a saturated node,
then $\Ec$ is satisfiable $\thD$.
To do so, we demonstrate a particular model $\M$ of $\thD$ that satisfies $\Ec$,
but first we require additional terminology concerning $\mu$-terms.

For a $\mu$-term $t_1$ with subterm $t_2$, 
the \emph{interpretation of $t_2$ in $t_1$} is the $\mu$-term $t_1\interp{t_2}^\emptyset$ as returned by the following recursive procedure,
where $x \mapsto \mu x. \const{C}( \vec u ) \in t_1$ indicates that $\mu x. \const{C}( \vec u )$ is the subterm of $t_1$ that binds this occurrence of variable $x$.
\[\begin{array}{l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l}
t_1\interp{x}^M & = & \mu x. \const{C}( t_1\interp{ \vec u}^{M \cup \{ x \}}) & x \not\in M, x \mapsto \mu x. \const{C}( \vec u ) \in t_1  \\
t_1\interp{x}^M & = & x & \text{otherwise} \\
t_1\interp{\mu x. \const{C}( \vec u )}^M & = & \mu x. \const{C}( t_1\interp{ \vec u }^{M \cup \{ x \}} ) & x \not\in M \\
t_1\interp{\mu x. \const{C}( \vec u )}^M & = & x & \text{otherwise}
\end{array}\]
We often write $t_1\interp{t_2}$ as shorthand for $t_1\interp{t_2}^\emptyset$.

Given a $\mu$-term $t_1$ of the form $\mu x. \const{C}( u_1, \ldots, u_n )$ with subterm $t_2$,
we say $t_2$ is a \emph{bisimilar subterm} of $t_1$ if and only if it is of the form
$\mu y. \const{C}( v_1, \ldots, v_n )$ and $t_1\interp{ u_i } \sim t_1\interp{ v_i }$ for $i = 1,\ldots, n$.
We say $t_1$ is \emph{normal} if and only if it does not contain a strict bisimilar subterm
and all of its strict subterms are also normal.
For instance, the $\mu$-term $t_1$ of the form $\mu x. \const{C}( \mu y. \const{C}( y ) )$ is not normal, 
since $\mu y. \const{C}( y )$ is a bisimilar subterm of $t_1$.
In particular, note that their arguments have the same interpretation in $t_1$, 
that is,
$t_1\interp{\mu y. \const{C}( y )}^\emptyset =$ 
$\mu y. \const{C}( t_1\interp{y}^{\{y\}} ) =$ 
$\mu y. \const{C}( y )$ 
is syntactically equivalent to
$t_1\interp{y}^\emptyset =$ 
$\mu y. \const{C}( t_1\interp{y}^{\{y\}} ) =$ 
$\mu y. \const{C}( y )$.
The $\mu$-term $t_1$ of the form $\mu x. \const{C}( \mu y. \const{C}( x ) )$ is also not normal, 
since $\mu y. \const{C}( x )$ is a bisimilar subterm of $t_1$,
noting that
$t_1\interp{\mu y. \const{C}( x )}^\emptyset =$ 
$\mu y. \const{C}( t_1\interp{x}^{\{y\}} ) =$ 
$\mu y. \const{C}( t_1\interp{\mu x. \const{C}( \mu y. \const{C}( x ) ) }^{\{y\}} ) =$ 
$\mu y. \const{C}( \mu x. \const{C}( t_1\interp{\mu y. \const{C}( x )}^{\{x,y\}} ) ) =$ 
$\mu y. \const{C}( \mu x. \const{C}( y ) )$
is syntactically equivalent to $t_1\interp{x}^\emptyset = t_1$ for the renaming $\{ x \mapsto y, y \mapsto x \}$.

For any $\mu$-term $t$ of the form $\mu x. C( \vec u )$, we may recursively construct a normal $\mu$-term $\nf{t}$
(which we call the \emph{normal form} of $t$)
that is a renaming of $v$ by replacing all of the bisimilar subterms of $t$ with $x$,
(which we call the \emph{normal form} of $t$)
that is a renaming of $t$ by replacing all of the bisimilar subterms of $t$ with $x$,
%and by replacing all of the nonnormal subterms of $t$ with their corresponding normal forms.
and by normalizing $t$'s subterms.
For instance, $\nf{(\mu x. \const{C}( \mu y. \const{C}( x ) ))} = \mu x. \const{C}( x )$.

\begin{lemma}
\label{lem:mu-norm-arg}
If $\vec u$ are normal, then if $t = \nf{(\mu x. \const{C}( \vec u ) )} = \mu x. \const{C}( \vec w )$,
then $\vec u \vsim t\interp{\vec w}$.
\end{lemma}
\begin{proof}
%Since $u_i$ is normal, $w_i$ is the result of replacing all subterms $v$ of $u_i$ such that $t\interp{v} \sim t$ with $x$.
\rem{TODO}
\end{proof}

\begin{lemma}
\label{lem:mu-cong}
If $t_u = \mu x. \const{C}( \vec u )$ and $t_w = \mu y. \const{C}( \vec w )$ are normal,
then $t_u\interp{ \vec u } \vsim t_w\interp{ \vec w }$ if and only if $t_u \vsim t_w$.
\end{lemma}
\begin{proof}
\rem{TODO}
\end{proof}

We now define a class of models that we consider.
\rem{Clarify that non-codatatype terms are interpreted as $\mu$-terms, although dropping the $\mu$'s gives the standard representation?}

\begin{definition}[Normal Model] \label{def:norm-model}
A model $\M$ is \emph{normal} if and only if:
\begin{enumerate}
\item 
for all types $\tau$, 
$\M( \tau )$ is a maximal set of closed normal $\mu$-terms of that type that are 
unique up to renaming of $\mu$-bound variables,
and acyclic when $\tau \not\in \Codata$,
\item 
for all constructor terms $\const{C}( \vec t \,)$ of type $\tau$,
$\M( \const{C}( \vec t \,) )$ is the value 
in $\M( \tau )$ that is a renaming of 
$\nf{(\mu x. \const{C}( \M( \vec t \,) ))}$ where $x$ is fresh, and
\item 
for all selector terms $s^j_i( t )$ of type $\tau$,% for some $\vec u$,
$\M( s^j_i( t ) )$ is the value
in $\M( \tau )$ that is a renaming of 
$\M( t )\interp{u_j}$
when $\M( t )$ is of the form $\mu x. \const{C}_i( \vec u )$.
\end{enumerate}
\end{definition}

In the following, we consider only normal models.
Thus, when constructing a model $\M$ for $\Ec$,
it remains only to define how $\M$ interprets wrong-applied selector terms and variables.
For the latter, this will be based on the mapping $\Val$ constructed in step two of our calculus.
We compute the \emph{completion} of $\Val$ for normal model $\M$, which we write as $\Val^\ast$,
which we construct by assigning values from $\M$ to unassigned variables in the domain of $\Val$.

First, we need the following definition.
We say that $t \vsimv{x} s$ if and only if $\mu$-terms $t$ and $s$ are syntactically equivalent
for some renaming that avoids capturing any variable other than $x$.
For instance, 
$\mu x. \const{D}( x ) \vsimv{y} \mu x. \const{D}( y )$,
$\mu x. \const{C}( x, x ) \vsimv{x} \mu y. \const{C}( x, y )$ and
$\mu x. \const{C}( z, x ) \vsimv{z} \mu y. \const{C}( z, y )$,
but
$\mu x. \const{D}( x ) \not\vsimv{x} \mu x. \const{D}( y )$ and
$\mu x. \const{C}( x, x ) \not\vsimv{y} \mu y. \const{C}( x, y )$.
For a variable $x$ of type $\tau$ and a fixed normal model $\M$,
we write $\mathcal{T}^\M_x( \Val )$ to denote the set consisting of all values $v$ from $\M( \tau )$
such that $v \vsim_x t_1\interp{t_2}$ for some term $t_1$ with subterm $t_2$ occurring in the range of $\Val$.
We first construct a mapping $\Val'$ by exhaustively applying the following update to $\Val$:

\(
\inferrule{
  x : \tau \in FV( \Val ) 
  \quad
  (\mu x. t) \sim v
  \quad
  v \in \M( \tau )
  \quad
  v \not\in \mathcal{T}^\M_x(\Val)
}{
  \Val := \Val \{ x \mapsto \mu x. t \}
}
\)

In this update, we choose an unassigned variable in $\Val$
and assign it a value that is not bisimilar to one occurring in $\mathcal{T}^\M_x(\Val)$.
Since this update removes one variable from the set $FV( \Val )$ and does not add any additional variables to $FV( \Val )$, 
it can only be applied a finite number of times.
We then let $\Val^\ast \ec{x}$ be $\nf{(\Val' \ec{x})}$ for all $\ec{x}$.

\begin{example}
Let $\tau$ be a type in $\Codata$ with three constructors $\const{A}$, $\const{B}$ and $\const{C}$ each having type $\tau \rightarrow \tau$.
Let $\Ec$ be the set consisting of equalities
$\{$
$y_1 \teq \const{A}( y_2 )$,
$y_2 \teq \const{B}( x )$,
$z_1 \teq \const{C}( z_2 )$,
$z_2 \teq \const{A}( z_1 )$,
$w_1 \teq \const{A}( x )$,
$w_2 \teq \const{C}( w_3 )$,
$x \not\teq y_2$,
$\}$.
After running the calculus to saturation on $\Ec$, the mapping $\Val$ contains:
\[\begin{array}{l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{2.0em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l@{\hspace{.5em}}l}
\Val \ec{y_1} & = & \mu v_{\ec{y_1}}. & \const{A}( & \mu v_{\ec{y_2}}. & \const{B}( v_{\ec{x}} ) ) &
\Val \ec{w_1} & = & \mu v_{\ec{w_1}}. & \const{A}( v_{\ec{x}} )      & \\ 
\Val \ec{y_2} & = & \mu v_{\ec{y_2}}. & \multicolumn{2}{l}{\const{B}( v_{\ec{x}} )}      & &
\Val \ec{w_2} & = & \mu v_{\ec{w_2}}. & \const{C}( v_{\ec{w_3}} ) \\
\Val \ec{z_1} & = & \mu v_{\ec{z_1}}. & \const{C}( & \mu v_{\ec{z_2}}. & \const{A}( v_{\ec{z_1}} ) ) &
\Val \ec{w_3} & = & v_{\ec{w_3}} \\
\Val \ec{z_2} & = & \mu v_{\ec{z_2}}. & \const{A}( & \mu v_{\ec{z_1}}. & \const{C}( v_{\ec{z_2}} ) ) & 
\Val \ec{x} & = & v_{\ec{x}} \\
\end{array}\]

To construct a completion of $\Val$, we must choose values for the free variables of $\Val$, $v_{\ec{x}}$ and $v_{\ec{w_3}}$.
The content of the set $\mathcal{T}^\M_{v_{\ec{x}}}( \Val )$ is $\alpha$-equivalent to:
\[%\begin{array}{c}
\{
\mu x. \const{A}( \mu y. \const{B}( x )),
\mu x. \const{A}( \mu y. \const{B}( y )),
\mu x. \const{B}( x ),
\mu x. \const{C}( \mu y. \const{A}( x )),
\mu x. \const{A}( \mu y. \const{C}( x )),
\mu x. \const{A}( x )
\}
%\end{array}
\]
Now, consider a model $\M$ that interprets variables in $\Ec$ based on the mapping $\Val$,
for instance, $x$ is interpretted as $\Val \ec{x}$, $y_1$ as $\Val \ec{y_1}$ and so on.
Assigning a value for $v_{\ec{x}}$ that is $\alpha$-equivalent to a value in $\mathcal{T}^\M_{v_{\ec{x}}}( \Val )$
may cause values in the range of $\Val$ to become $\alpha$-equivalent, 
which in turn may cause $\M$ to be inconsistent.
For instance, say we assign $\mu v_{\ec{x}}. \const{B}( v_{\ec{x}} )$ for $v_{\ec{x}}$.
After this substitution, $\Val \ec{y_2}$ is $\mu v_{\ec{y_2}}. \const{B}( \mu v_{\ec{x}}. \const{B}( v_{\ec{x}} ) )$, 
which has normal form $\mu v_{\ec{y_2}}. \const{B}( v_{\ec{y_2}} )$,
which is $\alpha$-equivalent to $\mu v_{\ec{x}}. \const{B}( v_{\ec{x}} )$.
However, this contradicts the disequality $x \not\teq y_2$ in $\Ec$.
Inversely, if the value assigned to $v_{\ec{x}}$ is not $\alpha$-equivalent to any term in $\mathcal{T}^\M_{v_{\ec{x}}}( \Val )$,
then the values in the range of $\Val$ remain $\alpha$-disequivalent.
For instance, we may assign values such as 
$\mu v_{\ec{x}}. \const{C}( v_{\ec{x}} )$,
$\mu v_{\ec{x}}. \const{C}( \mu x_1. \const{A}( x_1) )$, and
$\mu v_{\ec{x}}. \const{B}( \mu x_1. \const{A}( v_{\ec{x}} ) )$
to $v_{\ec{x}}$.
Notice that legal substitutions for $v_{\ec{x}}$ may cause the range of $\Val$ to contain non-normal terms,
as in after applying the third substitution mentioned above,
$\Val \ec{w_1}$ is $\mu v_{\ec{w_1}}. \const{A}( \mu v_{\ec{x}}. \const{B}( \mu x_1. \const{A}( v_{\ec{x}} ) ) )$.
$\Box$
\end{example}

We first state the following properties of $\Val^\ast$,.
%where we write $\muvar( t )$ to denote $t$ if $t$ is a variable, or $x$ if $t$ is of the form $\mu x. u$.

\begin{lemma} 
\label{lem:model-completion}
If $\Val$ is constructed for a saturated $\Ec$,
and $\Val^\ast$ is a completion of $\Val$ for normal model $\M$, then:
\begin{enumerate}
\item $\Val^\ast \ec{x}$ is bisimilar with a value in $\M( \tau )$, for all $\ec{x}$ of type $\tau$ of $\Ec$,
\item
If $\const{C}( t_1, \ldots, t_n ) \in \ec{x}$,
then $\Val^\ast \ec{x} = \mu v_{\ec{x}}. \const{C}( w_1, \ldots, w_n )$
and $\Val^\ast \ec{x} \interp{ w_i } = \Val^\ast \ec{t_i}$ for $i = 1, \ldots, n$.
%and $\muvar( w_i ) = v_{\ec{t_i}}$ for $i = 1, \ldots, n$,
%\item
%$t_1 \interp{ t_2 } = \Val^\ast \ec{x}$
%for all $t_1$ with subterm $t_2$ in the range of $\Val^\ast$ where $\muvar(t_2)=v_{\ec{x}}$,
\item 
$\Val^\ast \ec{x} \vsim \Val^\ast \ec{y}$ if and only if $\ec{x} = \ec{y}$.
\end{enumerate}
\end{lemma}
\begin{proof}
To show 1, we first show that $\Val^\ast$ contains no free variables.
Assume by contradiction that $\Val^\ast$ contained a free variable $v_{\ec{y}}$ for some $\ec{y}$ of type $\tau$.
Then it must be the case that $\ec{y}$ does not contain a constructor term,
or else $v_{\ec{y}}$ would not occur as a free variable in $\Val$.
Consider the case when $\tau$ is finite.
By assumption, $\tau \not\in \Nondata$.
Since \rn{Split} does not apply to $\Ec$, we have $\tau \not\in \Data$.
If $\tau \in \Codata$, then $\tau$ is corecursive by assumption, and by Lemma~\ref{lem:corecursive-singletons},
the cardinality of $\tau$ must be one.
Since \rn{Singleton} does not apply to $\Ec$,
there is only one equivalence class of type $\tau$ in $\Ec$,
and thus there are no terms in $\mathcal{T}^\M_x(\Val^\ast)$ of type $\tau$.
This is a contradiction, since our model completion may assign the value in the domain of $\tau$ to $v_{\ec{x}}$.
Now, consider the case when $\tau$ is infinite.
This is also a contradiction, 
since there are only a finite number of closed terms in $\mathcal{T}^\M_x(\Val^\ast)$,
and thus our model completion can assign a value not occurring in $\mathcal{T}^\M_x(\Val^\ast)$ to $v_{\ec{y}}$.
By construction, $\Val^\ast \ec{x}$ is normal.
Since \rn{Cyclic} does not apply, $\Val \ec{x}$ is acyclic when $\tau \in \Data$.
Moreover, our construction of $\Val^\ast$ applies substitutions of the form 
$\{ y \mapsto t \}$, where $t$ is acyclic when the type of $y$ is not a codatatype.
Thus, $\Val^\ast \ec{x}$ is acyclic when $\tau \not\in \Codata$.
Therefore, by definition, $\Val^\ast \ec{x}$ is bisimilar with a value in $\M( \tau )$.

To show 2, 
first note that since \rn{Clash} does not apply to $\Ec$,
for all equivalence classes $\ec{y}$,
each pair of constructor terms $\const{C}_i( \vec t )$ and $\const{C}_j( \vec u )$ in $\ec{y}$
are such that $i = j$ since \rn{Clash} does not apply to $\Ec$,
and are such that $\ec{ \vec t } = \ec{ \vec u }$ since \rn{Decomp} does not apply to $\Ec$.
Thus, 
if $\const{C}_i( t_1, \ldots, t_n ) \in \ec{y}$,
$\Val$ was constructed by applying a sequence of substitutions
that replace $v_{\ec{y}}$ by $\mu v_{\ec{y}}. \const{C}_i( v_{\ec{t_1}}, \ldots, v_{\ec{t_n}} )$.
Now, say that $\const{C}( t_1, \ldots, t_n )$ occurs in some equivalence class $\ec{x}$.
Then $\Val \ec{x}$ must be of the form $\mu v_{\ec{x}}. \const{C}_i( w_1, \ldots, w_n )$,
where for each $i=1,\ldots,n$, $w_i$ was obtained by applying a sequence of substitutions
of the form mentioned above to $v_{\ec{t_i}}$.
%Each $w_i$ is either $v_{\ec{x}}$,
%a variable $v_{\ec{y}}$ where $\ec{y}$ does not contain a constructor,
%or a term of the form $\mu v_{\ec{y}}. \const{C}_j( \vec u )$.
While interpreting $w_i$ in $\Val \ec{x}$,
all free occurrences of $v_{\ec{x}}$ in $\Val \ec{x} \interp{w_i}$ are replaced by $\Val \ec{x}$. \rem{better formalize.}
Thus, since $\Val \ec{x} \interp{w_i}$ and $\Val \ec{t_i}$ are obtained by applying the same sequence of substitutions to $v_{\ec{t_i}}$,
we have $\Val \ec{w_i} = \Val \ec{x} \interp{ w_i }$.
Since $\Val'$ is obtained by applying the same substitution to all terms in the range of $\Val$,
we have that $\Val' \ec{x} \interp{w_i} = \Val' \ec{t_i}$,
and hence $\Val^\ast \ec{x} \interp{w_i} = \Val^\ast \ec{t_i}$.

To show 3,
first note that since \rn{Bisimilar} does not apply,
$\Val \ec{x} \sim \Val \ec{y}$ if and only if $\ec{x} = \ec{y}$.
Since \rem{TODO}
we have $\nf{(\Val \ec{x})} \sim \nf{(\Val \ec{y})}$ if and only if $\ec{x} = \ec{y}$.
We show that for any substitution $\sigma$ applied to $\Val$ while constructing its completion is such that
$\nf{(\Val \ec{x} \sigma)} \sim \nf{(\Val \ec{y} \sigma)}$ if and only if $\ec{x} = \ec{y}$.
\rem{TODO}
\qed
\end{proof}

\begin{lemma}[Solution Soundness]%
\label{lem:ss}%
\afterDot
If there exists a derivation tree with root node $\Ec$ containing a saturated node, then $\Ec$ is satisfiable in $\thD$.
\end{lemma}
\begin{proof}
Let $\Fc$ be a saturated node in a derivation tree with root node $\Ec$.
%We will construct a model $\M$ for a set of equalities $\Fc$ that is equivalent to $\Fc_0$, and where 
%all equivalence classes of $\Fc$ contain at least one variable, and all selectors in $\Fc$ are applied to variables only.
%The former comes with no loss of generality since new equalities of the form $y \teq t$ for fresh variable $y$ can be added to $\Fc$ without affecting its satisfiability,
%The latter also comes with no loss of generality since nested applications of selectors in $\Fc_0$ can be replaced by fresh variables while adding additional equalities to $\Fc$.
We consider a normal model $\M$ 
that interprets wrongly-applied selectors based on equality information in $\Fc$,
and interprets the variables of $\Fc$ based on the completion $\Val^\ast$ of the mapping $\Val$ from step two of our calculus.
For the latter, let $\M( x )$ be the value in $\M$ that is bisimilar with $\Val^\ast \ec{x}$ for each variable $x$ in $\mathcal{T}(\Fc)$.

We first show $\M$ satisfies all equalities in $t_1 \teq t_2 \in \Fc$, where $t_1$ and $t_2$ have type $\tau$.
We show,
by structural induction on $t$,
that $\M( t ) \sim \Val^\ast \ec{t}$ for all terms $t \in \mathcal{T}( \Fc )$,
which implies $\M \models t_1 \teq t_2$.

If $t$ is a variable, then $\M( t ) \vsim \Val^\ast \ec{ t }$ by construction.

If $t$ is a constructor term of the form $\const{C}( u_1, \ldots, u_n )$, 
then $\M( t )$ is bisimilar with $\nf{(\mu x. \const{C}( \M( u_1 ), \ldots, \M( u_n ) ) )}$ for fresh $x$,
which by the induction hypothesis is bisimilar with $\nf{(\mu x. \const{C}( \Val^\ast \ec{ u_1 }, \ldots, \Val^\ast \ec{ u_n } ) )}$, call this term $t_u$.
By Lemma~\ref{lem:model-completion}.2, $\Val^\ast \ec{t}$ is a term
%Since \rn{Clash} does not apply to $\Fc$, then $\Val^\ast \ec{t}$ must be a term
$t_w$ of the form $\mu v_{\ec{t}}. \const{C}( w_1, \ldots, w_n )$
where $t_w\interp{w_i} = \Val^\ast \ec{u_i}$ for $i = 1, \ldots, n$.
%that is, an application of the same constructor.
For each $i = 1, \ldots, n$, let $u_i'$ be the $i^{th}$ argument of $t_u$.
By Lemma~\ref{lem:mu-norm-arg}, $t_u\interp{u_i'} \vsim \Val^\ast \ec{u_i}$.
%Say that $\muvar( w_i ) = v_{\ec{y_i}}$.
%Due to our construction of $\Val^\ast$ and since \rn{Decomp} does not apply to $\Fc$, we have $\ec{u_i} = \ec{y_i}$,
%and thus $t_u\interp{u_i'} \vsim \Val^\ast \ec{y_i}$.
%By Lemma~\ref{lem:model-completion}.2, $\Val^\ast \ec{ y_i } = t_w\interp{ w_i }$,
and thus $t_u\interp{u_i'} \vsim t_w\interp{ w_i }$. % for each $i = 1, \ldots, n$.
By Lemma~\ref{lem:mu-cong}, we have $t_u \vsim t_w$.
Since $\vsim$ is a transitive relation and since $\M( t ) \vsim t_u \vsim t_w = \Val^\ast \ec{t}$,
we have $\M( t ) \vsim \Val^\ast \ec{t}$.

If $t$ is a selector term of the form $s^j_k( u )$,
since \rn{Split} does not apply, 
$\ec{u}$ must contain a term of the form $C_i( s^1_i( u ), \ldots, s^{n}_i( u ) )$ for some $i$.
By Lemma~\ref{lem:model-completion}.2, $\Val^\ast \ec{u}$ is a term $t_w$ of the form
$\mu v_{\ec{u}}. C_i( w_1, \ldots, w_n )$,
where $t_w \interp{ w_j } = \Val^\ast \ec{ s^j_k( u )}$. 
%By our construction of $\Val^\ast$ and since \rn{Decomp} and \rn{Clash} do not apply to $\Fc$, 
%$\Val^\ast \ec{ u }$ must be of the form $t_u = \mu v_{\ec{u}}. C_i( u_1, \ldots, u_n )$,
%where $\muvar( u_1 ) = v_{\ec{s^1_i(u)}}$, $\ldots$, $\muvar(u_n) = v_{\ec{s^n_i( u )}}$,
%and $\M( u )$ is of the form $t_w = \mu x. C_i( w_1, \ldots, w_n )$,
%which by the induction hypothesis is bisimilar with $\Val^\ast \ec{u}$.
If $k = i$, then $\M( t )$ is bisimilar with $t_w\interp{w_j} = \Val^\ast \ec{ s^j_k( u )}$,
which is $\Val^\ast \ec{t}$.
%which since $t_w \vsim t_u$ by Lemma~\ref{lem:mu-cong} is bisimilar with $t_u\interp{u_j}$,
%which by Lemma~\ref{lem:model-completion}.2 is equal to $\Val^\ast \ec{ s^j_k( u )}$.
%Thus, $\M( t ) \vsim \Val^\ast \ec{ s^j_k( u )} 
If $k \neq i$, then we interpret $s^j_k( \M( u ) )$ as the value in $\M( \tau )$ that is bisimilar with $\Val^\ast \ec{ t }$.
Since \rn{Cong} does not apply and due to Lemma~\ref{lem:model-completion}.3, 
pairs of wrongly-applied selectors are assigned the same value if and only if they reside in the same equivalence class,
and thus this definition is well-defined.

We now show that all disequalities in $\Fc$ are satisfied by $\M$.
Say $t_1 \tneq t_2 \in \Fc$.
Since \rn{Conflict} does not apply, $t_1 \teq t_2 \not\in \Fc$ and thus $\ec{t_1}$ and $\ec{t_2}$ are distinct.
Since $\M( t_1 ) \vsim \Val^\ast \ec{t_1}$, $\M( t_2 ) \vsim \Val^\ast \ec{t_2}$
and Lemma~\ref{lem:model-completion}.3, $\M( t_1 ) \neq \M( t_2 )$, and thus $\M \models t_1 \tneq t_2$.

Since by assumption $\Fc$ contains only equalities and disequalities, we have $\M \models \Fc$,
and since $\Fc$ is a superset of $\Ec$, we have that $\Ec$ is satisfied by $\M$.
\qed
\end{proof}

By Lemmas~\ref{lem:t},~\ref{lem:rs}, and~\ref{lem:ss}, the calculus is sound and complete for $\thD$.

\section{Extension to Quantified Formulas}
\label{sec:extension-to-quantified-formulas}

  * universal conjecture is no problem:
    * falls into the ground fragment via negation
      and skolemization
  * nor is existential axiom a problem
  * what's interesting: universal axioms and existential conjectures

Blah.

\section{Implementation as a Theory Solver in CVC4}
\label{sec:the-theory-solver}

This section describes how the calculus in Section~\ref{sec:the-calculus} is implemented within the SMT solver CVC4.

\paragraph{Optimizations}
We first discuss several optimizations that are not reflected in the presentation of the calculus, which closely follow the approach outlined by Barrett et al in~\cite{}.
We only briefly mention these optimizations, since each applies to datatypes as well as codatatypes, and most have been presented thoroughly in~\cite{}.

Discriminators are treated as predicate symbols, so a discriminator $\const{d}_i( t )$ is such that $\const{d}_i$ 
is a predicate symbol, instead of reducing this constraint to $t \teq \const{C}_i( s^1_i( t ), \ldots, s^n_i( t ) )$.
We have found that this leads to better performance since this reduction introduces terms more eagerly to $\tEc$.
Handling discriminators requires extending the decision procedure with several additional rules (see~\cite{} for more details), which apply uniformly to both datatypes and codatatypes.
Also, selectors are collapsed eagerly:
if $s^j_i( t )$ is a term in $\tEc$ and $t$ contains the constructor 
$\const{C}_i( \vec u )$, then we immediately infer $s^j_i( t ) \teq u_j$, whereas the calculus we presented would apply \rn{Split} and \rn{Decomp} before inferring this equality.  
For the sake of reducing the number of unique constraints considered by the calculus, we compute a normal form for constraints as a pre-processing step.
In particular, we 
replace $t \teq s$ by $s \teq t$ if $s$ is less than $t$ based on a term ordering,
replace $\const{C}_i( \vec t ) \teq \const{C}_j( \vec u )$ with $\bot$ when $i \neq j$,
replace all selector terms of the form $\const{s}^{\,i}_j( \const{C}_j(t_1,\ldots,t_n) )$ by $t_i$,
and replace all occurrences of discriminators $\const{d}_i( \const{C}_k( \vec t ) )$ by $\top$ if $i=k$ and $\bot$ if $i \neq k$.

\paragraph{Integration into DPLL(T)}
The calculus is implemented as \emph{theory solver} of CVC4,
that is, a specialized solver for determining the satisfiability of conjunctions of constraints for its theory.
%In DPLL(T) \rem{CDCL{T}?},
%a SAT solver
Given a theory $T = T_1 \cup \ldots T_n$ and a input set of clauses $F$ in CNF,
the DPLL(T) \rem{CDCL{T}?} procedure
(incrementally) builds partial assignments from the atomic formulas of $F$ to truth values such that no clause in $F$ is falsified.
We may interpret this partial assignment as a set of literals where $a \in M$ for all atoms $a$ that it assigned the value $\top$, and $\neg a \in M$ for all atoms that it assigns the value $\bot$.
Then, at a high level, by the Nelson-Oppen combination framework,
each $T_i$-solver for $i = 1, \ldots, n$ takes as input a combination of (1) the purified form of $T_i$-constraints occurring in $M$ where terms containing symbols not belonging to $T_i$ are replaced by fresh variables of the same type, 
(2) additional equalities and disequalities between variables of types not belonging to $T_i$.
Let us call this set $M_i$.
Each $T_i$ solver either 
reports that a subset $C$ of $M_i$ is $T_i$-unsatisfiable in which case $\neg C$ is added as a additional clause to $F$,
adds an additional clause $C$ to $F$,
or does nothing.
When $M$ is a complete assignment for $F$, then a theory solver can only choose to do nothing when $M_i$ is indeed $T_i$-satisfiable.

Assume $\Ec$ is initially the set $M_i$ described above.
For each equality added to $\Ec$, we associate a set of equalities from $M_i$ that together $\thD$-entail $t \teq s$,
which we call its \emph{explanation}.
Similarly, each $\Val \ec{x}$ is also associated an explanation, that is, 
a set of equalities from $M_i$ that $\thD$-entail that the values of $\ec{x}$ in models of $\Ec$ are of the form $\Val \ec{x}$.
For instance, if $x \teq \const{C}( x ) \in M_i$, then $x \teq \const{C}( x )$ is a (possible) explanation for $\Val \ec{x} = \mu v_{\ec{x}}. \const{C}( v_{\ec{x}} )$.
Thus, the rules of the calculus are implemented as follows.
For all rules with conclusion $\bot$,
we report the union of the explanations for all premises is $\thD$-unsatisfiable.
For the \rn{Split} rule, we add a clause of the form
$(\const{C}_1( s^1_1( t ), \ldots, s^{a_1}_1( t ) ) \vee \ldots \vee t \teq \const{C}_n( s^1_n( t ), \ldots, s^{a_n}_n( t ) ))$
to $F$.
Notice that decisions on which branch to take are thus performed externally by the SAT solver, and not by the theory solver.
All other rules add equalities to the internal state of the theory solver.

Step 1 of the calculus (along with the optimization for collapsing selectors) and the \rn{Singleton} rule are performed eagerly, 
that is for partial satisfying assignments $M$, while step 2 and the \rn{Split} rule from step 3 are performed only for complete satisfying assignments $M$, and in that order.

    * sharing is caring
    * theory combination more complicated (and Theorem Completeness too weak)


%\section{Examples}
%\label{sec:examples}

\section{Evaluation on Isabelle Problems}
\label{sec:experimental-results}

\newcommand\gandl{G\&L}
\newcommand\HD[1]{\hbox to2.5em{\hfill#1\hfill}}

\begin{table*}[tbh!]
\normalsize
\begin{center}\begin{tabular}{l@{\kern1.5em}c@{\kern.5em}c@{\kern.5em}c@{\kern1.5em}c}
  & \HD{Distro} & \HD{AFP} & \HD{\gandl} & All
\\[1pt] %%% TYPESETTING HACK
\midrule
%$\enatT$
\\[-9pt] %%% TYPESETTING HACK
No (co)datatypes
  & 221 & 760 & \phantom{0}57 & 1038 \\
Datatypes without cyclicity
  & 227 & 765 & \phantom{0}57 & 1049 \\
Datatypes with cyclicity
  & 227 & 771 & \phantom{0}57 & 1055 \\
Codatatypes without bisimilarity
  & 217 & 787 & \phantom{0}55 & 1059 \\
Codatatypes with bisimilarity
  & 218 & 787 & \phantom{0}58 & 1063 \\
Full (co)datatypes
  & 224 & 798 & \phantom{0}58 & 1080 \\[\jot]
Total number of goals
  & 879 & 2974\phantom{0} & 317 & 4170
\end{tabular}\end{center}
\caption{\,Number of solved goals for the three benchmark suites}
\label{tab:bench}
\end{table*}

To evaluate the decision procedure, we generated problems from existing
Isabelle formalizations using Sledgehammer \cite{paulson-blanchette-2010}.
Codatatypes being a recent addition to Isabelle
\cite{blanchette-et-al-2014-impl}, benchmarks are somewhat hard to come by. We
included the theory files from the Isabelle distribution (the Distro) and the \emph{Archive
of Formal Proofs} (AFP) \cite{klein-et-al-afp} that define codatatypes falling
within the supported fragment. We also included two unpublished theories by
Peter Gammie and Andreas Lochbihler (\gandl), about Bird and Stern--Brocot trees.
To also exercise the the support
for datatypes, the benchmarks are complemented by theories about various list
and tree data structures. The theory files were selected before running the
experiments. The experimental data is publicly available \cite{our-eval-data}.

For each goal in each theory file, Sledgehammer was invoked to select
256~lemmas as axioms, which were then monomorphized and translated to SMT-LIB
along with the goal \cite{boehme-2012-phd}. The resulting problem was given to
CVC4, running for up to \textbf{TODO: XXX} seconds on the StarExec cluster
\cite{xxx}. Problems involving no (co)datatypes were filtered out.
Due to the lack of machinery for reconstructing inferences about (co)datatypes
in Isabelle, CVC4 is trusted as an oracle in these experiments.

CVC4 was run on each problem several times, with the support for datatypes and
codatatypes either enabled or disabled. The contributions of the cyclicity and
bisimilarity rules were also measured, so find out whether these somewhat
expensive rules are useful in practice. Even when the decision procedure is
disabled, some of the generated axioms typically include basic properties of
constructors and selectors, which the decision procedure would recognize as
tautologies.
%This allows us to answer the question, \relax{What are the
%benefits of activating the decision procedure as opposed to letting
%Sledgehammer do what it would normally do?}

\newcommand\BAD[1]{\textcolor{red}{\textbf{#1}}}

%  * experience with such features is not extremely high -- e.g. arithmetic,
%    a most useful theory on lots of benchmarks, increases Sledgehammer's
%    success rate by 2 percentage points, or 4\%, with Z3 in earlier work \cite{xxx}

%  * so when analyzing statistics of this kind, with highly varied problems,
%    we must not overestimate the importance of a single trick
%  * on the other hand: every percentage point counts! cite Tom Hales

The results are summarized in Table~\ref{tab:bench}. The decision procedure
makes a difference across all theories, and an overall difference of
\BAD{4.7\%}. Moreover, every aspect of the procedure, including the more
expensive rules, make a contribution. \textbf{NOT TRUE}: What is not visible in the table, but
readily available when looking at the raw data \cite{our-eval-data}, is that
the stronger decision procedures subsume the weaker ones. In the context of
Sledgehammer, the power of interpreted (co)datatypes is roughly
comparable to that of arithmetic \cite{blanchette-et-al-2013-smt}.

%* and finally, we look in more detail at one or two such proofs, by presenting
%  it and explaining it (and, before that, understanding it)

Among the four bisimilarity proofs, three corresponded to one-line
proofs in Isabelle, of the form \keyw{by}~\textit{coinduction}~\textit{auto}
\cite{blanchette-et-al-2014-impl}. The fourth proof was somewhat more elaborate:
%
\begin{quote}
\keyw{lemma} \,\textit{X0\_unique}: \,$x = \const{Node}\;0\;\const{num}\; x \Longrightarrow x = \const{X0}$ \\
\keyw{proof} \,(\textit{coinduction arbitrary}: $x$ \textit{rule}: \textit{tree.coinduct\_strong}) \\
\noindent\hbox{}\quad  \keyw{case} (\textit{Eq\_tree} $x$) \keyw{show} \textit{?case} \\
\noindent\hbox{}\qquad  \keyw{by} (\textit{subst} (1 2 3 4) \textit{Eq\_tree}) (\textit{simp add}: \textit{eqTrueI}[OF \textit{Eq\_tree}]) \\
\keyw{qed}
\end{quote}
%
\noindent
where \const{X0} is defined as $\const{X0} =
\const{Node}\;0\;\const{num}\;\const{X0}$.

\section{Conclusion}
\label{sec:conclusion}

We introduced a decision procedure for the ground theory of datatypes and
codatatypes and implemented it in the SMT solver CVC4. Our main theoretical
contribution has been the support for codatatypes. These are not very
difficult per se, but there are tricky corner cases to take care of if we care
about completeness (which we do).
%% alliteration
On the practical side, we obtained
interesting results on benchmarks generated from Isabelle theories, including
some rather
%mind-boggling
puzzling bisimulation proofs.

This work is part of a larger program that aims at enriching automatic provers
with high-level features and at reducing the gap between automatic and
interactive theorem proving. As future work, we want to implement proof
reconstruction for CVC4's (co)datatype inferences in Isabelle. We also want to
try out CVC4 for higher-order model finding in Isabelle, as an alternative to
the counterexample generator Nitpick \cite{blanchette-nipkow-2010}. We also
see some opportunities to enrich SMT solvers with recursive and corecursive
functions. Finally, it might be possible to go further in terms of supporting
nested and mixed (co)recursion and quantified formulas over (co)datatypes in
solvers.

\def\ackname{Acknowledgment}
\paragraph{\ackname.}
We owe a great debt to Clark Barrett and Cesare Tinelli for datatype case blah
blah blah. \textbf{TODO FIXME}
Morgan Deters?
%
Our present and former bosses, Viktor Kuncak, Stephan Merz, Tobias Nipkow,
Cesare Tinelli, and Christoph Weidenbach, have either encouraged the research on
codatatype or at least endured
%tolerated?
it, both of which we are thankful for.
%
Peter Gammie and Andreas Lochbihler shared their private
theories with us so we could include them in the benchmarks.
Andrei Popescu helped clarify our thoughts regarding the axiomatization of
codatatypes. Dmitriy Traytel took part in discussions about special
cases.
%
Blanchette's research was partially supported by the Deutsche
Forschungs\-gemein\-schaft (DFG) project
\relax{Hardening the Hammer} (grant Ni\,491\slash 14-1).

\bibliographystyle{splncs03}
\bibliography{bib}{}

\end{document}
